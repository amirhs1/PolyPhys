{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_CLXSgvVO_9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirhsi_mini/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "/Users/amirhsi_mini/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/MDAnalysis/coordinates/TRJ.py:1209: DeprecationWarning: Please use `netcdf_file` from the `scipy.io` namespace, the `scipy.io.netcdf` namespace is deprecated.\n",
      "  class NCDFPicklable(scipy.io.netcdf.netcdf_file):\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import SumRule\n",
    "from polyphys.probe import prober\n",
    "from polyphys.analyze import analyzer\n",
    "from polyphys.analyze import distributions\n",
    "import MDAnalysis as mda\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-9a35fa08-9da6-11ec-9d9e-1e00a3264579</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">872fbce0</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 8\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 16.00 GiB\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-1810d6ad-c3ba-47cb-be35-003683784146</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:53608\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:8787/status\" target=\"_blank\">http://127.0.0.1:8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 8\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 16.00 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:53626\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:53628/status\" target=\"_blank\">http://127.0.0.1:53628/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 4.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:53613\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/tests/dask-worker-space/worker-rt_k4os6\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:53622\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:53624/status\" target=\"_blank\">http://127.0.0.1:53624/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 4.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:53612\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/tests/dask-worker-space/worker-94wsqa4d\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:53620\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:53621/status\" target=\"_blank\">http://127.0.0.1:53621/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 4.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:53611\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/tests/dask-worker-space/worker-cu82ahy1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 3</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:53627\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 2\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:53629/status\" target=\"_blank\">http://127.0.0.1:53629/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 4.00 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:53614\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/tests/dask-worker-space/worker-f5cqz7f9\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:53608' processes=4 threads=8, memory=16.00 GiB>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "client = Client(n_workers=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.all.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.all.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "trjs_computed = []\n",
    "for topology in topologies:\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            if trj_info.segment_id ==14:\n",
    "                trj_delayed = delayed(prober.probe_all)(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=False)\n",
    "                trjs_computed.append(trj_delayed)\n",
    "            else:\n",
    "                trj_delayed = delayed(prober.probe_all)(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)\n",
    "                trjs_computed.append(trj_delayed)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing simulation data:\n",
    "There are several ways of analyzing the topology and trajectory pairs, depending on the number of trajectory files per a topology file, the continuity of trjaectory files, organization of files in a directory, and the parallel or sequencial arrangement of the computation powerhorse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separated *whole* simulation directories on a cluster: gnuparallel\n",
    "On the cluster, *whole* simulations are organized into *whole* directories, where each *whole* directory contains all the files for a given *whole* simulation. The **gnuparallel** is used to parallalize the **probe** phase at the **shell** level. For this purpose, all the python modules and scripts are separatedly installed and run on each core. For instance, if 32 cores are available, then the files in 32 *whole* directories are simulatenously installed. However, each *whole* directory may contains multiple toplogy and trajectory pairs. Thus, there is parallelization at the level of *whole* directories, not at the levle of the *segment* or *whole* trajectories inside a *whole* directory. Inside each *whole* directory, a python **main_probe.py** script analyzes the trajectories in a sequencial way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trj anf all segments on a cluster\n",
    "For each *whole* directory, the following script is executed by means of *gnuparallel*. See these scripts: *probe-1.7-all_trj_segments.py* and *probe-1.7-bug_trj_segments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import SumRule\n",
    "from polyphys.probe import prober\n",
    "\n",
    "geometry = 'biaxial'\n",
    "trj_lineage = 'segment'\n",
    "save_to=\"./\"\n",
    "\n",
    "bug_trjs = glob(\"./N*.bug.lammpstrj\")\n",
    "bug_trjs = organizer.sort_filenames(bug_trjs,extensions=['.bug.lammpstrj'])\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob(\"./N*.bug.data\")\n",
    "bug_topo = organizer.sort_filenames(bug_topo,extensions=['.bug.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "print(bug_topo)\n",
    "for bug_trj in bug_trjs:\n",
    "    print(bug_trj)\n",
    "    trj_info = SumRule(bug_trj, geometry=geometry, group='bug',\n",
    "                       lineage=trj_lineage)\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id ==len(bug_trjs):\n",
    "        prober.probe_bug(trj_topo, bug_trj, geometry, trj_lineage, save_to)\n",
    "    # the last frame in the all other segments is ignored:\n",
    "    else:\n",
    "        prober.probe_bug(trj_topo, bug_trj, geometry, trj_lineage, save_to,\n",
    "                         continuous=True)\n",
    "trj_lineage = 'segment'\n",
    "all_trjs = glob(\"./N*.all.lammpstrj\")\n",
    "all_trjs = organizer.sort_filenames(all_trjs,extensions=['.all.lammpstrj'])\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(\"./N*.all.data\")\n",
    "all_topo = organizer.sort_filenames(all_topo,extensions=['.all.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "print(all_topo)\n",
    "for all_trj in all_trjs:\n",
    "    print(all_trj)\n",
    "    trj_info = SumRule(all_trj, geometry=geometry, group='all',\n",
    "                       lineage=trj_lineage)\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id ==len(all_trjs):\n",
    "        prober.probe_all(trj_topo, bug_trj, geometry, trj_lineage, save_to)\n",
    "    # the last frame in the all other segments is ignored:\n",
    "    else:\n",
    "        prober.probe_all(trj_topo, bug_trj, geometry, trj_lineage, save_to,\n",
    "                         continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This approach from HERE\n",
    "path = pathlib.Path('../test_data/trjs-continuous/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "## to HERE, does not work of * is used in the string input for Path.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.bug.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.bug.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "for topology in topologies:\n",
    "    print(topology[0])\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            if trj_info.segment_id ==10:\n",
    "                prober.probe_bug(topology[0], trajectory[0], geometry, 'segment', save_to_whole)\n",
    "            else:\n",
    "                prober.probe_bug(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bug whole trjs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trjs whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This approach from HERE\n",
    "path = pathlib.Path('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "## to HERE, does not work of * is used in the string input for Path.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.bug.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.bug.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "for topology in topologies:\n",
    "    print(topology[0])\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='whole')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            prober.probe_bug(topology[0], trajectory[0], geometry, 'whole', save_to_whole, continuous=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bug whole trjs dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment'\n",
      "Directory '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment' exist. Files are saved/overwritten to an existing directory.\n",
      "/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.bug.data\n",
      "[Errno 17] File exists: '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1'\n",
      "Directory '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1' exist. Files are saved/overwritten to an existing directoy.\n",
      "/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1.bug.data\n",
      "[Errno 17] File exists: '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'\n",
      "Directory '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1' exist. Files are saved/overwritten to an existing directoy.\n"
     ]
    }
   ],
   "source": [
    "## This approach from HERE\n",
    "path = pathlib.Path('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "## to HERE, does not work of * is used in the string input for Path.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.bug.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.bug.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "trjs_computed = []\n",
    "for topology in topologies:\n",
    "    print(topology[0])\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='whole')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            trj_delayed = delayed(prober.probe_bug)(topology[0], trajectory[0], geometry, 'whole', save_to_whole, continuous=False)\n",
    "            trjs_computed.append(trj_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirhsi_mini/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "/Users/amirhsi_mini/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "/Users/amirhsi_mini/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/MDAnalysis/coordinates/TRJ.py:1209: DeprecationWarning: Please use `netcdf_file` from the `scipy.io` namespace, the `scipy.io.netcdf` namespace is deprecated.\n",
      "  class NCDFPicklable(scipy.io.netcdf.netcdf_file):\n",
      "/Users/amirhsi_mini/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/MDAnalysis/coordinates/TRJ.py:1209: DeprecationWarning: Please use `netcdf_file` from the `scipy.io` namespace, the `scipy.io.netcdf` namespace is deprecated.\n",
      "  class NCDFPicklable(scipy.io.netcdf.netcdf_file):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.64 s, sys: 2.37 s, total: 12 s\n",
      "Wall time: 9min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# it takes 9min and 34s.\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# probe all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all trj segments on pc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path('../test_data/trjs-continuous/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.all.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.all.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "for topology in topologies:\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.segment_id ==10:\n",
    "            prober.probe_all(topology[0], trajectory[0], geometry, 'segment', save_to_whole)\n",
    "        else:\n",
    "            prober.probe_all(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path('../test_data/trjs-continuous/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "all_tuples =  organizer.sort_filenames(observations,fmts=['all.lammpstrj'])\n",
    "all_trjs = [all_tuple[0] for all_tuple in all_tuples]\n",
    "all_data =  organizer.sort_filenames(observations,fmts=['all.data'])\n",
    "all_data = all_data[0][0]\n",
    "\n",
    "    \n",
    "for all_trj in all_trjs:\n",
    "    print(all_trj)\n",
    "    #PipeLine.extract_trj_all(all_data, all_trj, geom, save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trjs all segments dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.all.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.all.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "trjs_computed = []\n",
    "for topology in topologies:\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            if trj_info.segment_id ==14:\n",
    "                trj_delayed = delayed(prober.probe_all_new)(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=False)\n",
    "                trjs_computed.append(trj_delayed)\n",
    "            else:\n",
    "                trj_delayed = delayed(prober.probe_all_new)(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)\n",
    "                trjs_computed.append(trj_delayed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "geometry = 'biaxial'\n",
    "phase = 'analysis'\n",
    "stage = 'wholeSim'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "relation = 'tseries'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "observations = organizer.sort_filenames(observations, fmts=['bug-gyrTMon.npy'])\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "gyr_wholes = organizer.whole('gyrTMon', observations, geometry=geometry, group=group, relation=relation, save_to=save_to)\n",
    "\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "geometry = 'biaxial'\n",
    "phase = 'analysis'\n",
    "stage = 'wholeSim'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "relation = 'histogram'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "observations = organizer.sort_filenames(observations, fmts=['-all-rHistMon.npy'])\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "rhist_wholes = organizer.whole('rHistMon', observations, geometry=geometry, group=group, relation=relation, save_to=save_to)\n",
    "\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "geometry = 'biaxial'\n",
    "phase = 'analysis'\n",
    "stage = 'wholeSim'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "relation = 'bin_edge'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "observations = organizer.sort_filenames(observations, fmts=['-all-rEdgeMon.npy'])\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "redge_wholes = organizer.whole('rEdgeMon', observations, geometry=geometry, group=group, relation=relation, save_to=save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group = 'bug'\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "phase = 'analysis'\n",
    "stage = 'ens'\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "gyr_ens = organizer.ensemble(\n",
    "    'gyrTMon',\n",
    "    gyr_wholes,\n",
    "    group=group,\n",
    "    edge_wholes=None,\n",
    "    save_to=save_to)\n",
    "group = 'all'\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "phase = 'analysis'\n",
    "stage = 'ens'\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "rhist_ens = organizer.ensemble(\n",
    "    'rHistMon',\n",
    "    rhist_wholes,\n",
    "    group=group,\n",
    "    edge_wholes=redge_wholes,\n",
    "    save_to=save_to)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group = 'bug'\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "phase = 'analysis'\n",
    "stage = 'ensAvg'\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "gyr_ens_avg = analyzer.ensemble_avg(\n",
    "    'gyrTMon',\n",
    "    gyr_ens,\n",
    "    group=group,\n",
    "    save_to=save_to)\n",
    "group = 'all'\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "phase = 'analysis'\n",
    "stage = 'ensAvg'\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "rhist_ens_avg = analyzer.ensemble_avg(\n",
    "    'rHistMon',\n",
    "    rhist_ens,\n",
    "    group=group,\n",
    "    exclude=['bin_center'],\n",
    "    save_to=save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyr_ens_avg['N500D10.0ac0.8nc12012'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhist_ens['N500D10.0ac0.8nc12012']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(distributions.distributions_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist_paths = glob('/Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1*')\n",
    "hist_paths = glob('/Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1*')\n",
    "species = 'Crd'\n",
    "direction = 'z'\n",
    "geometry='biaxial'\n",
    "group='all'\n",
    "segments = organizer.sort_filenames(\n",
    "                hist_paths,\n",
    "                fmts=['-' + direction + 'Hist' + species + '.npy']\n",
    "            )\n",
    "edge_segments = organizer.sort_filenames(\n",
    "                hist_paths,\n",
    "                fmts=['-' + direction + 'Edge' + species + '.npy']\n",
    "            )\n",
    "wholes = organizer.whole(\n",
    "                direction + 'Hist' + species,\n",
    "                segments,\n",
    "                geometry=geometry,\n",
    "                group=group,\n",
    "                relation='histogram',\n",
    "                save_to=None\n",
    "            )\n",
    "edge_wholes = organizer.whole(\n",
    "                direction + 'Edge' + species,\n",
    "                edge_segments,\n",
    "                geometry=geometry,\n",
    "                group=group,\n",
    "                relation='bin_edge',\n",
    "                save_to=None\n",
    "            )\n",
    "            # 'whole' dataframes, each with a 'whole' columns.\n",
    "rho_wholes, phi_wholes = distributions.distributions_generator(\n",
    "                wholes,\n",
    "                edge_wholes,\n",
    "                group,\n",
    "                species,\n",
    "                geometry,\n",
    "                direction,\n",
    "                save_to=None,\n",
    "normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_wholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'][:-1],edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'],weights=wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'],histtype='step',density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'][:-1],bins=edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'],weights=wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1,ncols=1,sharex=True,figsize=(8,6))\n",
    "centers = 0.5*(edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'][:-1]+edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'][1:])\n",
    "hist_df = pd.DataFrame(wholes)\n",
    "rho_df = pd.DataFrame(rho_wholes)\n",
    "phi_df = pd.DataFrame(phi_wholes)\n",
    "df = pd.concat([hist_df,rho_df,phi_df],axis=1)\n",
    "df.columns = ['histogram','number_density','volume_fraction']\n",
    "df['center'] = centers\n",
    "#df['histogram'] = df['histogram'] / df['histogram'].sum()\n",
    "df['fake']= 1\n",
    "#df.set_index('center',inplace=True)\n",
    "#sns.histplot(x='center',bins=edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'] ,weights='volume_fraction',data=df,element='poly',fill=False, kde=True)\n",
    "#plt.show()\n",
    "#df['histogram'].plot(ax=axes,ylabel='histogram')\n",
    "#sns.set_theme(style=\"whitegrid\")\n",
    "#sns.set(font_scale=1.2)\n",
    "sns.axes_style(\"darkgrid\")\n",
    "sns.lineplot(x='center',y='histogram', data=df,ax=axes)\n",
    "#df.loc[-200:200,'number_density'].plot(ax=axes[1],ylabel='number_density')\n",
    "#df.loc[-200:200,'volume_fraction'].plot(ax=axes[2],ylabel='volume_fraction',xlabel='center')\n",
    "#axes.grid()\n",
    "#axes.set_xlim(df.index[0]-5, df.index[-1]+5)\n",
    "#axes.axvline(df.loc[df.index[0],'center'],lw=0.5,c='red',label='left end')\n",
    "#axes.axvline(df.loc[df.index[-1],'center'],lw=0.5,c='green',label='right end')\n",
    "#axes.axvline(df['center'],lw=0.5,c='red')\n",
    "axes.set_xlabel('z (a.u.)')\n",
    "axes.set_ylabel('Freqency of type-1 particles')\n",
    "#ax.set_xlim[]\n",
    "plt.savefig('histogram.pdf',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['center'][-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = 'N500epsilon5.0r5.5lz205.5sig0.8nc36036dt0.002bdump1000adump5000ens1'\n",
    "hist_info = SumRule(name, geometry='biaxial', group='all', lineage='whole')\n",
    "dist_new = distributions.Distribution(\n",
    "    wholes[name],\n",
    "    edges[name],\n",
    "    hist_info,\n",
    "    'dcrowd',\n",
    "    geometry='biaxial',\n",
    "    direction='z',\n",
    "    normalized=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whole_from_Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_database = '/Users/amirhsi_mini/probe/N500D10.0ac0.8-segment'\n",
    "geometry = 'biaxial'\n",
    "hierarchy = '/N*/N*'\n",
    "lineage = 'segment'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "#save_to = analyzer.database_path(input_database, phase='analysis', stage='wholeSim', group=group)\n",
    "#analyzer.analyze_segments(input_database, geometry, hierarchy)\n",
    "analyzer.analyze_wholes(input_database, geometry, hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "client = Client(n_workers=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script is used in GNU-Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PipeLine import *\n",
    "\n",
    "fname = glob(\"../N*.bug.*\")\n",
    "fname = PipeLine.file_reader(fname) # This is a list with one member\n",
    "\n",
    "save_to=\"./\"\n",
    "geom = 'cylindrical'\n",
    "print(fname)\n",
    "PipeLine.extract_trj_bug(fname[0], geom, save_to) # A list with one member, the member is a tuple of a trj and data pair.\n",
    "#PipeLine.bug_trj_rmsd(fname[0], geom, save_to) \n",
    "\n",
    "trj_files = glob(\"./N*all.lammpstrj\")\n",
    "all_tuples = PipeLine.file_reader(trj_files,extensions=['lammpstrj'])\n",
    "all_trjs = [all_tuple[0] for all_tuple in all_tuples]\n",
    "\n",
    "data_file = glob(\"./N*.all.data\")\n",
    "all_data = PipeLine.file_reader(data_file,extensions=['all.data'])\n",
    "all_data = all_data[0][0]\n",
    "\n",
    "    \n",
    "for all_trj in all_trjs:\n",
    "    print(all_trj)\n",
    "    PipeLine.extract_trj_all(all_data, all_trj, geom, save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard approach: Running on clusters: extraction from orgaznied *trjs_all* and *trjs_bug* directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This are not work properly on Graham cluster but work well on iMacmini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract from an organized *trjs_bug* directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script extract different bug's information from pairs (toplogy and trajectory) of bug simulation files in oen or more organized *trjs_bug* directories.\n",
    "from pathlib import Path\n",
    "import os\n",
    "from glob import glob\n",
    "from PipeLine import *\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "\n",
    "cores = 32\n",
    "print(f\"number of workers set to {cores}; is this the same requested cores on the cluster?\")\n",
    "client = Client(n_workers=cores)\n",
    "home = str(Path.home())\n",
    "cwdir = str(Path.cwd())\n",
    "# information extraction from simulations\n",
    "geom = 'cylindrical'\n",
    "fname = glob(home+'/amirhsi_rrg/cylinder_simulations/N*-trjs_bug/N*bug*')\n",
    "bug_pairs = PipeLine.file_reader(fname) # each bug_pair is a pair of trajectory and topopgy file.\n",
    "trjs_computed = []\n",
    "bug_dir = 'extraction_bug/'\n",
    "for bug_pair in bug_pairs:\n",
    "    sim_name = bug_pair[0].split(\"/\")[-1].split('bug')[0]\n",
    "    sim_dir = cwdir+bug_dir+sim_name\n",
    "    Path(sim_dir).mkdir(parents=True, exist_ok=False)\n",
    "    sim_save_to = sim_dir+\"/\"\n",
    "    trj_delayed = delayed(PipeLine.extract_trj_bug)(bug_pair, geom,sim_save_to)\n",
    "    trjs_computed.append(trj_delayed)\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract from an organized *trjs_all* directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script extract different bug's information from pairs (toplogy and trajectory) of bug simulation files in oen or more organized *trjs_bug* directories.\n",
    "from pathlib import Path\n",
    "import os\n",
    "from glob import glob\n",
    "from PipeLine import *\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "\n",
    "cores = 32\n",
    "print(f\"number of workers set to {cores}; is this the same requested cores on the cluster?\")\n",
    "client = Client(n_workers=cores)\n",
    "home = str(Path.home())\n",
    "cwdir = str(Path.cwd())\n",
    "sim_all_dirs = glob(home+'/amirhsi_rrg/cylinder_simulations/N*-trjs_all/N*/')\n",
    "geom = 'cylindrical'\n",
    "\n",
    "trjs_computed = []\n",
    "all_extraction_dir = 'extraction_all/'\n",
    "for sim_all_dir in sim_all_dirs:\n",
    "    sim_name = sim_all_dir[0].split(\"/\")[-1]\n",
    "    all_trjs = glob(sim_all_dir+\"N*.lammpstrj\")\n",
    "    all_trjs = PipeLine.file_reader(all_trjs,extensions=['lammpstrj'])\n",
    "    all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "\n",
    "    all_topology = glob(sim_all_dir+\"N*.all.data\")\n",
    "    all_topology = PipeLine.file_reader(all_topology,extensions=['all.data'])\n",
    "    all_topology = all_topology[0][0]\n",
    "    \n",
    "    \n",
    "    sim_extract_dir = cwdir+all_extraction_dir+sim_name\n",
    "    Path(sim_extract_dir).mkdir(parents=True, exist_ok=False)\n",
    "    sim_save_to = sim_extract_dir+\"/\"\n",
    "    \n",
    "    for all_trj in all_trjs:\n",
    "        trj_delayed = delayed(PipeLine.extract_trj_all)(all_topology, all_trj, geom,sim_save_To)\n",
    "        trjs_computed.append(trj_delayed)\n",
    "\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction from *extraction_bug* directory after a simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = str(Path.home())\n",
    "path=home+'N2000epsilon5.0r10.5lz336sig1.0nc100800dt0.005bdump1000adump5000ens1'\n",
    "fname = glob(path+\"/N*.bug.*\")\n",
    "fname = PipeLine.file_reader(fname) # This is a list with one member\n",
    "geom = 'cylindrical'\n",
    "print(fname)\n",
    "PipeLine.extract_trj_bug(fname[0], geom) # A list with one member, the member is a tuple of a trj and data pair.\n",
    "PipeLine.rmsd_trj_bug(fname[0], geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the segments in one trajectory: M dump files + one data file.\n",
    "path='/Users/amirhsi_mini/N2000epsilon5.0r10.5lz336sig1.0nc100800dt0.005bdump1000adump5000ens*'\n",
    "geom = 'cylindrical'\n",
    "trj_files = glob(path+\"/N*.lammpstrj\")\n",
    "all_tuples = PipeLine.file_reader(trj_files,extensions=['lammpstrj',])\n",
    "all_trjs = [all_tuple[0] for all_tuple in all_tuples]\n",
    "data_file = glob(path+\"/N*.all.data\")\n",
    "all_data = PipeLine.file_reader(data_file,extensions=['all.data'])\n",
    "all_data = all_data[0][0]\n",
    "for all_trj in all_trjs:\n",
    "    PipeLine.extract_trj_all(all_data, all_trj, geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New approach: tested on iMac Pro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single ensemble with one or more segments with one data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/amirhsi_mini/N2000epsilon5.0r15.5lz379.5sig6.0nc1068dt0.005bdump1000adump5000ens*'\n",
    "#path='/Users/amirhsi_mini/N1000epsilon5.0r8.0lz308.5sig2.0nc10412dt0.005bdump1000adump5000ens*'\n",
    "geom = 'cylindrical'\n",
    "trj_files = glob(path+\"/N*all*\")\n",
    "all_pairs = PipeLine.file_reader(trj_files)\n",
    "trjs_computed = []\n",
    "for all_pair in all_pairs:\n",
    "    trj_delayed = delayed(PipeLine.extract_all_trj_polymer_cog_fsd)(all_pair[1], all_pair[0], geom)\n",
    "    trjs_computed.append(trj_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N ensemble with N data file, each ensemble with one or more segments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/amirhsi_mini/N2000epsilon5.0r15.5lz379.5sig6.0nc1068dt0.005bdump1000adump5000ens*'\n",
    "#path='/Users/amirhsi_mini/N1000epsilon5.0r8.0lz308.5sig2.0nc10412dt0.005bdump1000adump5000ens*'\n",
    "geom = 'cylindrical'\n",
    "trj_pathes = glob(path+\"/N*all*\")\n",
    "trjs = PipeLine.file_reader(trj_pathes,extensions=['lammpstrj'])\n",
    "trjs = [trj[0] for trj in trjs]\n",
    "topology_pathes = glob(path+\"/N*.all.data\")\n",
    "topologies = PipeLine.file_reader(topology_pathes,extensions=['all.data'])\n",
    "topologies = [topology[0] for topology in topologies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(pair):\n",
    "    \"\"\"\n",
    "    simulation_pair pairs an \"all\" topology file with all the \"all\" trjectories of that \"all\" topology.\n",
    "    \n",
    "    Parameters:\n",
    "    pair (list of tuples): a list in whic each tuple is  pair of topolgy and trajectories of a simulations.\n",
    "    \n",
    "    Return:\n",
    "    a dict of of simulation pairs.\n",
    "    \"\"\"\n",
    "    return {'topology':pair[0], 'trajectories':pair[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_names = [topology.split(\"/\")[-1].split('.all')[0] for topology in topologies]\n",
    "ens_names = list(dict.fromkeys(ens_names))\n",
    "trjs_per_ens = []\n",
    "for ens_name in ens_names:\n",
    "    ens_trjs = []\n",
    "    for trj in trjs:\n",
    "        trj_name = trj.split(\"/\")[-1].split(\".all\")[0]\n",
    "        if trj_name == ens_name:\n",
    "            ens_trjs.append(trj)\n",
    "            #ensembles[key]['trajectories'] = trj\n",
    "    trjs_per_ens.append(ens_trjs)\n",
    "ensembles= dict(zip(ens_names,list(map(simulation,list(zip(topologies,trjs_per_ens))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = 'cylindrical'\n",
    "trjs_computed = []\n",
    "for ensemble in ensembles.values():\n",
    "    for trj_segment in ensemble['trajectories']:\n",
    "        trj_delayed = delayed(PipeLine.extract_trj_all)(ensemble['topology'], trj_segment, geom)\n",
    "        trjs_computed.append(trj_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = compute(trjs_computed)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_v4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
