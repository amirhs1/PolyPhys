{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_CLXSgvVO_9"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import SumRule\n",
    "from polyphys.probe import prober\n",
    "from polyphys.analyze import analyzer\n",
    "from polyphys.analyze import distributions\n",
    "import MDAnalysis as mda\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "client = Client(n_workers=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# The probe phase:\n",
    "There are several ways of analyzing the topology and trajectory pairs, depending on the number of trajectory files per a topology file, the continuity of trjaectory files, organization of files in a directory, and the parallel or sequencial arrangement of the computation powerhorse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Separated *whole* simulation directories on a cluster: gnuparallel\n",
    "On the cluster, *whole* simulations are organized into *whole* directories, where each *whole* directory contains all the files for a given *whole* simulation. The **gnuparallel** is used to parallalize the **probe** phase at the **shell** level. For this purpose, all the python modules and scripts are separatedly installed and run on each core. For instance, if 32 cores are available, then the files in 32 *whole* directories are simulatenously installed. However, each *whole* directory may contains multiple toplogy and trajectory pairs. Thus, there is parallelization at the level of *whole* directories, not at the levle of the *segment* or *whole* trajectories inside a *whole* directory. Inside each *whole* directory, a python **main_probe.py** script analyzes the trajectories in a sequencial way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### trj anf all segments on a cluster\n",
    "For each *whole* directory, the following script is executed by means of *gnuparallel*. See these scripts: *probe-1.7-all_trj_segments.py* and *probe-1.7-bug_trj_segments*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import SumRule\n",
    "from polyphys.probe import prober\n",
    "\n",
    "geometry = 'biaxial'\n",
    "trj_lineage = 'segment'\n",
    "save_to=\"./\"\n",
    "\n",
    "bug_trjs = glob(\"../test_data/trjs-continuous/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2/N*.bug.lammpstrj\")\n",
    "bug_trjs = organizer.sort_filenames(bug_trjs,fmts=['.bug.lammpstrj'])\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob(\"../test_data/trjs-continuous/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2/N*.bug.data\")\n",
    "bug_topo = organizer.sort_filenames(bug_topo,fmts=['.bug.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "print(bug_topo)\n",
    "for bug_trj in bug_trjs:\n",
    "    print(bug_trj)\n",
    "    trj_info = SumRule(bug_trj, geometry=geometry, group='bug',lineage=trj_lineage)\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id ==len(bug_trjs):\n",
    "        #print(\"last: \" + bug_trj)\n",
    "        prober.probe_bug(bug_topo, bug_trj, geometry, trj_lineage, save_to)\n",
    "    # the last frame in the all other segments is ignored:\n",
    "    else:\n",
    "        #print(bug_trj)\n",
    "        prober.probe_bug(bug_topo, bug_trj, geometry, trj_lineage, save_to, continuous=True)\n",
    "trj_lineage = 'segment'\n",
    "all_trjs = glob(\"../test_data/trjs-continuous/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2/N*.all.lammpstrj\")\n",
    "all_trjs = organizer.sort_filenames(all_trjs, fmts=['.all.lammpstrj'])\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(\"../test_data/trjs-continuous/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2/N*.all.data\")\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.all.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "print(all_topo)\n",
    "for all_trj in all_trjs:\n",
    "    print(all_trj)\n",
    "    trj_info = SumRule(all_trj, geometry=geometry, group='all',lineage=trj_lineage)\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id ==len(all_trjs):\n",
    "        #print(\"last: \" + all_trj)\n",
    "        prober.probe_all(all_topo, all_trj, geometry, trj_lineage, save_to)\n",
    "    # the last frame in the all other segments is ignored:\n",
    "    else:\n",
    "        #print(all_trj)\n",
    "        prober.probe_all(all_topo, all_trj, geometry, trj_lineage, save_to,continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Separated *whole* directories on a PC: Dask\n",
    "On a PC, the *whole* directories are located in a master *space-trjs* directory; however, one main python script probes all the *whole* directories in a parallel scheme via Dask. This is different from the *gnuparallel*-based approach in which each *whole* directory has its own copy of the required scripts and a main pytohn script is run to probe that direcotry individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This approach from HERE\n",
    "path = pathlib.Path('../test_data/trjs-continuous/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "## to HERE, does not work of * is used in the string input for Path.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.bug.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.bug.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "for topology in topologies:\n",
    "    print(topology[0])\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            if trj_info.segment_id ==10:\n",
    "                prober.probe_bug(topology[0], trajectory[0], geometry, 'segment', save_to_whole)\n",
    "            else:\n",
    "                prober.probe_bug(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### bug whole trjs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### trjs whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This approach from HERE\n",
    "path = pathlib.Path('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "## to HERE, does not work of * is used in the string input for Path.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.bug.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.bug.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "for topology in topologies:\n",
    "    print(topology[0])\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='whole')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            prober.probe_bug(topology[0], trajectory[0], geometry, 'whole', save_to_whole, continuous=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### bug whole trjs dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This approach from HERE\n",
    "path = pathlib.Path('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "## to HERE, does not work of * is used in the string input for Path.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.bug.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.bug.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "trjs_computed = []\n",
    "for topology in topologies:\n",
    "    print(topology[0])\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='whole')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            trj_delayed = delayed(prober.probe_bug)(topology[0], trajectory[0], geometry, 'whole', save_to_whole, continuous=False)\n",
    "            trjs_computed.append(trj_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# it takes 9min and 34s.\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Separated *segment* directories on a PC: Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path('../test_data/trjs-continuous/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.all.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.all.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "for topology in topologies:\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.segment_id ==10:\n",
    "            prober.probe_all(topology[0], trajectory[0], geometry, 'segment', save_to_whole)\n",
    "        else:\n",
    "            prober.probe_all(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path('../test_data/trjs-continuous/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "all_tuples =  organizer.sort_filenames(observations,fmts=['all.lammpstrj'])\n",
    "all_trjs = [all_tuple[0] for all_tuple in all_tuples]\n",
    "all_data =  organizer.sort_filenames(observations,fmts=['all.data'])\n",
    "all_data = all_data[0][0]\n",
    "\n",
    "    \n",
    "for all_trj in all_trjs:\n",
    "    print(all_trj)\n",
    "    #PipeLine.extract_trj_all(all_data, all_trj, geom, save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "### trjs all segments dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.all.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.all.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "trjs_computed = []\n",
    "for topology in topologies:\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            if trj_info.segment_id ==14:\n",
    "                trj_delayed = delayed(prober.probe_all_new)(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=False)\n",
    "                trjs_computed.append(trj_delayed)\n",
    "            else:\n",
    "                trj_delayed = delayed(prober.probe_all_new)(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)\n",
    "                trjs_computed.append(trj_delayed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# The analyze phase:\n",
    "In this phase, the segment files in the probe phase are merged into whole files. The ensemble, ensemble-averaged, and space files are created from whole files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## bugs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '//Users/amirhsi_mini/analysis/N500D10.0ac1.0-bug-wholeSim'\n",
      "Directory '//Users/amirhsi_mini/analysis/N500D10.0ac1.0-bug-wholeSim' exist. Files are saved/overwritten to an existing directory.\n",
      "[Errno 17] File exists: '//Users/amirhsi_mini/analysis/N500D10.0ac1.0-bug-ens'\n",
      "Directory '//Users/amirhsi_mini/analysis/N500D10.0ac1.0-bug-ens' exist. Files are saved/overwritten to an existing directory.\n",
      "[Errno 17] File exists: '//Users/amirhsi_mini/analysis/N500D10.0ac1.0-bug-ensAvg'\n",
      "Directory '//Users/amirhsi_mini/analysis/N500D10.0ac1.0-bug-ensAvg' exist. Files are saved/overwritten to an existing directory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:23\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/analyze/analyzer.py:604\u001b[0m, in \u001b[0;36manalyze_segments_bug\u001b[0;34m(input_database, non_scalar_properties, tseries_properties, acf_tseries_properties, hist_properties, rho_phi_hist_properties, geometry, hierarchy, nlags, alpha)\u001b[0m\n\u001b[1;32m    597\u001b[0m     time_series(\n\u001b[1;32m    598\u001b[0m         observations,\n\u001b[1;32m    599\u001b[0m         (save_to_whole, save_to_ens, save_to_ens_avg),\n\u001b[1;32m    600\u001b[0m         tseries_properties\u001b[38;5;241m=\u001b[39mtseries_properties,\n\u001b[1;32m    601\u001b[0m         geometry\u001b[38;5;241m=\u001b[39mgeometry\n\u001b[1;32m    602\u001b[0m     )\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m acf_tseries_properties \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 604\u001b[0m     \u001b[43mtime_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_to_whole\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to_ens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_to_ens_avg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m        \u001b[49m\u001b[43macf_tseries_properties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macf_tseries_properties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnlags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnlags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hist_properties \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    613\u001b[0m     histograms(\n\u001b[1;32m    614\u001b[0m         observations,\n\u001b[1;32m    615\u001b[0m         (save_to_whole, save_to_ens, save_to_ens_avg),\n\u001b[1;32m    616\u001b[0m         geometry\u001b[38;5;241m=\u001b[39mgeometry,\n\u001b[1;32m    617\u001b[0m         hist_properties\u001b[38;5;241m=\u001b[39mhist_properties\n\u001b[1;32m    618\u001b[0m     )\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/analyze/analyzer.py:118\u001b[0m, in \u001b[0;36mtime_series\u001b[0;34m(observations, save_to, tseries_properties, acf_tseries_properties, geometry, nlags, alpha)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# 'whole' dataframes, each with a 'whole' as its column:\u001b[39;00m\n\u001b[1;32m    110\u001b[0m wholes \u001b[38;5;241m=\u001b[39m whole(\n\u001b[1;32m    111\u001b[0m     property_ \u001b[38;5;241m+\u001b[39m species,\n\u001b[1;32m    112\u001b[0m     segments,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m     save_to\u001b[38;5;241m=\u001b[39msave_to_whole\n\u001b[1;32m    117\u001b[0m )\n\u001b[0;32m--> 118\u001b[0m ensembles \u001b[38;5;241m=\u001b[39m \u001b[43mensemble\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproperty_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mspecies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwholes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeometry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeometry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_ens\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m acfs, lower_cls, upper_cls \u001b[38;5;241m=\u001b[39m acf_generator(\n\u001b[1;32m    126\u001b[0m     property_ \u001b[38;5;241m+\u001b[39m species,\n\u001b[1;32m    127\u001b[0m     ensembles,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    131\u001b[0m     save_to\u001b[38;5;241m=\u001b[39msave_to_ens\n\u001b[1;32m    132\u001b[0m )\n\u001b[1;32m    133\u001b[0m _ \u001b[38;5;241m=\u001b[39m ensemble_avg(\n\u001b[1;32m    134\u001b[0m         property_ \u001b[38;5;241m+\u001b[39m species,\n\u001b[1;32m    135\u001b[0m         ensembles,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         save_to\u001b[38;5;241m=\u001b[39msave_to_ens_avg\n\u001b[1;32m    139\u001b[0m     )\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/manage/organizer.py:642\u001b[0m, in \u001b[0;36mensemble\u001b[0;34m(property_, wholes, geometry, group, edge_wholes, save_to)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;124;03m\"\"\"create an ensemble from a dictionary of wholes.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    A tuple of ensemble name and its assocaited dataframe.\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (ens[\u001b[38;5;241m0\u001b[39m], pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(ens[\u001b[38;5;241m1\u001b[39m], orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m--> 642\u001b[0m ensembles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmapping_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensembles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_wholes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ens_name \u001b[38;5;129;01min\u001b[39;00m ensembles\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/manage/organizer.py:641\u001b[0m, in \u001b[0;36mensemble.<locals>.mapping_func\u001b[0;34m(ens)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmapping_func\u001b[39m(\n\u001b[1;32m    628\u001b[0m     ens: Dict[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray]\n\u001b[1;32m    629\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\u001b[38;5;28mstr\u001b[39m, pd\u001b[38;5;241m.\u001b[39mDataFrame]:\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;124;03m\"\"\"create an ensemble from a dictionary of wholes.\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;124;03m    A tuple of ensemble name and its assocaited dataframe.\u001b[39;00m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (ens[\u001b[38;5;241m0\u001b[39m], \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/core/frame.py:1677\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly recognize index or columns for orient\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/core/frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/core/internals/construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    495\u001b[0m         x\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/core/internals/construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/core/internals/construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    679\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# takes 25 min with nlags=100000\n",
    "input_database = '/Users/amirhsi_mini/probe/N500D10.0ac1.0-segment/'\n",
    "#input_database = '../test_data/probe/N2000D30.0ac4.0-segment/'\n",
    "non_scalar_properties_bug = [\n",
    "    # property_, species, group\n",
    "    ('principalT', 'Mon', 'bug'),\n",
    "]\n",
    "\n",
    "acf_tseries_properties_bug = [\n",
    "    # property_, species, group\n",
    "    ('fsdT', 'Mon', 'bug'),\n",
    "    ('gyrT', 'Mon', 'bug'),\n",
    "    ('rfloryT', 'Mon', 'bug'),\n",
    "    ('shapeT', 'Mon', 'bug'),\n",
    "    ('asphericityT', 'Mon', 'bug')\n",
    "]\n",
    "\n",
    "hist_properties_bug = [\n",
    "    # direction, species, group\n",
    "    ('rflory', 'Mon', 'bug')\n",
    "]\n",
    "geometry = 'biaxial'\n",
    "analyzer.analyze_segments_bug(\n",
    "    input_database,\n",
    "    #non_scalar_properties=non_scalar_properties_bug,\n",
    "    acf_tseries_properties=acf_tseries_properties_bug,\n",
    "    #hist_properties=hist_properties_bug,\n",
    "    geometry=geometry,\n",
    "    hierarchy='N*/N*',\n",
    "    nlags=100000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AllInOne Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faking nc=0 for some spaces:\n",
    "Faking is done at the **ens** and **ensAvg** levels (and directories) not at the **segment** and **whole** levles, so the **segment stamps** are not modified byt the **whole** and **ens** ones are modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naming convention:\n",
    "This is the pattern of file or directory names:\n",
    "\n",
    "1. **whole** files: whole-group-property_[-measure][-stage][.ext]\n",
    "2. **ensemble** files: ensemble-group-property_[-measure][-stage][.ext]\n",
    "3. **ensemble_long** files: ensemble_long-group-property_[-measure][-stage][.ext]\n",
    "4. **space** files: space-group-property_[-measure][-stage][.ext]\n",
    "5. **all in one** files: **allInOne**-group-property_[-measure][-stage][.ext]\n",
    "\n",
    "[keyword] means that the keyword in the file name is option. [-measure] is a physical measurement such as the auto correlation function (AFC) done on the physical 'property_'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of unique property_measures:\n",
    "database = '/Users/amirhsi_mini/analysis/'\n",
    "bug_property_measures = glob(database+\"/N*-ensAvg\"+\"/N*.csv\")\n",
    "bug_property_measures = list(set([\"-\".join(property_measure.split(\"/\")[-1].split(\".csv\")[0] .split(\"-\")[2:]) for property_measure in bug_property_measures]))\n",
    "bug_property_measures.remove(\"stamps-ensAvg\")\n",
    "bug_property_measures.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### allInONe ensAvg stamps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ensemble_long</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>space</th>\n",
       "      <th>n_segments</th>\n",
       "      <th>nmon</th>\n",
       "      <th>epsilon</th>\n",
       "      <th>dcyl</th>\n",
       "      <th>lcyl</th>\n",
       "      <th>dcrowd</th>\n",
       "      <th>ncrowd</th>\n",
       "      <th>dt</th>\n",
       "      <th>bdump</th>\n",
       "      <th>adump</th>\n",
       "      <th>n_ensembles</th>\n",
       "      <th>dmon</th>\n",
       "      <th>phi_m_bulk</th>\n",
       "      <th>rho_m_bulk</th>\n",
       "      <th>phi_c_bulk</th>\n",
       "      <th>rho_c_bulk</th>\n",
       "      <th>n_frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc0dt0.005bdu...</td>\n",
       "      <td>N2000D30.0ac4.0nc0</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc1602dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc1602</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1602</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.100061</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc2402dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc2402</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2402</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.150030</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc3203</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3203</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.200061</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc3603dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc3603</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3603</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.225045</td>\n",
       "      <td>0.006716</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc4003dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc4003</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.250029</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc4403dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc4403</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4403</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.275013</td>\n",
       "      <td>0.008207</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc4804dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc4804</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4804</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.300060</td>\n",
       "      <td>0.008954</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc5204dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc5204</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5204</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.325044</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc5604dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc5604</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5604</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.350028</td>\n",
       "      <td>0.010445</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc6004dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc6004</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.375012</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig4.0nc6405dt0.005...</td>\n",
       "      <td>N2000D30.0ac4.0nc6405</td>\n",
       "      <td>N2000D30.0ac4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6405</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.400059</td>\n",
       "      <td>0.011938</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc475dt0.005b...</td>\n",
       "      <td>N2000D30.0ac6.0nc475</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>475</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.100132</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc712dt0.005b...</td>\n",
       "      <td>N2000D30.0ac6.0nc712</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>712</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.150092</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc949dt0.005b...</td>\n",
       "      <td>N2000D30.0ac6.0nc949</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>949</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.200053</td>\n",
       "      <td>0.001769</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc1068dt0.005...</td>\n",
       "      <td>N2000D30.0ac6.0nc1068</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1068</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.225138</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc1186dt0.005...</td>\n",
       "      <td>N2000D30.0ac6.0nc1186</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1186</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.250013</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc1305dt0.005...</td>\n",
       "      <td>N2000D30.0ac6.0nc1305</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1305</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.275099</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc1424dt0.005...</td>\n",
       "      <td>N2000D30.0ac6.0nc1424</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1424</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.300184</td>\n",
       "      <td>0.002654</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc1542dt0.005...</td>\n",
       "      <td>N2000D30.0ac6.0nc1542</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1542</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.325059</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc1661dt0.005...</td>\n",
       "      <td>N2000D30.0ac6.0nc1661</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1661</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.350145</td>\n",
       "      <td>0.003096</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005...</td>\n",
       "      <td>N2000D30.0ac6.0nc1779</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1779</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.375020</td>\n",
       "      <td>0.003316</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>N2000epsilon5.0r15.5lz379.5sig6.0nc1898dt0.005...</td>\n",
       "      <td>N2000D30.0ac6.0nc1898</td>\n",
       "      <td>N2000D30.0ac6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>759.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1898</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.400105</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>300001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ensemble_long               ensemble  \\\n",
       "0   N2000epsilon5.0r15.5lz379.5sig4.0nc0dt0.005bdu...     N2000D30.0ac4.0nc0   \n",
       "1   N2000epsilon5.0r15.5lz379.5sig4.0nc1602dt0.005...  N2000D30.0ac4.0nc1602   \n",
       "2   N2000epsilon5.0r15.5lz379.5sig4.0nc2402dt0.005...  N2000D30.0ac4.0nc2402   \n",
       "3   N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005...  N2000D30.0ac4.0nc3203   \n",
       "4   N2000epsilon5.0r15.5lz379.5sig4.0nc3603dt0.005...  N2000D30.0ac4.0nc3603   \n",
       "5   N2000epsilon5.0r15.5lz379.5sig4.0nc4003dt0.005...  N2000D30.0ac4.0nc4003   \n",
       "6   N2000epsilon5.0r15.5lz379.5sig4.0nc4403dt0.005...  N2000D30.0ac4.0nc4403   \n",
       "7   N2000epsilon5.0r15.5lz379.5sig4.0nc4804dt0.005...  N2000D30.0ac4.0nc4804   \n",
       "8   N2000epsilon5.0r15.5lz379.5sig4.0nc5204dt0.005...  N2000D30.0ac4.0nc5204   \n",
       "9   N2000epsilon5.0r15.5lz379.5sig4.0nc5604dt0.005...  N2000D30.0ac4.0nc5604   \n",
       "10  N2000epsilon5.0r15.5lz379.5sig4.0nc6004dt0.005...  N2000D30.0ac4.0nc6004   \n",
       "11  N2000epsilon5.0r15.5lz379.5sig4.0nc6405dt0.005...  N2000D30.0ac4.0nc6405   \n",
       "0   N2000epsilon5.0r15.5lz379.5sig6.0nc475dt0.005b...   N2000D30.0ac6.0nc475   \n",
       "1   N2000epsilon5.0r15.5lz379.5sig6.0nc712dt0.005b...   N2000D30.0ac6.0nc712   \n",
       "2   N2000epsilon5.0r15.5lz379.5sig6.0nc949dt0.005b...   N2000D30.0ac6.0nc949   \n",
       "3   N2000epsilon5.0r15.5lz379.5sig6.0nc1068dt0.005...  N2000D30.0ac6.0nc1068   \n",
       "4   N2000epsilon5.0r15.5lz379.5sig6.0nc1186dt0.005...  N2000D30.0ac6.0nc1186   \n",
       "5   N2000epsilon5.0r15.5lz379.5sig6.0nc1305dt0.005...  N2000D30.0ac6.0nc1305   \n",
       "6   N2000epsilon5.0r15.5lz379.5sig6.0nc1424dt0.005...  N2000D30.0ac6.0nc1424   \n",
       "7   N2000epsilon5.0r15.5lz379.5sig6.0nc1542dt0.005...  N2000D30.0ac6.0nc1542   \n",
       "8   N2000epsilon5.0r15.5lz379.5sig6.0nc1661dt0.005...  N2000D30.0ac6.0nc1661   \n",
       "9   N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005...  N2000D30.0ac6.0nc1779   \n",
       "10  N2000epsilon5.0r15.5lz379.5sig6.0nc1898dt0.005...  N2000D30.0ac6.0nc1898   \n",
       "\n",
       "              space  n_segments  nmon  epsilon  dcyl   lcyl  dcrowd  ncrowd  \\\n",
       "0   N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0       0   \n",
       "1   N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    1602   \n",
       "2   N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    2402   \n",
       "3   N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    3203   \n",
       "4   N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    3603   \n",
       "5   N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    4003   \n",
       "6   N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    4403   \n",
       "7   N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    4804   \n",
       "8   N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    5204   \n",
       "9   N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    5604   \n",
       "10  N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    6004   \n",
       "11  N2000D30.0ac4.0         2.0  2000      5.0  30.0  759.0     4.0    6405   \n",
       "0   N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0     475   \n",
       "1   N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0     712   \n",
       "2   N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0     949   \n",
       "3   N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0    1068   \n",
       "4   N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0    1186   \n",
       "5   N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0    1305   \n",
       "6   N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0    1424   \n",
       "7   N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0    1542   \n",
       "8   N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0    1661   \n",
       "9   N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0    1779   \n",
       "10  N2000D30.0ac6.0         2.0  2000      5.0  30.0  759.0     6.0    1898   \n",
       "\n",
       "       dt  bdump  adump  n_ensembles  dmon  phi_m_bulk  rho_m_bulk  \\\n",
       "0   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "1   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "2   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "3   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "4   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "5   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "6   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "7   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "8   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "9   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "10  0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "11  0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "0   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "1   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "2   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "3   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "4   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "5   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "6   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "7   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "8   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "9   0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "10  0.005   1000   5000            8   1.0    0.001952    0.003728   \n",
       "\n",
       "    phi_c_bulk  rho_c_bulk  n_frames  \n",
       "0     0.000000    0.000000    300001  \n",
       "1     0.100061    0.002986    300001  \n",
       "2     0.150030    0.004477    300001  \n",
       "3     0.200061    0.005970    300001  \n",
       "4     0.225045    0.006716    300001  \n",
       "5     0.250029    0.007461    300001  \n",
       "6     0.275013    0.008207    300001  \n",
       "7     0.300060    0.008954    300001  \n",
       "8     0.325044    0.009700    300001  \n",
       "9     0.350028    0.010445    300001  \n",
       "10    0.375012    0.011191    300001  \n",
       "11    0.400059    0.011938    300001  \n",
       "0     0.100132    0.000885    300001  \n",
       "1     0.150092    0.001327    300001  \n",
       "2     0.200053    0.001769    300001  \n",
       "3     0.225138    0.001991    300001  \n",
       "4     0.250013    0.002211    300001  \n",
       "5     0.275099    0.002432    300001  \n",
       "6     0.300184    0.002654    300001  \n",
       "7     0.325059    0.002874    300001  \n",
       "8     0.350145    0.003096    300001  \n",
       "9     0.375020    0.003316    300001  \n",
       "10    0.400105    0.003538    300001  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database = '/Users/amirhsi_mini/analysis/'\n",
    "spaces_stamps = glob(database+\"/N*-ensAvg\"+\"/N*-stamps-ensAvg.csv\")\n",
    "allInOne_stamps = []\n",
    "for space in spaces_stamps:\n",
    "    space_stamps = pd.read_csv(space)\n",
    "    allInOne_stamps.append(space_stamps)\n",
    "allInOne_stamps = pd.concat(allInOne_stamps, axis=0)\n",
    "allInOne_stamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chain-size timeseries and their associated measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asphericityTMon-acf-ensAvg', 'asphericityTMon-acfLowerCi-ensAvg', 'asphericityTMon-acfUpperCi-ensAvg', 'fsdTMon-acf-ensAvg', 'fsdTMon-acfLowerCi-ensAvg', 'fsdTMon-acfUpperCi-ensAvg', 'gyrTMon-acf-ensAvg', 'gyrTMon-acfLowerCi-ensAvg', 'gyrTMon-acfUpperCi-ensAvg', 'rfloryTMon-acf-ensAvg', 'rfloryTMon-acfLowerCi-ensAvg', 'rfloryTMon-acfUpperCi-ensAvg', 'shapeTMon-acf-ensAvg', 'shapeTMon-acfLowerCi-ensAvg', 'shapeTMon-acfUpperCi-ensAvg']\n",
      "['asphericityTMon-ensAvg', 'fsdTMon-ensAvg', 'gyrTMon-ensAvg', 'rfloryTMon-ensAvg', 'shapeTMon-ensAvg']\n"
     ]
    }
   ],
   "source": [
    "# separating property_measures of kinds timeseries and timesseries acfs:\n",
    "bug_property_acfs = list()\n",
    "for property_measure in bug_property_measures:\n",
    "    if \"-acf\" in property_measure:\n",
    "        bug_property_acfs.append(property_measure)\n",
    "bug_property_acfs.sort()\n",
    "print(bug_property_acfs)\n",
    "# chain timeseries:\n",
    "bug_properties = list()\n",
    "for property_measure in bug_property_acfs:\n",
    "    if \"-acf-\" in property_measure:\n",
    "        bug_properties.append(property_measure.split(\"-\")[0]+'-ensAvg')\n",
    "bug_properties.sort()\n",
    "print(bug_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m ensAvgs \u001b[38;5;241m=\u001b[39m ensAvgs\u001b[38;5;241m.\u001b[39mloc[:,\u001b[38;5;241m~\u001b[39mensAvgs\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mduplicated()]\n\u001b[1;32m     18\u001b[0m output_name \u001b[38;5;241m=\u001b[39m database \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallInOne-bug-chainSize.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mensAvgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/core/generic.py:3563\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3552\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3554\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3555\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3556\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3560\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3561\u001b[0m )\n\u001b[0;32m-> 3563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3565\u001b[0m \u001b[43m    \u001b[49m\u001b[43mline_terminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mline_terminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3566\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3568\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/io/formats/format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1162\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1163\u001b[0m     line_terminator\u001b[38;5;241m=\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1179\u001b[0m )\n\u001b[0;32m-> 1180\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/io/formats/csvs.py:261\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/io/formats/csvs.py:266\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 266\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/io/formats/csvs.py:304\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/io/formats/csvs.py:315\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    312\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[1;32m    314\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 315\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/pandas/_libs/writers.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# allInOne timeseries for chain-size statistics\n",
    "group = 'bug'\n",
    "geometry = 'biaxial'\n",
    "ensAvg_path = \"/Users/amirhsi_mini/analysis/N2000D30.0ac4.0-bug-ensAvg\"\n",
    "ensAvgs = []\n",
    "for property_measure in bug_properties:\n",
    "    ensAvg = organizer.all_in_one_tseries(\n",
    "        ensAvg_path,\n",
    "        property_measure,\n",
    "        group = group,\n",
    "        geometry = geometry,\n",
    "        save_to = None\n",
    "    )\n",
    "    ensAvgs.append(ensAvg)\n",
    "ensAvgs = pd.concat(ensAvgs,axis=1)\n",
    "# drop duplicated columns:\n",
    "ensAvgs = ensAvgs.loc[:,~ensAvgs.columns.duplicated()]\n",
    "output_name = database + \"allInOne-bug-chainSize.csv\"\n",
    "ensAvgs.to_csv(output_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all in one timeseries for chain-size acf statistics\n",
    "group = 'bug'\n",
    "geometry = 'biaxial'\n",
    "ensAvg_path = \"/Users/amirhsi_mini/analysis/N2000D30.0ac4.0-bug-ensAvg\"\n",
    "ensAvgs = list()\n",
    "for property_measure in bug_property_acfs:\n",
    "    ensAvg = organizer.all_in_one_tseries(\n",
    "        ensAvg_path,\n",
    "        property_measure,\n",
    "        group = group,\n",
    "        geometry = geometry,\n",
    "        save_to = None\n",
    "    )\n",
    "    ensAvgs.append(ensAvg)\n",
    "ensAvgs = pd.concat(ensAvgs,axis=1)\n",
    "# drop duplicated columns:\n",
    "ensAvgs = ensAvgs.loc[:,~ensAvgs.columns.duplicated()]\n",
    "output_name = database + \"allInOne-bug-chainSize-acf.csv\"\n",
    "ensAvgs.to_csv(output_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parallel version has memory leak issue.\n",
    "%%time\n",
    "# This has memory leaking issue\n",
    "group = 'bug'\n",
    "geometry = 'biaxial'\n",
    "ensAvg_path = \"/Users/amirhsi_mini/analysis/N2000D30.0ac4.0-bug-ensAvg\"\n",
    "all_in_one_computed = []\n",
    "for property_measure in bug_property_measures:\n",
    "    all_in_one_delayed = delayed(organizer.all_in_one_tseries)(\n",
    "        ensAvg_path,\n",
    "        property_measure,\n",
    "        group = group,\n",
    "        geometry = geometry,\n",
    "        save_to = database\n",
    "    )\n",
    "    all_in_one_computed.append(all_in_one_delayed)\n",
    "_ = compute(all_in_one_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist_paths = glob('/Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1*')\n",
    "hist_paths = glob('/Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1*')\n",
    "species = 'Crd'\n",
    "direction = 'z'\n",
    "geometry='biaxial'\n",
    "group='all'\n",
    "segments = organizer.sort_filenames(\n",
    "                hist_paths,\n",
    "                fmts=['-' + direction + 'Hist' + species + '.npy']\n",
    "            )\n",
    "edge_segments = organizer.sort_filenames(\n",
    "                hist_paths,\n",
    "                fmts=['-' + direction + 'Edge' + species + '.npy']\n",
    "            )\n",
    "wholes = organizer.whole(\n",
    "                direction + 'Hist' + species,\n",
    "                segments,\n",
    "                geometry=geometry,\n",
    "                group=group,\n",
    "                relation='histogram',\n",
    "                save_to=None\n",
    "            )\n",
    "edge_wholes = organizer.whole(\n",
    "                direction + 'Edge' + species,\n",
    "                edge_segments,\n",
    "                geometry=geometry,\n",
    "                group=group,\n",
    "                relation='bin_edge',\n",
    "                save_to=None\n",
    "            )\n",
    "            # 'whole' dataframes, each with a 'whole' columns.\n",
    "rho_wholes, phi_wholes = distributions.distributions_generator(\n",
    "                wholes,\n",
    "                edge_wholes,\n",
    "                group,\n",
    "                species,\n",
    "                geometry,\n",
    "                direction,\n",
    "                save_to=None,\n",
    "normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_wholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'][:-1],edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'],weights=wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'],histtype='step',density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'][:-1],bins=edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'],weights=wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1,ncols=1,sharex=True,figsize=(8,6))\n",
    "centers = 0.5*(edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'][:-1]+edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'][1:])\n",
    "hist_df = pd.DataFrame(wholes)\n",
    "rho_df = pd.DataFrame(rho_wholes)\n",
    "phi_df = pd.DataFrame(phi_wholes)\n",
    "df = pd.concat([hist_df,rho_df,phi_df],axis=1)\n",
    "df.columns = ['histogram','number_density','volume_fraction']\n",
    "df['center'] = centers\n",
    "#df['histogram'] = df['histogram'] / df['histogram'].sum()\n",
    "df['fake']= 1\n",
    "#df.set_index('center',inplace=True)\n",
    "#sns.histplot(x='center',bins=edge_wholes['N500epsilon5.0r5.5lz205.5sig0.8nc48047dt0.002bdump1000adump5000ens1'] ,weights='volume_fraction',data=df,element='poly',fill=False, kde=True)\n",
    "#plt.show()\n",
    "#df['histogram'].plot(ax=axes,ylabel='histogram')\n",
    "#sns.set_theme(style=\"whitegrid\")\n",
    "#sns.set(font_scale=1.2)\n",
    "sns.axes_style(\"darkgrid\")\n",
    "sns.lineplot(x='center',y='histogram', data=df,ax=axes)\n",
    "#df.loc[-200:200,'number_density'].plot(ax=axes[1],ylabel='number_density')\n",
    "#df.loc[-200:200,'volume_fraction'].plot(ax=axes[2],ylabel='volume_fraction',xlabel='center')\n",
    "#axes.grid()\n",
    "#axes.set_xlim(df.index[0]-5, df.index[-1]+5)\n",
    "#axes.axvline(df.loc[df.index[0],'center'],lw=0.5,c='red',label='left end')\n",
    "#axes.axvline(df.loc[df.index[-1],'center'],lw=0.5,c='green',label='right end')\n",
    "#axes.axvline(df['center'],lw=0.5,c='red')\n",
    "axes.set_xlabel('z (a.u.)')\n",
    "axes.set_ylabel('Freqency of type-1 particles')\n",
    "#ax.set_xlim[]\n",
    "plt.savefig('histogram.pdf',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['center'][-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name = 'N500epsilon5.0r5.5lz205.5sig0.8nc36036dt0.002bdump1000adump5000ens1'\n",
    "hist_info = SumRule(name, geometry='biaxial', group='all', lineage='whole')\n",
    "dist_new = distributions.Distribution(\n",
    "    wholes[name],\n",
    "    edges[name],\n",
    "    hist_info,\n",
    "    'dcrowd',\n",
    "    geometry='biaxial',\n",
    "    direction='z',\n",
    "    normalized=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whole_from_Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_database = '/Users/amirhsi_mini/probe/N500D10.0ac0.8-segment'\n",
    "geometry = 'biaxial'\n",
    "hierarchy = '/N*/N*'\n",
    "lineage = 'segment'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "#save_to = analyzer.database_path(input_database, phase='analysis', stage='wholeSim', group=group)\n",
    "#analyzer.analyze_segments(input_database, geometry, hierarchy)\n",
    "analyzer.analyze_wholes(input_database, geometry, hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "client = Client(n_workers=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script is used in GNU-Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PipeLine import *\n",
    "\n",
    "fname = glob(\"../N*.bug.*\")\n",
    "fname = PipeLine.file_reader(fname) # This is a list with one member\n",
    "\n",
    "save_to=\"./\"\n",
    "geom = 'cylindrical'\n",
    "print(fname)\n",
    "PipeLine.extract_trj_bug(fname[0], geom, save_to) # A list with one member, the member is a tuple of a trj and data pair.\n",
    "#PipeLine.bug_trj_rmsd(fname[0], geom, save_to) \n",
    "\n",
    "trj_files = glob(\"./N*all.lammpstrj\")\n",
    "all_tuples = PipeLine.file_reader(trj_files,extensions=['lammpstrj'])\n",
    "all_trjs = [all_tuple[0] for all_tuple in all_tuples]\n",
    "\n",
    "data_file = glob(\"./N*.all.data\")\n",
    "all_data = PipeLine.file_reader(data_file,extensions=['all.data'])\n",
    "all_data = all_data[0][0]\n",
    "\n",
    "    \n",
    "for all_trj in all_trjs:\n",
    "    print(all_trj)\n",
    "    PipeLine.extract_trj_all(all_data, all_trj, geom, save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard approach: Running on clusters: extraction from orgaznied *trjs_all* and *trjs_bug* directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This are not work properly on Graham cluster but work well on iMacmini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract from an organized *trjs_bug* directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script extract different bug's information from pairs (toplogy and trajectory) of bug simulation files in oen or more organized *trjs_bug* directories.\n",
    "from pathlib import Path\n",
    "import os\n",
    "from glob import glob\n",
    "from PipeLine import *\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "\n",
    "cores = 32\n",
    "print(f\"number of workers set to {cores}; is this the same requested cores on the cluster?\")\n",
    "client = Client(n_workers=cores)\n",
    "home = str(Path.home())\n",
    "cwdir = str(Path.cwd())\n",
    "# information extraction from simulations\n",
    "geom = 'cylindrical'\n",
    "fname = glob(home+'/amirhsi_rrg/cylinder_simulations/N*-trjs_bug/N*bug*')\n",
    "bug_pairs = PipeLine.file_reader(fname) # each bug_pair is a pair of trajectory and topopgy file.\n",
    "trjs_computed = []\n",
    "bug_dir = 'extraction_bug/'\n",
    "for bug_pair in bug_pairs:\n",
    "    sim_name = bug_pair[0].split(\"/\")[-1].split('bug')[0]\n",
    "    sim_dir = cwdir+bug_dir+sim_name\n",
    "    Path(sim_dir).mkdir(parents=True, exist_ok=False)\n",
    "    sim_save_to = sim_dir+\"/\"\n",
    "    trj_delayed = delayed(PipeLine.extract_trj_bug)(bug_pair, geom,sim_save_to)\n",
    "    trjs_computed.append(trj_delayed)\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract from an organized *trjs_all* directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script extract different bug's information from pairs (toplogy and trajectory) of bug simulation files in oen or more organized *trjs_bug* directories.\n",
    "from pathlib import Path\n",
    "import os\n",
    "from glob import glob\n",
    "from PipeLine import *\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "\n",
    "cores = 32\n",
    "print(f\"number of workers set to {cores}; is this the same requested cores on the cluster?\")\n",
    "client = Client(n_workers=cores)\n",
    "home = str(Path.home())\n",
    "cwdir = str(Path.cwd())\n",
    "sim_all_dirs = glob(home+'/amirhsi_rrg/cylinder_simulations/N*-trjs_all/N*/')\n",
    "geom = 'cylindrical'\n",
    "\n",
    "trjs_computed = []\n",
    "all_extraction_dir = 'extraction_all/'\n",
    "for sim_all_dir in sim_all_dirs:\n",
    "    sim_name = sim_all_dir[0].split(\"/\")[-1]\n",
    "    all_trjs = glob(sim_all_dir+\"N*.lammpstrj\")\n",
    "    all_trjs = PipeLine.file_reader(all_trjs,extensions=['lammpstrj'])\n",
    "    all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "\n",
    "    all_topology = glob(sim_all_dir+\"N*.all.data\")\n",
    "    all_topology = PipeLine.file_reader(all_topology,extensions=['all.data'])\n",
    "    all_topology = all_topology[0][0]\n",
    "    \n",
    "    \n",
    "    sim_extract_dir = cwdir+all_extraction_dir+sim_name\n",
    "    Path(sim_extract_dir).mkdir(parents=True, exist_ok=False)\n",
    "    sim_save_to = sim_extract_dir+\"/\"\n",
    "    \n",
    "    for all_trj in all_trjs:\n",
    "        trj_delayed = delayed(PipeLine.extract_trj_all)(all_topology, all_trj, geom,sim_save_To)\n",
    "        trjs_computed.append(trj_delayed)\n",
    "\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction from *extraction_bug* directory after a simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = str(Path.home())\n",
    "path=home+'N2000epsilon5.0r10.5lz336sig1.0nc100800dt0.005bdump1000adump5000ens1'\n",
    "fname = glob(path+\"/N*.bug.*\")\n",
    "fname = PipeLine.file_reader(fname) # This is a list with one member\n",
    "geom = 'cylindrical'\n",
    "print(fname)\n",
    "PipeLine.extract_trj_bug(fname[0], geom) # A list with one member, the member is a tuple of a trj and data pair.\n",
    "PipeLine.rmsd_trj_bug(fname[0], geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the segments in one trajectory: M dump files + one data file.\n",
    "path='/Users/amirhsi_mini/N2000epsilon5.0r10.5lz336sig1.0nc100800dt0.005bdump1000adump5000ens*'\n",
    "geom = 'cylindrical'\n",
    "trj_files = glob(path+\"/N*.lammpstrj\")\n",
    "all_tuples = PipeLine.file_reader(trj_files,extensions=['lammpstrj',])\n",
    "all_trjs = [all_tuple[0] for all_tuple in all_tuples]\n",
    "data_file = glob(path+\"/N*.all.data\")\n",
    "all_data = PipeLine.file_reader(data_file,extensions=['all.data'])\n",
    "all_data = all_data[0][0]\n",
    "for all_trj in all_trjs:\n",
    "    PipeLine.extract_trj_all(all_data, all_trj, geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New approach: tested on iMac Pro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single ensemble with one or more segments with one data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/amirhsi_mini/N2000epsilon5.0r15.5lz379.5sig6.0nc1068dt0.005bdump1000adump5000ens*'\n",
    "#path='/Users/amirhsi_mini/N1000epsilon5.0r8.0lz308.5sig2.0nc10412dt0.005bdump1000adump5000ens*'\n",
    "geom = 'cylindrical'\n",
    "trj_files = glob(path+\"/N*all*\")\n",
    "all_pairs = PipeLine.file_reader(trj_files)\n",
    "trjs_computed = []\n",
    "for all_pair in all_pairs:\n",
    "    trj_delayed = delayed(PipeLine.extract_all_trj_polymer_cog_fsd)(all_pair[1], all_pair[0], geom)\n",
    "    trjs_computed.append(trj_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N ensemble with N data file, each ensemble with one or more segments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/amirhsi_mini/N2000epsilon5.0r15.5lz379.5sig6.0nc1068dt0.005bdump1000adump5000ens*'\n",
    "#path='/Users/amirhsi_mini/N1000epsilon5.0r8.0lz308.5sig2.0nc10412dt0.005bdump1000adump5000ens*'\n",
    "geom = 'cylindrical'\n",
    "trj_pathes = glob(path+\"/N*all*\")\n",
    "trjs = PipeLine.file_reader(trj_pathes,extensions=['lammpstrj'])\n",
    "trjs = [trj[0] for trj in trjs]\n",
    "topology_pathes = glob(path+\"/N*.all.data\")\n",
    "topologies = PipeLine.file_reader(topology_pathes,extensions=['all.data'])\n",
    "topologies = [topology[0] for topology in topologies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(pair):\n",
    "    \"\"\"\n",
    "    simulation_pair pairs an \"all\" topology file with all the \"all\" trjectories of that \"all\" topology.\n",
    "    \n",
    "    Parameters:\n",
    "    pair (list of tuples): a list in whic each tuple is  pair of topolgy and trajectories of a simulations.\n",
    "    \n",
    "    Return:\n",
    "    a dict of of simulation pairs.\n",
    "    \"\"\"\n",
    "    return {'topology':pair[0], 'trajectories':pair[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_names = [topology.split(\"/\")[-1].split('.all')[0] for topology in topologies]\n",
    "ens_names = list(dict.fromkeys(ens_names))\n",
    "trjs_per_ens = []\n",
    "for ens_name in ens_names:\n",
    "    ens_trjs = []\n",
    "    for trj in trjs:\n",
    "        trj_name = trj.split(\"/\")[-1].split(\".all\")[0]\n",
    "        if trj_name == ens_name:\n",
    "            ens_trjs.append(trj)\n",
    "            #ensembles[key]['trajectories'] = trj\n",
    "    trjs_per_ens.append(ens_trjs)\n",
    "ensembles= dict(zip(ens_names,list(map(simulation,list(zip(topologies,trjs_per_ens))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = 'cylindrical'\n",
    "trjs_computed = []\n",
    "for ensemble in ensembles.values():\n",
    "    for trj_segment in ensemble['trajectories']:\n",
    "        trj_delayed = delayed(PipeLine.extract_trj_all)(ensemble['topology'], trj_segment, geom)\n",
    "        trjs_computed.append(trj_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = compute(trjs_computed)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_v4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
