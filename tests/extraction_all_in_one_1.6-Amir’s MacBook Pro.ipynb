{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_CLXSgvVO_9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirhsi_mini/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n",
      "/Users/amirhsi_mini/opt/anaconda3/envs/polyLab/lib/python3.9/site-packages/MDAnalysis/coordinates/TRJ.py:1209: DeprecationWarning: Please use `netcdf_file` from the `scipy.io` namespace, the `scipy.io.netcdf` namespace is deprecated.\n",
      "  class NCDFPicklable(scipy.io.netcdf.netcdf_file):\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import SumRule\n",
    "from polyphys.probe import prober\n",
    "from polyphys.analyze import analyzer\n",
    "from polyphys.analyze import distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test probe bug on pc:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trj segments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '//Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/test_data/probe/N500D10.0ac0.8-segment'\n",
      "Directory '//Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/test_data/probe/N500D10.0ac0.8-segment' exist. Files are saved/overwritten to an existing directory.\n",
      "/Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/test_data/trjs-continuous/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.bug.data\n",
      "[Errno 17] File exists: '//Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/test_data/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1'\n",
      "Directory '//Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/test_data/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1' exist. Files are saved/overwritten to an existing directoy.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j01-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j02-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j03-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j04-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j05-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j06-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j07-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j08-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j09-bug is analyzing...\n",
      "\n",
      "done.\n",
      "lineage is 'segment' and 'continuous' is 'False. Please ensure the '/Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/test_data/trjs-continuous/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j10.bug.lammpstrj' is NOT part of a sequence of trjectories.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.j10-bug is analyzing...\n",
      "\n",
      "done.\n",
      "/Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/test_data/trjs-continuous/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.bug.data\n",
      "[Errno 17] File exists: '//Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/test_data/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2'\n",
      "Directory '//Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/test_data/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2' exist. Files are saved/overwritten to an existing directoy.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j01-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j02-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j03-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j04-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j05-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j06-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j07-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j08-bug is analyzing...\n",
      "\n",
      "done.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j09-bug is analyzing...\n",
      "\n",
      "done.\n",
      "lineage is 'segment' and 'continuous' is 'False. Please ensure the '/Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/test_data/trjs-continuous/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j10.bug.lammpstrj' is NOT part of a sequence of trjectories.\n",
      "Setting the name of analyze file...\n",
      "\n",
      "N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens2.j10-bug is analyzing...\n",
      "\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "## This approach from HERE\n",
    "path = pathlib.Path('../test_data/trjs-continuous/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "## to HERE, does not work of * is used in the string input for Path.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.bug.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.bug.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "for topology in topologies:\n",
    "    print(topology[0])\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            if trj_info.segment_id ==10:\n",
    "                prober.probe_bug(topology[0], trajectory[0], geometry, 'segment', save_to_whole)\n",
    "            else:\n",
    "                prober.probe_bug(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trjs whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment'\n",
      "Directory '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment' exist. Files are saved/overwritten to an existing directory.\n",
      "/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.bug.data\n",
      "[Errno 17] File exists: '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1'\n",
      "Directory '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1' exist. Files are saved/overwritten to an existing directoy.\n",
      "('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc12012dt0.002bdump1000adump5000ens1.bug.lammpstrj',)\n",
      "/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc36036dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc36036dt0.002bdump1000adump5000ens1.bug.data\n",
      "[Errno 17] File exists: '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc36036dt0.002bdump1000adump5000ens1'\n",
      "Directory '//Users/amirhsi_mini/probe/N500D10.0ac0.8-segment/N500epsilon5.0r5.5lz205.5sig0.8nc36036dt0.002bdump1000adump5000ens1' exist. Files are saved/overwritten to an existing directoy.\n",
      "('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs/N500epsilon5.0r5.5lz205.5sig0.8nc36036dt0.002bdump1000adump5000ens1/N500epsilon5.0r5.5lz205.5sig0.8nc36036dt0.002bdump1000adump5000ens1.bug.lammpstrj',)\n"
     ]
    }
   ],
   "source": [
    "## This approach from HERE\n",
    "path = pathlib.Path('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "## to HERE, does not work of * is used in the string input for Path.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.bug.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.bug.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "for topology in topologies:\n",
    "    print(topology[0])\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='whole')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            print(trajectory)\n",
    "            #prober.probe_bug(topology[0], trajectory[0], geometry, 'whole', save_to_whole, continuous=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check probe all trj segments on pc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path('../test_data/trjs-continuous/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.all.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.all.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "for topology in topologies:\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.segment_id ==10:\n",
    "            prober.probe_all(topology[0], trajectory[0], geometry, 'segment', save_to_whole)\n",
    "        else:\n",
    "            prober.probe_all(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '../test_data/analysis/N500D10.0ac0.8-bug-wholeSim'\n",
      "Directory '../test_data/analysis/N500D10.0ac0.8-bug-wholeSim' exist. Files are saved/overwritten to an existing directory.\n",
      "[Errno 17] File exists: '../test_data/analysis/N500D10.0ac0.8-all-wholeSim'\n",
      "Directory '../test_data/analysis/N500D10.0ac0.8-all-wholeSim' exist. Files are saved/overwritten to an existing directory.\n",
      "[Errno 17] File exists: '../test_data/analysis/N500D10.0ac0.8-all-wholeSim'\n",
      "Directory '../test_data/analysis/N500D10.0ac0.8-all-wholeSim' exist. Files are saved/overwritten to an existing directory.\n"
     ]
    }
   ],
   "source": [
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "geometry = 'biaxial'\n",
    "phase = 'analysis'\n",
    "stage = 'wholeSim'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "relation = 'tseries'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "observations = organizer.sort_filenames(observations, fmts=['bug-gyrTMon.npy'])\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "gyr_wholes = organizer.whole('gyrTMon', observations, geometry=geometry, group=group, relation=relation, save_to=save_to)\n",
    "\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "geometry = 'biaxial'\n",
    "phase = 'analysis'\n",
    "stage = 'wholeSim'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "relation = 'histogram'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "observations = organizer.sort_filenames(observations, fmts=['-all-rHistMon.npy'])\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "rhist_wholes = organizer.whole('rHistMon', observations, geometry=geometry, group=group, relation=relation, save_to=save_to)\n",
    "\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "geometry = 'biaxial'\n",
    "phase = 'analysis'\n",
    "stage = 'wholeSim'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "relation = 'bin_edge'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "observations = organizer.sort_filenames(observations, fmts=['-all-rEdgeMon.npy'])\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "redge_wholes = organizer.whole('rEdgeMon', observations, geometry=geometry, group=group, relation=relation, save_to=save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '../test_data/analysis/N500D10.0ac0.8-bug-ens'\n",
      "Directory '../test_data/analysis/N500D10.0ac0.8-bug-ens' exist. Files are saved/overwritten to an existing directory.\n",
      "[Errno 17] File exists: '../test_data/analysis/N500D10.0ac0.8-all-ens'\n",
      "Directory '../test_data/analysis/N500D10.0ac0.8-all-ens' exist. Files are saved/overwritten to an existing directory.\n"
     ]
    }
   ],
   "source": [
    "group = 'bug'\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "phase = 'analysis'\n",
    "stage = 'ens'\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "gyr_ens = organizer.ensemble(\n",
    "    'gyrTMon',\n",
    "    gyr_wholes,\n",
    "    group=group,\n",
    "    edge_wholes=None,\n",
    "    save_to=save_to)\n",
    "group = 'all'\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "phase = 'analysis'\n",
    "stage = 'ens'\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "rhist_ens = organizer.ensemble(\n",
    "    'rHistMon',\n",
    "    rhist_wholes,\n",
    "    group=group,\n",
    "    edge_wholes=redge_wholes,\n",
    "    save_to=save_to)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '../test_data/analysis/N500D10.0ac0.8-bug-ensAvg'\n",
      "Directory '../test_data/analysis/N500D10.0ac0.8-bug-ensAvg' exist. Files are saved/overwritten to an existing directory.\n",
      "[Errno 17] File exists: '../test_data/analysis/N500D10.0ac0.8-all-ensAvg'\n",
      "Directory '../test_data/analysis/N500D10.0ac0.8-all-ensAvg' exist. Files are saved/overwritten to an existing directory.\n"
     ]
    }
   ],
   "source": [
    "group = 'bug'\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "phase = 'analysis'\n",
    "stage = 'ensAvg'\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "gyr_ens_avg = analyzer.ensemble_avg(\n",
    "    'gyrTMon',\n",
    "    gyr_ens,\n",
    "    group=group,\n",
    "    save_to=save_to)\n",
    "group = 'all'\n",
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "phase = 'analysis'\n",
    "stage = 'ensAvg'\n",
    "save_to = analyzer.database_path(input_database, phase=phase, stage=stage, group=group)\n",
    "rhist_ens_avg = analyzer.ensemble_avg(\n",
    "    'rHistMon',\n",
    "    rhist_ens,\n",
    "    group=group,\n",
    "    exclude=['bin_center'],\n",
    "    save_to=save_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gyr_ens_avg['N500D10.0ac0.8nc12012'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhist_ens['N500D10.0ac0.8nc12012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./N2000D20.0ac2.0nc15120.0-rPhisMon.csv', './N2000D20.0ac2.0nc15120.0-rRhosMon.csv', './N2000D20.0ac2.0nc15120.0-rHistsCrd.csv', './N2000D20.0ac2.0nc15120.0-rRhosCrd.csv', './N2000D20.0ac2.0nc15120.0-rHistsMon.csv', './N2000D20.0ac2.0nc15120.0-rPhisCrd.csv', './N2000epsilon5.0r10.5lz504sig2.0nc15120dt0.005bdump1000adump5000ens1-rEdges.csv']\n",
      "./N2000D20.0ac2.0nc15120.0-rPhisMon.csv\n"
     ]
    }
   ],
   "source": [
    "ens = glob(\"./N2000*.csv\")\n",
    "print(ens)\n",
    "print(ens[0])\n",
    "rhist_crd= pd.read_csv('./N2000D20.0ac2.0nc15120.0-rHistsCrd.csv', header=0)\n",
    "rhist_crd.rename(columns={\"Unnamed: 0\":\"bin_center\"}, inplace=True)\n",
    "edge = np.loadtxt('./N2000epsilon5.0r10.5lz504sig2.0nc15120dt0.005bdump1000adump5000ens1-rEdges.csv')\n",
    "wholes = {}\n",
    "edges = {}\n",
    "for col in rhist_crd.columns:\n",
    "    if col!='bin_center' :\n",
    "        wholes[col] = rhist_crd[col].values\n",
    "        edges[col] = edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### whole_from_Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_database = '../test_data/probe/N500D10.0ac0.8-segment'\n",
    "geometry = 'biaxial'\n",
    "hierarchy = '/N*/N*'\n",
    "lineage = 'segment'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "#save_to = analyzer.database_path(input_database, phase='analysis', stage='wholeSim', group=group)\n",
    "analyzer.analyze_segments(input_database, geometry, hierarchy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "client = Client(n_workers=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script is used in GNU-Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PipeLine import *\n",
    "\n",
    "fname = glob(\"../N*.bug.*\")\n",
    "fname = PipeLine.file_reader(fname) # This is a list with one member\n",
    "\n",
    "save_to=\"./\"\n",
    "geom = 'cylindrical'\n",
    "print(fname)\n",
    "PipeLine.extract_trj_bug(fname[0], geom, save_to) # A list with one member, the member is a tuple of a trj and data pair.\n",
    "#PipeLine.bug_trj_rmsd(fname[0], geom, save_to) \n",
    "\n",
    "trj_files = glob(\"./N*all.lammpstrj\")\n",
    "all_tuples = PipeLine.file_reader(trj_files,extensions=['lammpstrj'])\n",
    "all_trjs = [all_tuple[0] for all_tuple in all_tuples]\n",
    "\n",
    "data_file = glob(\"./N*.all.data\")\n",
    "all_data = PipeLine.file_reader(data_file,extensions=['all.data'])\n",
    "all_data = all_data[0][0]\n",
    "\n",
    "    \n",
    "for all_trj in all_trjs:\n",
    "    print(all_trj)\n",
    "    PipeLine.extract_trj_all(all_data, all_trj, geom, save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard approach: Running on clusters: extraction from orgaznied *trjs_all* and *trjs_bug* directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This are not work properly on Graham cluster but work well on iMacmini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract from an organized *trjs_bug* directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script extract different bug's information from pairs (toplogy and trajectory) of bug simulation files in oen or more organized *trjs_bug* directories.\n",
    "from pathlib import Path\n",
    "import os\n",
    "from glob import glob\n",
    "from PipeLine import *\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "\n",
    "cores = 32\n",
    "print(f\"number of workers set to {cores}; is this the same requested cores on the cluster?\")\n",
    "client = Client(n_workers=cores)\n",
    "home = str(Path.home())\n",
    "cwdir = str(Path.cwd())\n",
    "# information extraction from simulations\n",
    "geom = 'cylindrical'\n",
    "fname = glob(home+'/amirhsi_rrg/cylinder_simulations/N*-trjs_bug/N*bug*')\n",
    "bug_pairs = PipeLine.file_reader(fname) # each bug_pair is a pair of trajectory and topopgy file.\n",
    "trjs_computed = []\n",
    "bug_dir = 'extraction_bug/'\n",
    "for bug_pair in bug_pairs:\n",
    "    sim_name = bug_pair[0].split(\"/\")[-1].split('bug')[0]\n",
    "    sim_dir = cwdir+bug_dir+sim_name\n",
    "    Path(sim_dir).mkdir(parents=True, exist_ok=False)\n",
    "    sim_save_to = sim_dir+\"/\"\n",
    "    trj_delayed = delayed(PipeLine.extract_trj_bug)(bug_pair, geom,sim_save_to)\n",
    "    trjs_computed.append(trj_delayed)\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract from an organized *trjs_all* directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script extract different bug's information from pairs (toplogy and trajectory) of bug simulation files in oen or more organized *trjs_bug* directories.\n",
    "from pathlib import Path\n",
    "import os\n",
    "from glob import glob\n",
    "from PipeLine import *\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "\n",
    "cores = 32\n",
    "print(f\"number of workers set to {cores}; is this the same requested cores on the cluster?\")\n",
    "client = Client(n_workers=cores)\n",
    "home = str(Path.home())\n",
    "cwdir = str(Path.cwd())\n",
    "sim_all_dirs = glob(home+'/amirhsi_rrg/cylinder_simulations/N*-trjs_all/N*/')\n",
    "geom = 'cylindrical'\n",
    "\n",
    "trjs_computed = []\n",
    "all_extraction_dir = 'extraction_all/'\n",
    "for sim_all_dir in sim_all_dirs:\n",
    "    sim_name = sim_all_dir[0].split(\"/\")[-1]\n",
    "    all_trjs = glob(sim_all_dir+\"N*.lammpstrj\")\n",
    "    all_trjs = PipeLine.file_reader(all_trjs,extensions=['lammpstrj'])\n",
    "    all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "\n",
    "    all_topology = glob(sim_all_dir+\"N*.all.data\")\n",
    "    all_topology = PipeLine.file_reader(all_topology,extensions=['all.data'])\n",
    "    all_topology = all_topology[0][0]\n",
    "    \n",
    "    \n",
    "    sim_extract_dir = cwdir+all_extraction_dir+sim_name\n",
    "    Path(sim_extract_dir).mkdir(parents=True, exist_ok=False)\n",
    "    sim_save_to = sim_extract_dir+\"/\"\n",
    "    \n",
    "    for all_trj in all_trjs:\n",
    "        trj_delayed = delayed(PipeLine.extract_trj_all)(all_topology, all_trj, geom,sim_save_To)\n",
    "        trjs_computed.append(trj_delayed)\n",
    "\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction from *extraction_bug* directory after a simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = str(Path.home())\n",
    "path=home+'N2000epsilon5.0r10.5lz336sig1.0nc100800dt0.005bdump1000adump5000ens1'\n",
    "fname = glob(path+\"/N*.bug.*\")\n",
    "fname = PipeLine.file_reader(fname) # This is a list with one member\n",
    "geom = 'cylindrical'\n",
    "print(fname)\n",
    "PipeLine.extract_trj_bug(fname[0], geom) # A list with one member, the member is a tuple of a trj and data pair.\n",
    "PipeLine.rmsd_trj_bug(fname[0], geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the segments in one trajectory: M dump files + one data file.\n",
    "path='/Users/amirhsi_mini/N2000epsilon5.0r10.5lz336sig1.0nc100800dt0.005bdump1000adump5000ens*'\n",
    "geom = 'cylindrical'\n",
    "trj_files = glob(path+\"/N*.lammpstrj\")\n",
    "all_tuples = PipeLine.file_reader(trj_files,extensions=['lammpstrj',])\n",
    "all_trjs = [all_tuple[0] for all_tuple in all_tuples]\n",
    "data_file = glob(path+\"/N*.all.data\")\n",
    "all_data = PipeLine.file_reader(data_file,extensions=['all.data'])\n",
    "all_data = all_data[0][0]\n",
    "for all_trj in all_trjs:\n",
    "    PipeLine.extract_trj_all(all_data, all_trj, geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New approach: tested on iMac Pro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A single ensemble with one or more segments with one data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/amirhsi_mini/N2000epsilon5.0r15.5lz379.5sig6.0nc1068dt0.005bdump1000adump5000ens*'\n",
    "#path='/Users/amirhsi_mini/N1000epsilon5.0r8.0lz308.5sig2.0nc10412dt0.005bdump1000adump5000ens*'\n",
    "geom = 'cylindrical'\n",
    "trj_files = glob(path+\"/N*all*\")\n",
    "all_pairs = PipeLine.file_reader(trj_files)\n",
    "trjs_computed = []\n",
    "for all_pair in all_pairs:\n",
    "    trj_delayed = delayed(PipeLine.extract_all_trj_polymer_cog_fsd)(all_pair[1], all_pair[0], geom)\n",
    "    trjs_computed.append(trj_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N ensemble with N data file, each ensemble with one or more segments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/amirhsi_mini/N2000epsilon5.0r15.5lz379.5sig6.0nc1068dt0.005bdump1000adump5000ens*'\n",
    "#path='/Users/amirhsi_mini/N1000epsilon5.0r8.0lz308.5sig2.0nc10412dt0.005bdump1000adump5000ens*'\n",
    "geom = 'cylindrical'\n",
    "trj_pathes = glob(path+\"/N*all*\")\n",
    "trjs = PipeLine.file_reader(trj_pathes,extensions=['lammpstrj'])\n",
    "trjs = [trj[0] for trj in trjs]\n",
    "topology_pathes = glob(path+\"/N*.all.data\")\n",
    "topologies = PipeLine.file_reader(topology_pathes,extensions=['all.data'])\n",
    "topologies = [topology[0] for topology in topologies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation(pair):\n",
    "    \"\"\"\n",
    "    simulation_pair pairs an \"all\" topology file with all the \"all\" trjectories of that \"all\" topology.\n",
    "    \n",
    "    Parameters:\n",
    "    pair (list of tuples): a list in whic each tuple is  pair of topolgy and trajectories of a simulations.\n",
    "    \n",
    "    Return:\n",
    "    a dict of of simulation pairs.\n",
    "    \"\"\"\n",
    "    return {'topology':pair[0], 'trajectories':pair[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_names = [topology.split(\"/\")[-1].split('.all')[0] for topology in topologies]\n",
    "ens_names = list(dict.fromkeys(ens_names))\n",
    "trjs_per_ens = []\n",
    "for ens_name in ens_names:\n",
    "    ens_trjs = []\n",
    "    for trj in trjs:\n",
    "        trj_name = trj.split(\"/\")[-1].split(\".all\")[0]\n",
    "        if trj_name == ens_name:\n",
    "            ens_trjs.append(trj)\n",
    "            #ensembles[key]['trajectories'] = trj\n",
    "    trjs_per_ens.append(ens_trjs)\n",
    "ensembles= dict(zip(ens_names,list(map(simulation,list(zip(topologies,trjs_per_ens))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = 'cylindrical'\n",
    "trjs_computed = []\n",
    "for ensemble in ensembles.values():\n",
    "    for trj_segment in ensemble['trajectories']:\n",
    "        trj_delayed = delayed(PipeLine.extract_trj_all)(ensemble['topology'], trj_segment, geom)\n",
    "        trjs_computed.append(trj_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = compute(trjs_computed)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_v4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
