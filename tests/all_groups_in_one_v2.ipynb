{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922ca2c-02a9-4be1-8c28-ad36c4d47dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PipeLine import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "import statsmodels.tsa.stattools as tsas\n",
    "import statsmodels.graphics.tsaplots as tsap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adace0c-0e1b-4993-9cfc-8d2dbffce80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_in_one_attributes(\n",
    "                    attr_path, attr_name, properties_db, simulation_type,\n",
    "                    geometry, direction=None, save_to=True):\n",
    "    \"\"\"takes ensemble-averaged data of a given attribute and performs the \\\n",
    "    following operations on them: First, it concatenates the \\\n",
    "    ensemble-averaged files into one dataframe and adds the properties of \\\n",
    "    the ensemble to the merged files. Finally, it combines all the \\\n",
    "    ensembles from all the groups into one dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    attr_path (str): path to the the files of theattribute of interest.\n",
    "    attr_name (str): name of the attribute of interest.\n",
    "    properties_db (Pandas dataframe): The database of ensemble-average \\\n",
    "    properties.\n",
    "    simulation_type (str): the type of particles for which the analysis is \\\n",
    "    one. For now, it is either 'all' or 'bug'. 'all' means all the species \\\n",
    "    in the system. 'bug' means the whole polymeric chain.\n",
    "    geometry (str): Geomtery of the simulation box.\n",
    "    direction (str): Direction along which the distributions are computed.\n",
    "    save_to (str): address to which the ensemble files of a group are saved.\n",
    "\n",
    "    Return;\n",
    "    A pandad databse in which all the dsitbrutions of all the simulation \\\n",
    "    groups are merged.\n",
    "    \"\"\"\n",
    "    attr_ext = \"-\" + attr_name + \"-ens_avg.csv\"\n",
    "    attr_csvs = glob(attr_path + \"/N*\" + attr_ext)\n",
    "    attr_csvs = organizer.sort_filenames(attr_csvs, extensions=[attr_ext])\n",
    "    properties = pd.read_csv(properties_db, index_col=0)\n",
    "    attr_db = []\n",
    "    properties[['ens_name', 'garbage']] = properties.filename.str.split(\n",
    "        pat='-', expand=True)  # find the ensemble names.\n",
    "    selected_cols = [\n",
    "        'filename', 'nmon', 'dcyl', 'dcrowd', 'phi_c_bulk', 'phi_c_bulk_eff',\n",
    "        'ens_name']\n",
    "    for attr_csv in attr_csvs:\n",
    "        attr_df = pd.read_csv(attr_csv[0], index_col=0)\n",
    "        ens_name = list(attr_df.columns)[0].split('-')[0]  # name of the file\n",
    "        cell_attrs = SumRule(ens_name, geometry, warning=False)\n",
    "\n",
    "        dist_names = [\n",
    "            'HistsCrd', 'HistsMon', 'PhisCrd', 'PhisMon', 'RhosCrd', 'RhosMon',\n",
    "            'FloryHists', 'Hists', 'Rhos', 'Phis']\n",
    "        if (direction is not None) and \\\n",
    "                (attr_name.split(direction)[-1] in dist_names):  \\\n",
    "                # a distribtuion needs the index column\n",
    "            attr_df = pd.read_csv(\n",
    "                attr_csv[0], names=[attr_name], skiprows=1, index_col=0)\n",
    "            attr_df.reset_index(inplace=True)\n",
    "            attr_df.rename(columns={'index': direction}, inplace=True)\n",
    "            bin_center_norm_box = {\n",
    "                'r': cell_attrs.dcyl,\n",
    "                'z': cell_attrs.lcyl,\n",
    "                'theta': 4 * np.pi\n",
    "                }\n",
    "            attr_df[direction+'_norm'] = \\\n",
    "                2 * attr_df[direction] / bin_center_norm_box[direction]\n",
    "            if direction != 'theta':\n",
    "                attr_df[direction+'_norm_mon'] = attr_df[direction]  \\\n",
    "                    # This should be divided by 'dmon' but this operation \\\n",
    "                # is not done since dmon = 1.0\n",
    "                attr_df[direction+'_norm_crd'] = \\\n",
    "                    attr_df[direction] / cell_attrs.dcrowd\n",
    "        else:\n",
    "            attr_df = pd.read_csv(\n",
    "                attr_csv[0], names=[attr_name], skiprows=1, index_col=0)\n",
    "            attr_df.reset_index(inplace=True)\n",
    "            attr_df.rename(columns={'index': 'time'}, inplace=True)\n",
    "            attr_df['time'] = attr_df['time'] * cell_attrs.dt\n",
    "        for col in selected_cols:\n",
    "            cond = properties['ens_name'] == ens_name\n",
    "            attr_df[col] = properties[cond][col].values[0]\n",
    "        # Defining concise name for ensembles and groups\n",
    "        attr_df['ens_name'] = f\"N{cell_attrs.nmon}D{cell_attrs.dcyl}\\\n",
    "            ac{cell_attrs.dcrowd}nc{cell_attrs.ncrowd}\"\n",
    "        attr_df['group_name'] = f\"N{cell_attrs.nmon}D{cell_attrs.dcyl}\\\n",
    "            ac{cell_attrs.dcrowd}\"\n",
    "        attr_df.drop(['filename'], axis=1, inplace=True)\n",
    "        attr_db.append(attr_df)\n",
    "    attr_db = pd.concat(attr_db)\n",
    "    attr_db.reset_index(inplace=True, drop=True)\n",
    "    if save_to:\n",
    "        attr_save_to = properties_db.split('all_in_one')[0] + \"all_in_one-\"\n",
    "        + simulation_type + attr_ext\n",
    "        attr_db.to_csv(attr_save_to)\n",
    "    return attr_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed2f5d1-d726-4ff1-99f1-881495348e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# distributions:\n",
    "database = '/Users/amirhsi_mini/analysis/'\n",
    "dist_db= database+\"/N*-all-analysis-ens_avg/N*.csv\"\n",
    "properties_db  = database+'all_in_one-properties-ens_avg-normalized.csv'\n",
    "simulation_type = 'all'\n",
    "geometry='cylindrical'\n",
    "radial_dists = PipeLine.generator_dist_all_in_one(dist_db, properties_db, simulation_type, geometry, 'radial')\n",
    "longitudinal_dists = PipeLine.generator_dist_all_in_one(dist_db, properties_db, simulation_type, geometry, 'longitudinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885f251f-a194-4d59-910e-dc6657ed76f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "client = Client(n_workers=2, threads_per_worker=1, silence_logs=1)\n",
    "client\n",
    "database = '/Users/amirhsi_mini/analysis/'\n",
    "prop_path= database+\"/N*-bug-analysis-ens_avg\"\n",
    "properties_db  = database+'all_in_one-properties-ens_avg-normalized.csv'\n",
    "simulation_type = 'bug'\n",
    "geometry='cylindrical'\n",
    "analysis_delayed = []\n",
    "attrs_dict = {'rFloryHists': 'r', 'rHists': 'r', 'zHists': 'z','thetaHists': 'theta','rPhis' : 'r',\n",
    "              'zPhis': 'z','rRhos': 'r', 'zRhos': 'z'}\n",
    "for attr, direction in attrs_dict.items():\n",
    "    analysis = delayed(PipeLine.all_in_one_properties)(prop_path, attr, properties_db, simulation_type, geometry, direction = direction)\n",
    "    analysis_delayed.append(analysis)\n",
    "results = compute(analysis_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d148ef-46be-45fc-9fda-8e8bc629c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## for a a loop with one core, it takes ~ 4 min\n",
    "## This does NOT work with more than 2 workers.\n",
    "database = '/Users/amirhsi_mini/analysis/'\n",
    "prop_path= database+\"/N*-bug-analysis-ens_avg\"\n",
    "properties_db  = database+'all_in_one-properties-ens_avg-normalized.csv'\n",
    "simulation_type = 'bug'\n",
    "geometry='cylindrical'\n",
    "#attrs_dict = {'fsd_t': None, 'gyr_t': None, 'rFlory_t': None}\n",
    "attrs_dict = {'fsd_t-acf_ci_lower': None, 'gyr_t-acf_ci_lower': None, 'rFlory_t-acf_ci_lower': None, 'fsd_t-acf_ci_upper': None, 'gyr_t-acf_ci_upper': None, 'rFlory_t-acf_ci_upper': None, 'fsd_t-acf_only': None, 'gyr_t-acf_only': None, 'rFlory_t-acf_only': None}\n",
    "for attr, direction in attrs_dict.items():\n",
    "    _ = PipeLine.all_in_one_properties(prop_path, attr, properties_db, simulation_type, geometry, direction = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb773ab7-401e-49b3-86ab-1ad5e49b353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merging_cols = ['time', 'nmon', 'dcyl', 'dcrowd', 'phi_c_bulk', 'phi_c_bulk_eff', 'ens_name', 'group_name']\n",
    "attrs_names = attrs_dict.keys() # change this to use.\n",
    "database = '/Users/amirhsi_mini/analysis/'\n",
    "file_type = 'all_in_one'\n",
    "simulation_type = 'bug'\n",
    "db_type = 'ens_avg.csv'\n",
    "dfs_to_be_merged = []\n",
    "for attr in attrs_names:\n",
    "    df_name = database + \"-\".join([file_type, simulation_type, attr, db_type])\n",
    "    df = pd.read_csv(df_name, index_col=0)\n",
    "    dfs_to_be_merged.append(df)\n",
    "df_merged = reduce(lambda  left, right: pd.merge(left, right, on=merging_cols), dfs_to_be_merged)\n",
    "df_merged.to_csv(database+\"-\".join([file_type, simulation_type, \"acf_t\", db_type]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cb4364-e6b9-4bf8-aba6-445f58db7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_dfs(attrs_names.keys, merging_cols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
