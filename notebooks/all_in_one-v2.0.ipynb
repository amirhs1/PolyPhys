{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337ba9e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# AllInOne Files\n",
    "\n",
    "### Faking nc=0 for some spaces:\n",
    "\n",
    "Faking is done at the **ens** and **ensAvg** levels (and directories) not at the **segment** and **whole** levles, so the **segment stamps** are not modified byt the **whole** and **ens** ones are modified.\n",
    "\n",
    "### To-do list\n",
    "- [x] **space_tseries** fucntion for all the timeseries in one **space**.\n",
    "- [ ] **space** fucntion for all the distributions in one **space**.\n",
    "- [ ] **all-in-one** fucntion for all the timeseries in all **space**s in a **project**.\n",
    "- [ ] **all-in-one** fucntion for all the distributions in all **space**s in a **project**.\n",
    "\n",
    "### Naming convention:\n",
    "\n",
    "This is the pattern of file or directory names:\n",
    "\n",
    "1. **whole** files: whole-group-property_[-measure][-stage][.ext]\n",
    "2. **ensemble** files: ensemble-group-property_[-measure][-stage][.ext]\n",
    "3. **ensemble_long** files: ensemble_long-group-property_[-measure][-stage][.ext]\n",
    "4. **space** files: space-group-property_[-measure][-stage][.ext]\n",
    "5. **all in one** files: space-group-**species**-**allInOne**-property-_[-measure][-stage][.ext]\n",
    "\n",
    "[keyword] means that the keyword in the file name is option. [-measure] is a physical measurement such as the auto correlation function (AFC) done on the physical 'property_'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48512f1b-49d3-4ea2-abe9-6ed2655b3e7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## CUATION: How to do:\n",
    "\n",
    "1. Choose the project setting\n",
    "2. Choose the space\n",
    "3. Check the unique properties, and the ACF measures per unique properties.\n",
    "4. Check the name, format, and extension of the Pandas writer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce07c9a-47f4-4980-b972-8b4a96b65737",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5107e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import SumRule, TransFoci\n",
    "from polyphys.analyze import measurer\n",
    "import polyphys.api as api\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# List of physical properties: Set the project hierarchy\n",
    "project = 'SumRule'\n",
    "#project = 'TransFoci'\n",
    "project_details ={\n",
    "    'SumRule':{\n",
    "        'parser': SumRule,\n",
    "        'space_pat': 'N*D*ac*',\n",
    "        'hierarchy': 'N*',\n",
    "        'space_hierarchy': 'N*',\n",
    "        'attributes': ['space', 'ensemble_long', 'ensemble', 'nmon', 'dcyl',\n",
    "                       'dcrowd','phi_c_bulk'\n",
    "                      ],\n",
    "        'time_varying_props': [ 'asphericityTMon', 'fsdTMon', 'gyrTMon',\n",
    "                               'rfloryTMon','shapeTMon'],\n",
    "        'equil_measures': [np.mean, np.var, measurer.sem],\n",
    "        'equil_attributes': ['space', 'ensemble_long', 'ensemble', 'nmon',\n",
    "                             'dcyl','dcrowd', 'phi_c_bulk', \n",
    "                             'phi_c_bulk_round'\n",
    "                            ],\n",
    "        'equil_properties': ['asphericityMon-mean', 'asphericityMon-var',\n",
    "                             'asphericityMon-sem', 'fsdMon-mean',\n",
    "                             'fsdMon-var', 'fsdMon-sem', 'gyrMon-mean',\n",
    "                             'gyrMon-var', 'gyrMon-sem', 'rfloryMon-mean',\n",
    "                             'rfloryMon-var', 'rfloryMon-sem',\n",
    "                             'shapeMon-mean', 'shapeMon-var', 'shapeMon-sem']\n",
    "    },\n",
    "    'TransFoci':{\n",
    "        'parser': TransFoci,\n",
    "        'space_pat': 'ns*nl*al*D*ac*',\n",
    "        'hierarchy': 'eps*',\n",
    "        'space_hierarchy': 'ns*',\n",
    "        'attributes': ['space', 'ensemble_long', 'ensemble', 'nmon_small',\n",
    "                       'nmon_large','dmon_large', 'dcyl', 'dcrowd',\n",
    "                       'phi_c_bulk'\n",
    "                      ],\n",
    "        'time_varying_props': ['asphericityTMon', 'fsdTMon', 'gyrTMon',\n",
    "                               'shapeTMon'],\n",
    "        'equil_measures': [np.mean, np.var, measurer.sem],\n",
    "        'equil_attributes': ['ensemble_long', 'ensemble', 'space', 'dcyl',\n",
    "                             'dmon_large', 'nmon_large', 'nmon_small',\n",
    "                             'dcrowd', 'phi_c_bulk', 'phi_c_bulk_round'],\n",
    "        'equil_properties': ['asphericityMon-mean', 'asphericityMon-var',\n",
    "                             'asphericityMon-sem', 'fsdMon-mean',\n",
    "                             'fsdMon-var', 'fsdMon-sem', 'gyrMon-mean',\n",
    "                             'gyrMon-var', 'gyrMon-sem', 'shapeMon-mean',\n",
    "                             'shapeMon-var', 'shapeMon-sem']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262003e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## allInOne *whole* and *ensAvg* stamps per project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7fab6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **ensemble-averaged** stamps per project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "group = 'bug'\n",
    "phase=\"ensAvg\"\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        group + '-' + phase\n",
    "    )\n",
    "]\n",
    "allInOne_stamps = []\n",
    "for space_db in ens_avg_space_dbs:\n",
    "    stamp_path = project_details[project]['space_hierarchy'] + 'stamps*' \n",
    "    stamp_path = glob(space_db + \"/\" + stamp_path + '.csv')[0]\n",
    "    space_stamps = pd.read_csv(stamp_path)\n",
    "    allInOne_stamps.append(space_stamps)\n",
    "allInOne_stamps = pd.concat(allInOne_stamps, axis=0)\n",
    "allInOne_stamps.reset_index(inplace=True, drop=True)\n",
    "output = analysis_db + \"allInOne-\" + project + \"-stamps-\" + phase + \".csv\"\n",
    "allInOne_stamps.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c51724",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **whole** stamps per project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0a825-b48c-41d9-b954-7b988b1dea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "group = 'bug'\n",
    "phase='ens'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "phase_space_dbs = [\n",
    "    space_db for space_db in space_dbs if space_db.endswith(\n",
    "        group + '-' + phase\n",
    "    )\n",
    "]\n",
    "allInOne_stamps = []\n",
    "for space_db in phase_space_dbs:\n",
    "    stamp_path = project_details[project]['space_hierarchy'] + 'stamps*'\n",
    "    stamp_path = glob(space_db + \"/\" + stamp_path + '.csv')[0]\n",
    "    space_stamps = pd.read_csv(stamp_path)\n",
    "    allInOne_stamps.append(space_stamps)\n",
    "allInOne_stamps = pd.concat(allInOne_stamps, axis=0)\n",
    "allInOne_stamps.reset_index(inplace=True, drop=True)\n",
    "output = analysis_db + \"allInOne-\" + project + \"-stamps-\" + phase +\".csv\"\n",
    "allInOne_stamps.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d81b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **ensAvg** timeseries and their associated measures "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f538b6-83e3-443f-8d4e-612dc9bfaf07",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Measures** of chainsize timeseries properties per space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc9a63-48f6-45d6-9f30-f2a7d76b560f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **allInONe** ACFs of the chain-size properties per **space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ee296-b30e-42a6-b594-bf5990c709ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 11.8 s for TransFoci\n",
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "group = 'bug'\n",
    "geometry = 'biaxial'\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        group + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "# list of unique property_measures:\n",
    "filepath = ens_avg_space_dbs[0] + '*' + project_details[project]['hierarchy'] + '.csv'  # physical properties in all the \n",
    "_, uniq_props_measures = organizer.unique_property(\n",
    "    filepath, 2, [\"-\" + phase], drop_properties=['stamps'])\n",
    "print(uniq_props_measures)\n",
    "for ens_avg_space_db in ens_avg_space_dbs:\n",
    "    ens_avgs = list()\n",
    "    space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "    for property_ in uniq_props_measures:\n",
    "        ens_avg = organizer.space_tseries(\n",
    "            ens_avg_space_db,\n",
    "            property_,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            group,\n",
    "            geometry,\n",
    "            is_save = False  # if True, save per property per space\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=1)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:,~ens_avgs.columns.duplicated()]\n",
    "    output_name = analysis_db +  \"-\".join(\n",
    "        [space,  group, \"chainSize-acf.parquet.brotli\"]\n",
    "    )\n",
    "    ens_avgs.to_parquet(output_name, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259588f1-c129-48c6-98d0-6a1f4990d1ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### **allInOne** the chian-size properties per **space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844af7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 14.7 s for TransFoci\n",
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "group = 'bug'\n",
    "geometry = 'biaxial'\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        group + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "# list of unique property_measures:\n",
    "filepath = ens_avg_space_dbs[0] + '*' + project_details[project]['hierarchy'] + '.csv'  # physical properties in all the \n",
    "_, uniq_props_measures = organizer.unique_property(\n",
    "    filepath, 2, [\"-\" + phase], drop_properties=['stamps'])\n",
    "props_tseries = list(\n",
    "    set(\n",
    "        [prop.split(\"-acf\")[0] for prop in uniq_props_measures]\n",
    "    )\n",
    ")\n",
    "print(props_tseries)\n",
    "for ens_avg_space_db in ens_avg_space_dbs:\n",
    "    ens_avgs = list()\n",
    "    space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "    for property_ in props_tseries:\n",
    "        ens_avg = organizer.space_tseries(\n",
    "            ens_avg_space_db,\n",
    "            property_,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            group,\n",
    "            geometry,\n",
    "            is_save = False  # if True, save per property per space\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=1)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:,~ens_avgs.columns.duplicated()]\n",
    "    output_name = analysis_db +  \"-\".join(\n",
    "        [space,  group, \"chainSize.parquet.brotli\"]\n",
    "    )\n",
    "    ens_avgs.to_parquet(output_name, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3bcc1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Pair distance time-series per project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836072fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "group = 'bug'\n",
    "geometry = 'biaxial'\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        group + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "tseries_foci_props = ['pairDistTFoci']\n",
    "project_ens_avgs = []\n",
    "for prop in tseries_foci_props:\n",
    "    prop_ens_avgs = list()\n",
    "    for ens_avg_space_db in ens_avg_space_dbs:\n",
    "        space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "        ens_avg = organizer.space_tseries(\n",
    "            ens_avg_space_db,\n",
    "            prop,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            group,\n",
    "            geometry,\n",
    "            is_save = False  # if True, save per property per space\n",
    "        )\n",
    "        prop_ens_avgs.append(ens_avg)\n",
    "    prop_ens_avgs = pd.concat(prop_ens_avgs,axis=0)\n",
    "    # drop duplicated columns:\n",
    "    prop_ens_avgs = prop_ens_avgs.loc[:, ~prop_ens_avgs.columns.duplicated()]\n",
    "    prop_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    project_ens_avgs.append(prop_ens_avgs)\n",
    "project_ens_avgs = pd.concat(project_ens_avgs,axis=1)\n",
    "project_ens_avgs = \\\n",
    "    project_ens_avgs.loc[:, ~project_ens_avgs.columns.duplicated()]\n",
    "project_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "output ='-'.join(['allInOne', project, group, 'pairDistT.parquet.brotli'])\n",
    "output = analysis_db + output\n",
    "project_ens_avgs.to_parquet(output, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50541f3-23c6-493c-b03c-59791f0c8af9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Equilibrium timeseries properties per space AND per project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6550f1-7813-4bfb-8009-6955a89378ef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Whole quilibrium properties allInOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8079e8a-9a4f-4fcd-861e-9c4a3ae02de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 14.7 s for TransFoci\n",
    "# Wall time: 2min and 22 s for SumRule\n",
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "group = 'bug'\n",
    "spaces = glob(analysis_db + project_details[project]['space_pat'])\n",
    "spaces = list(set([space.split('/')[-1].split('-')[0] for space in spaces]))\n",
    "save_space = True\n",
    "equili_props_wholes = api.allInOne_equil_tseries(\n",
    "    project,\n",
    "    analysis_db,\n",
    "    group,\n",
    "    spaces,\n",
    "    project_details[project]['time_varying_props'],\n",
    "    project_details[project]['equil_measures'],\n",
    "    save_space=save_space,\n",
    "    divisor = 0.025,\n",
    "    round_to = 3,\n",
    "    save_to=analysis_db\n",
    ")\n",
    "\n",
    "ens_avg = api.allInOne_equil_tseries_ensAvg(\n",
    "    project,\n",
    "    equili_props_wholes,\n",
    "    group,\n",
    "    project_details[project]['equil_properties'],\n",
    "    project_details[project]['equil_attributes'],\n",
    "    save_to=analysis_db\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74045030",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1612fd82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Clusters and bonds per project\n",
    "\n",
    "- The histograms of **Clusters** and **bonds** can **not** be combined in **one** dataset.\n",
    "- Since **per project** datasets are small, we create **one** per project dataset for each property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d12660",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "group = 'bug'\n",
    "geometry = 'biaxial'\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        group + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "\n",
    "nmon_large = 5\n",
    "hist_t_foci_bin_centers = {\n",
    "   'bondsHistFoci': np.arange(nmon_large),\n",
    "   'clustersHistFoci': np.arange(1, nmon_large + 1)\n",
    "}\n",
    "# Separate dataset for bonds and clusters per \n",
    "for prop, bin_center in hist_t_foci_bin_centers.items():\n",
    "    ens_avgs = list()\n",
    "    for ens_avg_space_db in ens_avg_space_dbs:\n",
    "        space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "        ens_avg = organizer.space_hists(\n",
    "            ens_avg_space_db,\n",
    "            prop,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            group,\n",
    "            geometry,\n",
    "            bin_center=bin_center,\n",
    "            normalize=True,\n",
    "            is_save = False\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=0)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:, ~ens_avgs.columns.duplicated()]\n",
    "    ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    output =  \"-\".join(['allInOne', project, group, prop + \".parquet.brotli\"])\n",
    "    output = analysis_db + output\n",
    "    ens_avgs.to_parquet(output, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f988b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Pair Distance Statisitcs per project\n",
    "\n",
    "- These **properties** can be **combined** in one file per project.\n",
    "- Since **per project** datasets are small, we create **one** per project dataset for **all** properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d009009",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "group = 'bug'\n",
    "geometry = 'biaxial'\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        group + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "\n",
    "hist_foci_props = ['pairDistHistFoci', 'pairDistRdfFoci']\n",
    "# One per-project database for both rpeorty since they are samll and related \n",
    "project_ens_avgs = []\n",
    "for prop in hist_foci_props:\n",
    "    prop_ens_avgs = list()\n",
    "    for ens_avg_space_db in ens_avg_space_dbs:\n",
    "        space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "        ens_avg = organizer.space_hists(\n",
    "            ens_avg_space_db,\n",
    "            prop,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            group,\n",
    "            geometry,\n",
    "            bin_center=None,\n",
    "            normalize=False,\n",
    "            is_save=False\n",
    "        )\n",
    "        prop_ens_avgs.append(ens_avg)\n",
    "    prop_ens_avgs = pd.concat(prop_ens_avgs,axis=0)\n",
    "    # drop duplicated columns:\n",
    "    prop_ens_avgs = prop_ens_avgs.loc[:, ~prop_ens_avgs.columns.duplicated()]\n",
    "    prop_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    project_ens_avgs.append(prop_ens_avgs)\n",
    "project_ens_avgs = pd.concat(project_ens_avgs,axis=1)\n",
    "# drop duplicated columns:\n",
    "project_ens_avgs = project_ens_avgs.loc[:, ~project_ens_avgs.columns.duplicated()]\n",
    "project_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "output = '-'.join(\n",
    "    ['allInOne', project, group, 'pairDistStats.parquet.brotli']\n",
    ")\n",
    "output = analysis_db + output\n",
    "project_ens_avgs.to_parquet(output, index=False, compression='brotli')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237d3b9-7cb0-40cb-8d2f-6c86f747702c",
   "metadata": {},
   "source": [
    "### Local radial and longitudinal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04ab64-afa1-45c2-8d2c-d0ab198a4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "group = 'all'\n",
    "geometry = 'biaxial'\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        group + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "# list of unique properties and property_measures:\n",
    "# Local distributions do not have any property_measures:\n",
    "uniq_props, _ = organizer.unique_property(\n",
    "    ens_avg_space_dbs[0] + '*' + \\\n",
    "        project_details[project]['hierarchy'] + '.csv',\n",
    "    2,\n",
    "    [\"-\" + phase],\n",
    "    drop_properties=[\"stamps\"])\n",
    "print(uniq_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224ffe25-b818-4f72-b1f1-cd95f6aad5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "species = ['Mon', 'Crd']\n",
    "species = ['Mon', 'Crd', 'Foci']\n",
    "normalizing_indexes = {\n",
    "    'r': {\n",
    "        'Mon': 0,\n",
    "        'Crd': 0,\n",
    "    },\n",
    "    'z': {\n",
    "        'Mon': (0,\n",
    "        'Crd': 0,\n",
    "    },\n",
    "    'theta': {\n",
    "        'Mon': 0,\n",
    "        'Crd': 0,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353b297-223a-4715-bb48-828ae76bf3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = ['r', 'z', 'theta']\n",
    "for direction in directions:\n",
    "    props_by_dir = [prop for prop in uniq_props if prop.startswith(direction)]\n",
    "    dir_ens_avgs = list()\n",
    "    for prop in props_by_dir:\n",
    "        prop_ens_avgs = list()\n",
    "        for ens_avg_space_db in ens_avg_space_dbs:\n",
    "            space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "            ens_avg = organizer.space_hists(\n",
    "                ens_avg_space_db,\n",
    "                prop,\n",
    "                project_details[project]['parser'],\n",
    "                project_details[project]['hierarchy'],\n",
    "                project_details[project]['attributes'],\n",
    "                species,\n",
    "                group,\n",
    "                geometry,\n",
    "                bin_center=None,\n",
    "                normalize=direction,\n",
    "                is_save=False\n",
    "            )\n",
    "            prop_ens_avgs.append(ens_avg)\n",
    "        prop_ens_avgs = pd.concat(prop_ens_avgs,axis=0)\n",
    "        # drop duplicated columns:\n",
    "        prop_ens_avgs = \\\n",
    "            prop_ens_avgs.loc[:, ~prop_ens_avgs.columns.duplicated()]\n",
    "        prop_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "        dir_ens_avgs.append(prop_ens_avgs)\n",
    "    dir_ens_avgs = pd.concat(dir_ens_avgs,axis=1)\n",
    "        # drop duplicated columns:\n",
    "    dir_ens_avgs = dir_ens_avgs.loc[:, ~dir_ens_avgs.columns.duplicated()]\n",
    "    dir_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    print(dir_ens_avgs.isna().sum().sum())\n",
    "    output = analysis_db +  \"-\".join([\n",
    "        'allInOne', project,  group,  direction + \"LocalDist.parquet.brotli\"\n",
    "    ])\n",
    "    dir_ens_avgs.to_parquet(output, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b4672-ba7b-4453-9f4f-6827487cbd74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Sum-Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b767a-56de-45d0-8d66-be721b684c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_in_one_distributions(\n",
    "                dist_tuples, properties, geometry, direction, save_to=None,\n",
    "                round_to=4):\n",
    "    \"\"\"takes ensemble-averaged distributions and performs three operations\n",
    "    on them. First, it concatenates the ensemble-averaged distributions of\n",
    "    all the species in an ensebmle into one dataframe.\n",
    "\n",
    "    In this dataframe, bin centers are indices and the number of columns\n",
    "    are equal to the number of species. Next, it adds the properties of\n",
    "    the ensemble to the merged distributions. Finally, it combines all\n",
    "    the ensebles from all the gropus into one dataframe.\n",
    "\n",
    "    Cautions:\n",
    "    For each species, a distribution is a dataframe with bin centers as\n",
    "    indices and a column of frequencies.\n",
    "    A simulation group usually results in a graph or curve for the project\n",
    "    and refers to a collection of simulations that all have the same values\n",
    "    for one or several input parameters of the project.\n",
    "    An ensemble is a collection of themodynamically-equivalent simulations\n",
    "    that differs only in their random number seeds, initial conditions, or\n",
    "    boundary conditions but have the same input parameters. In standard\n",
    "    statitatical mechanical approach, an ensmeble is equivalent a simulation,\n",
    "    but here we used it to reffer to all the thermodynamically-equivalent\n",
    "    simulations.\n",
    "    An ensemble-averaged group is an average over all the simulations in an\n",
    "    ensemble and usually gives a data point.\n",
    "    If there are N ensembles, each with M simulations, then there are N\n",
    "    ensemble-average groups and N*M simulations in the simulation group.\n",
    "    By default, the indexes of an ensemble (dataframe) are timesteps.\n",
    "    For some properties such as histograms, however, the indexes are bin\n",
    "    centers. As a result, simulations are tuples where each tuple can have\n",
    "    one or more members. For histogram-like properties, each tuple has two\n",
    "    members where the second member is the bin edges.\n",
    "\n",
    "    Issue:\n",
    "    1. Current implementation only work for a pair of species\n",
    "    (e.g., a monomer type and a crowder type).\n",
    "    2. This function only works when we have all the three distributions for\n",
    "    a species: local histograms, densities, and volume fractions.\n",
    "\n",
    "    Parameters:\n",
    "    dist_tuples (list of tuples): A list of tuples in which each tuple has\n",
    "    all the A*B ensemble-averaged distributions in one ensemble;\n",
    "    here, A is the number of distribution types in this direction\n",
    "    (histogram of particle numbers, number desnity, and volume fraction) ,\n",
    "    and M is the number of different types of particles in that ensemble.\n",
    "    properties (Pandas dataframe): The database of ensemble-average properties.\n",
    "    geomtery (str): the geometry of the simulation box.\n",
    "    direction (str): Direction along which the distributions are computed.\n",
    "    save_to (bool): whether save to file or not\n",
    "    round_to (int): rounding the whole dataframe to the given round-off number.\n",
    "\n",
    "    Return;\n",
    "    A pandad databse in which all the dsitbrutions of all the simulation\n",
    "    groups are merged.\n",
    "    \"\"\"\n",
    "    group_species = []\n",
    "    properties[['ens_name', 'garbage']] = properties.filename.str.split(\n",
    "        pat='-', expand=True)  # find the ensemble names.\n",
    "    selected_cols = [\n",
    "        'filename', 'nmon', 'dcyl', 'lcyl', 'phi_m_bulk', 'rho_m_bulk',\n",
    "        'dcrowd', 'phi_c_bulk', 'rho_c_bulk', 'phi_c_bulk_normalized',\n",
    "        'phi_c_bulk_eff', 'phi_c_bulk_eff_normalized', 'ens_name']\n",
    "    for hist_crd, hist_mon, phi_crd, phi_mon, rho_crd, rho_mon in dist_tuples:\n",
    "        hist_mon_df = pd.read_csv(hist_mon, index_col=0)\n",
    "        ens_name = list(hist_mon_df.columns)[0].split('-')[0]\n",
    "        hist_crd_df = pd.read_csv(\n",
    "            hist_crd, names=['hist_crd_' + direction], skiprows=1, index_col=0)\n",
    "        hist_mon_df = pd.read_csv(\n",
    "            hist_mon, names=['hist_mon_' + direction], skiprows=1, index_col=0)\n",
    "        rho_crd_df = pd.read_csv(\n",
    "            rho_crd, names=['rho_crd_' + direction], skiprows=1, index_col=0)\n",
    "        rho_mon_df = pd.read_csv(\n",
    "            rho_mon, names=['rho_mon_' + direction], skiprows=1, index_col=0)\n",
    "        phi_crd_df = pd.read_csv(\n",
    "            phi_crd, names=['phi_crd_' + direction], skiprows=1, index_col=0)\n",
    "        phi_mon_df = pd.read_csv(\n",
    "            phi_mon, names=['phi_mon_' + direction], skiprows=1, index_col=0)\n",
    "        ens_species = pd.concat([\n",
    "            hist_mon_df, hist_crd_df, rho_mon_df, rho_crd_df, phi_mon_df,\n",
    "            phi_crd_df], axis=1)\n",
    "        ens_species.reset_index(inplace=True)\n",
    "        ens_species.rename(columns={'index': direction}, inplace=True)\n",
    "        # add the properties of the ensemble to merged distributions\n",
    "        for col in selected_cols:\n",
    "            cond = properties['ens_name'] == ens_name\n",
    "            ens_species[col] = properties[cond][col].values[0]\n",
    "        cell_attrs = SumRule(ens_name, geometry, warning=False)\n",
    "        # normalizing the bin centers (or directions) in three different ways:\n",
    "        bin_center_norm_box = {\n",
    "            'r': cell_attrs.dcyl,\n",
    "            'z': cell_attrs.lcyl\n",
    "            }\n",
    "        ens_species[direction+'_norm'] = \\\n",
    "            2 * ens_species[direction] / bin_center_norm_box[direction]\n",
    "        # The following should be divided by 'dmon' but this operation is not\n",
    "        # done since dmon = 1.0:\n",
    "        ens_species[direction+'_norm_mon'] = ens_species[direction]\n",
    "        ens_species[direction+'_norm_crd'] = \\\n",
    "            ens_species[direction] / cell_attrs.dcrowd\n",
    "        # normalizing local volume fractions in different directions\n",
    "        if direction == 'r':\n",
    "            phi_mon_origin = ens_species.loc[0, 'phi_mon_r']\n",
    "            phi_crd_infinity = ens_species.loc[0, 'phi_crd_r']  \\\n",
    "                # it is actually origin but for the sake of similiarity with\\\n",
    "            # z direction.\n",
    "            rho_mon_origin = ens_species.loc[0, 'rho_mon_r']\n",
    "            rho_crd_infinity = ens_species.loc[0, 'rho_crd_r']  \\\n",
    "                # it is actually origin but for the sake of similiarity with\\\n",
    "            # z direction\n",
    "        if direction == 'z':\n",
    "            around_max = 20\n",
    "            non_zero_phi_mon_z_max_idx = ens_species[\n",
    "                ens_species['phi_mon_z'] != 0]['phi_mon_z'].idxmax()\n",
    "            phi_mon_origin = ens_species.loc[\n",
    "                non_zero_phi_mon_z_max_idx - around_max:\n",
    "                non_zero_phi_mon_z_max_idx + around_max, 'phi_mon_z'].mean()\n",
    "            phi_crd_infinity = ens_species[\n",
    "                ens_species['phi_mon_z'] == 0.0]['phi_crd_z'].mean()\n",
    "            non_zero_rho_mon_z_max_idx = ens_species[\n",
    "                ens_species['rho_mon_z'] != 0]['rho_mon_z'].idxmax()\n",
    "            rho_mon_origin = ens_species.loc[\n",
    "                non_zero_rho_mon_z_max_idx - around_max:\n",
    "                non_zero_rho_mon_z_max_idx + around_max, 'rho_mon_z'].mean()\n",
    "            rho_crd_infinity = ens_species[\n",
    "                ens_species['rho_mon_z'] == 0.0]['rho_crd_z'].mean()\n",
    "        ens_species['phi_mon_' + direction + '_uniform'] = phi_mon_origin\n",
    "        ens_species['phi_mon_' + direction + '_uniform_size'] = \\\n",
    "            phi_mon_origin  \\\n",
    "            # This should be divided by 'dmon' but this operation is not\\\n",
    "        # done since dmon = 1.0\n",
    "        ens_species['phi_mon_' + direction + '_uniform_size_norm'] = 1.0\n",
    "        ens_species['phi_mon_' + direction + '_norm'] = \\\n",
    "            ens_species['phi_mon_' + direction] / phi_mon_origin\n",
    "        ens_species['phi_mon_' + direction + '_norm_size'] = \\\n",
    "            ens_species['phi_mon_' + direction + '_norm']  \\\n",
    "            # This should be divided by 'dmon' but this operation is not\\\n",
    "        # done since dmon = 1.0\n",
    "        ens_species['phi_mon_' + direction + '_size'] = \\\n",
    "            ens_species['phi_mon_' + direction]  \\\n",
    "            # This should be divided by 'dmon' but this operation is not\\\n",
    "        # done since dmon = 1.0\n",
    "        ens_species['phi_crd_' + direction + '_uniform'] = phi_crd_infinity\n",
    "        ens_species['phi_crd_' + direction + '_uniform_size'] = \\\n",
    "            phi_crd_infinity / cell_attrs.dcrowd\n",
    "        ens_species['phi_crd_' + direction + '_uniform_size_norm'] = 1.0\n",
    "        ens_species['phi_crd_' + direction + '_norm'] = \\\n",
    "            ens_species['phi_crd_' + direction] / phi_crd_infinity\n",
    "        ens_species['phi_crd_' + direction + '_norm_size'] = \\\n",
    "            ens_species['phi_crd_' + direction + '_norm'] / cell_attrs.dcrowd\n",
    "        ens_species['phi_crd_' + direction + '_size'] = \\\n",
    "            ens_species['phi_crd_' + direction] / cell_attrs.dcrowd\n",
    "        ens_species['phi_' + direction + '_uniform_sum'] = \\\n",
    "            ens_species['phi_mon_' + direction + '_uniform_size']\n",
    "        + ens_species['phi_crd_' + direction + '_uniform_size']\n",
    "        ens_species['phi_' + direction + '_uniform_sum_norm'] = 1.0\n",
    "        ens_species['rho_mon_' + direction + '_uniform'] = rho_mon_origin\n",
    "        ens_species['rho_mon_' + direction + '_uniform_size'] = \\\n",
    "            rho_mon_origin  \\\n",
    "            # This should be mutiplied by 'dmon'**2 but this operation is\\\n",
    "        # not done since dmon = 1.0\n",
    "        ens_species['rho_mon_' + direction + '_norm'] = \\\n",
    "            ens_species['rho_mon_' + direction] / rho_mon_origin\n",
    "        ens_species['rho_mon_' + direction + '_norm_size'] = \\\n",
    "            ens_species['rho_mon_' + direction + '_norm'] \\\n",
    "            # This should be mutiplied by 'dmon'**2 but this operation is\\\n",
    "        # not done since dmon = 1.0\n",
    "        ens_species['rho_mon_' + direction + '_size'] = \\\n",
    "            ens_species['rho_mon_' + direction] \\\n",
    "            # This should be mutiplied by 'dmon'**2 but this operation is\\\n",
    "        # not done since dmon = 1.0\n",
    "        ens_species['rho_crd_' + direction + '_uniform'] = rho_crd_infinity\n",
    "        ens_species['rho_crd_' + direction + '_uniform_size'] = \\\n",
    "            (rho_crd_infinity * cell_attrs.dcrowd**2)\n",
    "        ens_species['rho_crd_' + direction + '_norm'] = \\\n",
    "            (ens_species['rho_crd_' + direction] / rho_crd_infinity)\n",
    "        ens_species['rho_crd_' + direction + '_norm_size'] = \\\n",
    "            (ens_species['rho_crd_' + direction + '_norm']\n",
    "                * cell_attrs.dcrowd**2)\n",
    "        ens_species['rho_crd_' + direction + '_size'] = \\\n",
    "            (ens_species['rho_crd_' + direction] * cell_attrs.dcrowd**2)\n",
    "        ens_species['rho_' + direction + '_uniform_sum'] = \\\n",
    "            (ens_species['rho_mon_' + direction + '_uniform_size']\n",
    "                + ens_species['rho_crd_' + direction + '_uniform_size'])\n",
    "        # sum rule: The monomer and crowder volume fractions normalized\\\n",
    "        # by their particle size and then added to create the sum rule:\n",
    "        ens_species['phi_sumrule_' + direction] = \\\n",
    "            ens_species['phi_mon_' + direction + '_size']\n",
    "        + ens_species['phi_crd_' + direction + '_size']\n",
    "        ens_species['phi_sumrule_' + direction + '_norm'] = \\\n",
    "            (ens_species['phi_sumrule_' + direction]\n",
    "                / (phi_mon_origin\n",
    "                    + (phi_crd_infinity / cell_attrs.dcrowd)))  \\\n",
    "            # The first term in the denominator should be divided by 'dmon' \\\n",
    "        # but this operation isnot done since dmon = 1.0\n",
    "        ens_species['rho_sumrule_' + direction] = \\\n",
    "            (ens_species['rho_mon_' + direction + '_size']\n",
    "                + ens_species['rho_crd_' + direction + '_size'])\n",
    "        ens_species['rho_sumrule_' + direction + '_norm'] = \\\n",
    "            (ens_species['rho_sumrule_' + direction]\n",
    "                / (rho_mon_origin\n",
    "                    + (rho_crd_infinity * cell_attrs.dcrowd**2))) \\\n",
    "            # The first term in the denominator should be mutiplied by\\\n",
    "        # 'dmon'**2 but this operation isnot done since dmon = 1.0\n",
    "        # sume rule phi: Amir's way\n",
    "        if direction == 'z':\n",
    "            ens_species['phi_sumrule_' + direction] = \\\n",
    "                (ens_species['phi_mon_' + direction + '_size']\n",
    "                    + ens_species['phi_crd_' + direction + '_size'])\n",
    "            ens_species['phi_sumrule_' + direction + '_norm_crowd_only'] = \\\n",
    "                (ens_species['phi_sumrule_' + direction]\n",
    "                    / (phi_crd_infinity / cell_attrs.dcrowd))\n",
    "        if ens_species['phi_c_bulk'].any() == 0:\n",
    "            ens_species['phi_crd_' + direction + '_norm'] = 0.0\n",
    "            ens_species['phi_crd_' + direction + '_norm_size'] = 0.0\n",
    "            ens_species['rho_crd_' + direction + '_norm'] = 0.0\n",
    "            ens_species['rho_crd_' + direction + '_norm_size'] = 0.0\n",
    "            if direction == 'z':\n",
    "                ens_species['phi_sumrule_'\n",
    "                            + direction + '_norm_crowd_only'] = 0.0\n",
    "        # Defining concise name for ensembles anf groups\n",
    "        ens_species['ens_name'] = f\"N{cell_attrs.nmon}D{cell_attrs.dcyl}\\\n",
    "            ac{cell_attrs.dcrowd}nc{cell_attrs.ncrowd}\"\n",
    "        ens_species['group_name'] = f\"N{cell_attrs.nmon}D{cell_attrs.dcyl}\\\n",
    "            ac{cell_attrs.dcrowd}\"\n",
    "        ens_species.drop(['filename'], axis=1, inplace=True)\n",
    "        group_species.append(ens_species)\n",
    "    species_database = pd.concat(group_species)\n",
    "    species_database = species_database.round(round_to)\n",
    "    species_database.reset_index(inplace=True, drop=True)\n",
    "    if save_to is not None:\n",
    "        species_database.to_csv(save_to)\n",
    "    return species_database\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cf582efbfbdef60505769a313a3ca49eebfd77179e86f4387bd11d254c0a990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
