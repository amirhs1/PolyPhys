{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The probe phase\n",
    "There are several ways of analyzing the topology and trajectory pairs, depending on the number of trajectory files per a topology file, the continuity of trjaectory files, organization of files in a directory, and the parallel or sequencial arrangement of the computation powerhorse.\n",
    "\n",
    "\n",
    "### To-do-list\n",
    "\n",
    "This notebook is a living documnent. It is an integration of all the past notebooks and scripts written for the *probe* phase in the *PolyPhys* package (or formerly-called *extraction* phase in the decryped *sumrule* package)\n",
    "\n",
    "BThe list below allows to review the past notebooks and scripts and combine them into this notebook:\n",
    "\n",
    "- [] Sum-rule: segments: bug test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: segments: all test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: wholes: bug test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: wholes: all test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: all_in_one: test and run on **date:NODATE-YET**\n",
    "- [X] Trans-Foci: segments: bug test and run on **date:20220621**\n",
    "- [] Trans-Foci: segments: all test and run on **date:NODATE-YET**\n",
    "- [] Trans-Foci: wholes: bug test and run on **date:NODATE-YET**\n",
    "- [] Trans-Foci: wholes: all test and run on **date:NODATE-YET**\n",
    "- [] Trans-Foci: all_in_one: test and run on **date:NODATE-YET**\n",
    "\n",
    "### Naming convention:\n",
    "\n",
    "This is the pattern of file or directory names:\n",
    "\n",
    "1. **whole** files: whole-group-property_[-measure][-stage][.ext]\n",
    "2. **ensemble** files: ensemble-group-property_[-measure][-stage][.ext]\n",
    "3. **ensemble_long** files: ensemble_long-group-property_[-measure][-stage][.ext]\n",
    "4. **space** files: space-group-property_[-measure][-stage][.ext]\n",
    "5. **all in one** files: space-group-**species**-**allInOne**-property-_[-measure][-stage][.ext]\n",
    "\n",
    "[keyword] means that the keyword in the file name is option. [-measure] is a physical measurement such as the auto correlation function (AFC) done on the physical 'property_'.\n",
    "\n",
    "### Settings for testing and running on a PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_CLXSgvVO_9"
   },
   "outputs": [],
   "source": [
    "# settings for testing and running on a PC.\n",
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import \\\n",
    "    SumRuleCyl, TransFociCyl, TransFociCub, HnsCub\n",
    "from polyphys.probe import prober"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# HPC Cluster: gnuparallel\n",
    "\n",
    "## Separated *whole* simulation directories\n",
    "\n",
    "On a cluster, *whole* simulations are organized into *whole* directories, where each *whole* directory contains all the files for a given *whole* simulation. The **gnuparallel** is used to parallalize the **probe** phase at the **shell** level. For this purpose, all the python modules and scripts are separatedly installed and run on each core. For instance, if 32 cores are available, then the files in 32 *whole* directories are simulatenously installed. However, each *whole* directory may contains multiple toplogy and trajectory pairs. Thus, there is parallelization at the level of *whole* directories, not at the levle of the *segment* or *whole* trajectories inside a *whole* directory. Inside each *whole* directory, a python **main_probe.py** script analyzes the trajectories in a sequencial way.\n",
    "\n",
    "- trj and all *segments* on a cluster\n",
    "\n",
    "For each *whole* directory, the following script is executed by means of *gnuparallel*. See these scripts: *probe-1.7-all_trj_segments.py* and *probe-1.7-bug_trj_segments*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sum-rule project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "\n",
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./N*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.sum_rule_bug_cyl(bug_topo, bug_trj, lineage, save_to=save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRuleCyl\n",
    "\n",
    "\n",
    "group = 'bug'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "bug_trjs = glob('./N*' + group + '*')\n",
    "bug_trjs = organizer.sort_filenames(\n",
    "    bug_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob('./N*' + group + '*')\n",
    "bug_topo = organizer.sort_filenames(bug_topo, fmts=['.' + group + '.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "max_segment_id = len(bug_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for bug_trj in bug_trjs:\n",
    "    trj_info = SumRuleCyl(bug_trj, topo_lineage, 'cylindrical', group)\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_bug_cyl(bug_topo, bug_trj, lineage, save_to=save_to)\n",
    "    else:\n",
    "        prober.sum_rule_bug_cyl(\n",
    "            bug_topo,\n",
    "            bug_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRuleCyl\n",
    "\n",
    "\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./N*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = SumRuleCyl(all_trj, topo_lineage, 'cylindrical', group)\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all_cyl(all_topo, all_trj, lineage, save_to=save_to)\n",
    "    else:\n",
    "        prober.sum_rule_all_cyl(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs:  transverse size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "\n",
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./N*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.sum_rule_bug_cyl_transverse_size(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment bug trjs: transverse size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRuleCyl\n",
    "\n",
    "group = 'bug'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "bug_trjs = glob('./N*' + group + '*')\n",
    "bug_trjs = organizer.sort_filenames(\n",
    "    bug_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob('./N*' + group + '*')\n",
    "bug_topo = organizer.sort_filenames(bug_topo, fmts=['.' + group + '.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "max_segment_id = len(bug_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for bug_trj in bug_trjs:\n",
    "    trj_info = SumRuleCyl(bug_trj, topo_lineage, 'cylindrical', group)\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_bug_cyl_transverse_size(\n",
    "            bug_topo, bug_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_bug_cyl_transverse_size(\n",
    "            bug_topo,\n",
    "            bug_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs: hist_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRuleCyl\n",
    "\n",
    "\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./N*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = SumRuleCyl(all_trj, topo_lineage, 'cylindrical', group)\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all_cyl_hist2d(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_all_cyl_hist2d(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trans-Foci project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cylindrical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### whole bug trjs\n",
    "Each *bug topology* comes with only **one** *bug trajectory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cyl(bug_topo, bug_trj, lineage, save_to=save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCyl(all_trj, topo_lineage, 'cylindrical', group)\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cyl(all_topo, all_trj, lineage, save_to=save_to)\n",
    "    else:\n",
    "        prober.trans_foci_all_cyl(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs: transverse_size\n",
    "Each *bug topology* comes with only **one** *bug trajectory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cyl_transverse_size(\n",
    "        bug_topo, bug_trj, lineage, save_to=save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs: hist_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCyl(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cyl_hist2d(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "\n",
    "        prober.trans_foci_all_cyl_hist2d(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs\n",
    "Each *bug topology* comes with only **one** *bug trajectory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "# analyzing bug files.\n",
    "geometry = 'biaxial'\n",
    "group='bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./al*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cubic(bug_topo, bug_trj, lineage, save_to=save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./al*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./al*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCubic(all_trj, topo_lineage, 'cubic', group)\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cubic(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.trans_foci_all_cubic(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PC Serial scheme \n",
    "\n",
    "There are 4 different types of directories from which only one type can be in a *space* directory.\n",
    "\n",
    "There are separated **whole** directories in each of which there **all** and **bug** **whole** trajectories; or, there are again separated **whole** directories in each of which there are **all** and **bug** **segment** trjaectories. Below there are two groups of scrips for **serial** and **parallel** runnung schemes.\n",
    "\n",
    "\n",
    "On a PC, the *whole* directories are located in a master *space-trjs* directory; however, one main python script probes all the *whole* directories in a parallel scheme via Dask. This is different from the *gnuparallel*-based approach in which each *whole* directory has its own copy of the required scripts and a main pytohn script is run to probe that direcotry individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sumrule project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cylindrical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "#macbookpro_path = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "bug_pairs = glob(macbookpro_path + '/N*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.sum_rule_bug_cyl(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        lineage,\n",
    "        continuous=False,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "group = 'bug'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "bug_trjs = glob(macbookpro_path + '/N*' + group + '*')\n",
    "bug_trjs = organizer.sort_filenames(\n",
    "    bug_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob(macbookpro_path + '/N*' + group + '*')\n",
    "bug_topo = organizer.sort_filenames(bug_topo, fmts=['.' + group + '.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "max_segment_id = len(bug_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for bug_trj in bug_trjs:\n",
    "    trj_info = SumRuleCyl(\n",
    "        bug_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'linear'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_bug_cyl(\n",
    "            bug_topo, bug_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_bug_cyl(\n",
    "            bug_topo,\n",
    "            bug_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs: hist_1d and hist_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 mins for ~4000 particles with one all trj\n",
    "# macbookmini\n",
    "parent = \"/Users/amirhsi_mini/research_data/trjs\"\n",
    "# macbookpro\n",
    "#parent = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(parent + '/N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "print(all_trjs)\n",
    "all_topo = glob(parent + '/N*' + group + '*')\n",
    "print(all_topo)\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = SumRuleCyl(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'linear'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all_cyl(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_all_cyl(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs: transverse size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "macmini_path = \"/Users/amirhsi_mini/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc4804dt0.005bdump1000adump5000ens6/*.bug*\"\n",
    "#macbookpro_path = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "bug_pairs = glob(macbookpro_path + '/N*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.sum_rule_bug_cyl_transverse_size(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        lineage,\n",
    "        continuous=False,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment bug trjs: transverse size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 18 mins for N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7 two bugs\n",
    "#trjs_db = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "trjs_db = \"/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc4804dt0.005bdump1000adump5000ens6\"\n",
    "group = 'bug'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "bug_trjs = glob(trjs_db + '/N*' + group + '*')\n",
    "bug_trjs = organizer.sort_filenames(\n",
    "    bug_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob(trjs_db + '/N*' + group + '*')\n",
    "bug_topo = organizer.sort_filenames(bug_topo, fmts=['.' + group + '.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "max_segment_id = len(bug_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for bug_trj in bug_trjs:\n",
    "    trj_info = SumRuleCyl(\n",
    "        bug_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'linear'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_bug_cyl_transverse_size(\n",
    "            bug_topo, bug_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_bug_cyl_transverse_size(\n",
    "            bug_topo,\n",
    "            bug_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs: hist_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 10 mins for N2000epsilon5.0r13.0lz259.0sig1.0nc133547dt0.005bdump1000adump5000ens1 2 all trjs\n",
    "# macbookmini\n",
    "trjs_db = \"/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r13.0lz259.0sig1.0nc133547dt0.005bdump1000adump5000ens1\"\n",
    "# macbookpro\n",
    "#trjs_db = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(trjs_db + '/N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "print(all_trjs)\n",
    "all_topo = glob(trjs_db + '/N*' + group + '*')\n",
    "print(all_topo)\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = SumRuleCyl(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'linear'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all_cyl_hist2d(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        prober.sum_rule_all_cyl_hist2d(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Trans-Foci project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cylindrical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "linage = 'whole'\n",
    "save_to = './'\n",
    "#macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "bug_pairs = glob(macbookpro_path + '/eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cyl(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "#macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "macmini_path = '/Users/amirhsi_mini/research_data/test'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(macmini_path + '/eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(macmini_path + '/eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCyl(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'ring'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cyl(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.trans_foci_all_cyl(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment bug trjs: transverse size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "linage = 'whole'\n",
    "save_to = './'\n",
    "#macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "bug_pairs = glob(macbookpro_path + '/eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_foci_bug_cyl_transverse_size(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs: hist_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "#macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "macmini_path = '/Users/amirhsi_mini/research_data/test'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(macmini_path + '/eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(macmini_path + '/eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCyl(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'ring'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_hist2d(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.trans_foci_all_hist2d(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "#macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "macbookpro_path = \"/Users/amirhsi_mini/research_data/ns400nl5al5ml125ac1nc0l62dt0.005bdump2000adump5000ens3.ring\"\n",
    "bug_pairs = glob(macbookpro_path + '/al*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cub(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "macbookpro_path = \"/Users/amirhsi_mini/research_data/ns400nl5al5ml125ac1nc0l62dt0.005bdump2000adump5000ens3.ring\"\n",
    "#macmini_path = '/Users/amirhsi_mini/research_data/test'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(macbookpro_path + '/al*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(macbookpro_path + '/al*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCub(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cubic',\n",
    "        group,\n",
    "        'ring'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cub(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.trans_foci_all_cub(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HNS project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "group = 'nucleoid'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "probe_path = \"/Users/amirhsi_mini/research_data/hns_cubic-trjs/N*/N*\"\n",
    "#probe_path = \"/Users/amirhsi_mini/research_data/ns400nl5al5ml125ac1nc0l62dt0.005bdump2000adump5000ens3.ring\"\n",
    "nuc_pairs = glob(probe_path + '/N*' + group + '*')\n",
    "nuc_pairs = organizer.sort_filenames(\n",
    "    nuc_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (nuc_topo, nuc_trj) in nuc_pairs:\n",
    "    prober.hns_nucleoid_cub(\n",
    "        nuc_topo,\n",
    "        nuc_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "macbookpro_path = \"/Users/amirhsi_mini/research_data/ns400nl5al5ml125ac1nc0l62dt0.005bdump2000adump5000ens3.ring\"\n",
    "#macmini_path = '/Users/amirhsi_mini/research_data/test'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(macbookpro_path + '/al*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(macbookpro_path + '/al*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = HnsCub(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cubic',\n",
    "        group,\n",
    "        'ring'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.hns_all_cub(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.hns_all_cub(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hns Cubi: test probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import Optional, Tuple, Dict\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis.base import AnalysisFromFunction\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from polyphys.manage.typer import ParserT\n",
    "from polyphys.manage.parser import SumRuleCyl, TransFociCyl, TransFociCub\n",
    "from polyphys.manage.organizer import invalid_keyword, sort_filenames\n",
    "from polyphys.analyze import clusters, correlations\n",
    "from polyphys.probe.prober import stamps_report\n",
    "import warnings\n",
    "from glob import glob\n",
    "\n",
    "from MDAnalysis.analysis import polymer\n",
    "from MDAnalysis.analysis import distances\n",
    "from polyphys.manage.parser import HnsCub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hns_nucleoid_cub_dist(\n",
    "    topology: str,\n",
    "    trajectory: str,\n",
    "    lineage: str,\n",
    "    save_to: str = './',\n",
    "    continuous: bool = False\n",
    ") -> None:\n",
    "    if (lineage == 'segment') & (continuous is False):\n",
    "        warnings.warn(\n",
    "            \"lineage is \"\n",
    "            f\"'{lineage}' \"\n",
    "            \"and 'continuous' is \"\n",
    "            f\"'{continuous}. \"\n",
    "            \"Please ensure the \"\n",
    "            f\"'{trajectory}' is NOT part of a sequence of trajectories.\",\n",
    "            UserWarning\n",
    "        )\n",
    "    print(\"Setting the name of analyze file...\")\n",
    "    sim_info = HnsCub(\n",
    "        trajectory,\n",
    "        lineage,\n",
    "        'cubic',\n",
    "        'nucleoid',\n",
    "        'ring'\n",
    "    )\n",
    "    sim_name = sim_info.lineage_name + \"-\" + sim_info.group\n",
    "    print(\"\\n\" + sim_name + \" is analyzing...\\n\")\n",
    "    # LJ time difference between two consecutive frames:\n",
    "    time_unit = sim_info.dmon * np.sqrt(\n",
    "        sim_info.mmon * sim_info.eps_others)  # LJ time unit\n",
    "    lj_nstep = sim_info.ndump  # Sampling steps via dump command in Lammps\n",
    "    lj_dt = sim_info.dt\n",
    "    sim_real_dt = lj_nstep * lj_dt * time_unit\n",
    "    cell = mda.Universe(\n",
    "        topology, trajectory, topology_format='DATA',\n",
    "        format='LAMMPSDUMP', lammps_coordinate_convention='unscaled',\n",
    "        atom_style=\"id resid type x y z\", dt=sim_real_dt\n",
    "        )\n",
    "    # slicing trajectory based the continuous condition\n",
    "    if continuous:\n",
    "        sliced_trj = cell.trajectory[0: -1]\n",
    "        n_frames = cell.trajectory.n_frames - 1\n",
    "    else:\n",
    "        sliced_trj = cell.trajectory\n",
    "        n_frames = cell.trajectory.n_frames\n",
    "    # selecting atom groups\n",
    "    bug = cell.select_atoms('resid 1')  # the bug\n",
    "    hns_pole = cell.select_atoms('type 2')  # the hns holes\n",
    "    hns_core = cell.select_atoms('type 3')  # the hns cores\n",
    "\n",
    "    # bond info\n",
    "    n_bonds = len(bug.bonds.indices)\n",
    "    bond_lengths = np.zeros(n_bonds, dtype=np.float64)\n",
    "    cosine_corrs = np.zeros(n_bonds, dtype=np.float64)\n",
    "    #ljcut_coeff = 1.122462\n",
    "    #hns_core_mon_cutoff = 0.5*(\n",
    "    #    sim_info.dmon*ljcut_coeff + 0.2 + sim_info.dhns\n",
    "    #)\n",
    "    hns_pole_mon_cutoff = 0.5*(sim_info.dmon*ljcut_coeff + 0.2)\n",
    "    #mon_mon_cutoff = sim_info.dmon*ljcut_coeff + 0.2 + sim_info.dhns\n",
    "    dist_array_core_contact = np.zeros((sim_info.nmon, sim_info.nhns), dtype=np.int64)\n",
    "    dist_array_pole_contact = np.zeros((sim_info.nmon, 2*sim_info.nhns), dtype=np.int64)\n",
    "    dist_array_mon_contact = np.zeros((sim_info.nmon, sim_info.nmon), dtype=np.int64)\n",
    "    for _ in sliced_trj:\n",
    "        # bug:\n",
    "        #dummy = distances.distance_array(bug, hns_core, box=cell.dimensions)\n",
    "        #dummy = np.asarray(dummy <= hns_core_mon_cutoff, dtype=int)\n",
    "        #dist_array_core_contact += dummy\n",
    "        dummy = distances.distance_array(bug, hns_pole, box=cell.dimensions)\n",
    "        dummy = np.asarray(dummy <= hns_pole_mon_cutoff, dtype=int)\n",
    "        dist_array_pole_contact += dummy\n",
    "        #dummy = distances.distance_array(bug, bug, box=cell.dimensions)\n",
    "        #dummy = np.asarray(dummy <= mon_mon_cutoff, dtype=int)\n",
    "        #dist_array_mon_contact += dummy\n",
    "        # bug:\n",
    "        #bond_dummy, cosine_dummy = correlations.bond_info(bug.positions, 'ring')\n",
    "        #bond_lengths += bond_dummy.reshape(200)\n",
    "        #cosine_corrs += cosine_dummy\n",
    "\n",
    "    #dist_array_core_contact_mean = dist_array_core_contact / n_frames\n",
    "    dist_array_pole_contact_mean = dist_array_pole_contact / n_frames\n",
    "    #dist_array_mon_contact_mean = dist_array_mon_contact / n_frames\n",
    "    #bond_lengths_mean = bond_lengths_acc / n_frames\n",
    "    #cosine_corrs_mean = cosine_corrs_acc / n_frames\n",
    "    #np.save(\n",
    "    #    save_to + sim_name + \"distCoreMonMean.npy\",\n",
    "    #    dist_array_core_contact_mean\n",
    "    #)\n",
    "    np.save(\n",
    "        save_to + sim_name + \"-distPoleMonMean.npy\",\n",
    "        dist_array_pole_contact_mean\n",
    "    )\n",
    "    #np.save(\n",
    "    #    save_to + sim_name + \"-distMonMonMeanNewCutoff.npy\",\n",
    "    #    dist_array_mon_contact_mean\n",
    "    #)\n",
    "    bond_lengths = bond_lengths / n_frames\n",
    "    bonds_per_lag = np.arange(n_bonds, 0, -1)\n",
    "    cosine_corrs = cosine_corrs / (n_frames * bonds_per_lag)\n",
    "    np.save(save_to + sim_name +'-bondLengthVec.npy', bond_lengths)\n",
    "    np.save(save_to + sim_name +'-bondCosineCorrVec.npy', cosine_corrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 2min per pairs\n",
    "# 32 min for 10 pairs\n",
    "# analyzing bug files.\n",
    "group = 'nucleoid'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "probe_path = \"/Users/amirhsi_mini/research_data/hns_cubic-trjs/N*/N200epshm29nh49ac1*\"\n",
    "#probe_path = \"/Users/amirhsi_mini/research_data/ns400nl5al5ml125ac1nc0l62dt0.005bdump2000adump5000ens3.ring\"\n",
    "nuc_pairs = glob(probe_path + '/N*' + group + '*')\n",
    "nuc_pairs = organizer.sort_filenames(\n",
    "    nuc_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (nuc_topo, nuc_trj) in nuc_pairs:\n",
    "    hns_nucleoid_cub_dist(\n",
    "        nuc_topo,\n",
    "        nuc_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_v4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cf582efbfbdef60505769a313a3ca49eebfd77179e86f4387bd11d254c0a990"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
