{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The probe phase\n",
    "There are several ways of analyzing the topology and trajectory pairs, depending on the number of trajectory files per a topology file, the continuity of trjaectory files, organization of files in a directory, and the parallel or sequencial arrangement of the computation powerhorse.\n",
    "\n",
    "\n",
    "### To-do-list\n",
    "\n",
    "This notebook is a living documnent. It is an integration of all the past notebooks and scripts written for the *probe* phase in the *PolyPhys* package (or formerly-called *extraction* phase in the decryped *sumrule* package)\n",
    "\n",
    "BThe list below allows to review the past notebooks and scripts and combine them into this notebook:\n",
    "\n",
    "- [] Sum-rule: segments: bug test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: segments: all test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: wholes: bug test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: wholes: all test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: all_in_one: test and run on **date:NODATE-YET**\n",
    "- [X] Trans-Foci: segments: bug test and run on **date:20220621**\n",
    "- [] Trans-Foci: segments: all test and run on **date:NODATE-YET**\n",
    "- [] Trans-Foci: wholes: bug test and run on **date:NODATE-YET**\n",
    "- [] Trans-Foci: wholes: all test and run on **date:NODATE-YET**\n",
    "- [] Trans-Foci: all_in_one: test and run on **date:NODATE-YET**\n",
    "\n",
    "### Naming convention:\n",
    "\n",
    "This is the pattern of file or directory names:\n",
    "\n",
    "1. **whole** files: whole-group-property_[-measure][-stage][.ext]\n",
    "2. **ensemble** files: ensemble-group-property_[-measure][-stage][.ext]\n",
    "3. **ensemble_long** files: ensemble_long-group-property_[-measure][-stage][.ext]\n",
    "4. **space** files: space-group-property_[-measure][-stage][.ext]\n",
    "5. **all in one** files: space-group-**species**-**allInOne**-property-_[-measure][-stage][.ext]\n",
    "\n",
    "[keyword] means that the keyword in the file name is option. [-measure] is a physical measurement such as the auto correlation function (AFC) done on the physical 'property_'.\n",
    "\n",
    "### Settings for testing and running on a PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_CLXSgvVO_9"
   },
   "outputs": [],
   "source": [
    "# settings for testing and running on a PC.\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import SumRule, TransFoci\n",
    "from polyphys.probe import prober"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "client = Client(n_workers=2)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HPC Cluster: gnuparallel\n",
    "\n",
    "## Separated *whole* simulation directories\n",
    "\n",
    "On a cluster, *whole* simulations are organized into *whole* directories, where each *whole* directory contains all the files for a given *whole* simulation. The **gnuparallel** is used to parallalize the **probe** phase at the **shell** level. For this purpose, all the python modules and scripts are separatedly installed and run on each core. For instance, if 32 cores are available, then the files in 32 *whole* directories are simulatenously installed. However, each *whole* directory may contains multiple toplogy and trajectory pairs. Thus, there is parallelization at the level of *whole* directories, not at the levle of the *segment* or *whole* trajectories inside a *whole* directory. Inside each *whole* directory, a python **main_probe.py** script analyzes the trajectories in a sequencial way.\n",
    "\n",
    "- trj and all *segments* on a cluster\n",
    "\n",
    "For each *whole* directory, the following script is executed by means of *gnuparallel*. See these scripts: *probe-1.7-all_trj_segments.py* and *probe-1.7-bug_trj_segments*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum-rule project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "\n",
    "# analyzing bug files.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "linage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./N*' + group '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.sum_rule_bug(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        geometry,\n",
    "        whole,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### segment bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRule\n",
    "\n",
    "\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "bug_trjs = glob('./N*' + group + '*')\n",
    "bug_trjs = organizer.sort_filenames(\n",
    "    bug_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob('./N*' + group + '*')\n",
    "bug_topo = organizer.sort_filenames(bug_topo, fmts=['.' + group + '.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "max_segment_id = len(bug_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for bug_trj in bug_trjs[:1]:\n",
    "    trj_info = SumRule(\n",
    "        bug_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_bug(\n",
    "            bug_topo, bug_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_bug(\n",
    "            bug_topo,\n",
    "            bug_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRule\n",
    "\n",
    "\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./N*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs[:1]:\n",
    "    trj_info = SumRule(\n",
    "        all_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all(\n",
    "            all_topo, all_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_all(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Trans-Foci project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whole bug trjs\n",
    "Each *bug topology* comes with only **one** *bug trajectory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "# analyzing bug files.\n",
    "geometry = 'biaxial'\n",
    "group='bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug(\n",
    "        bug_topo, bug_trj, lineage, group, geometry, save_to=save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFoci(\n",
    "        all_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all(\n",
    "            all_topo, all_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "\n",
    "        prober.trans_foci_all(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PC Serial scheme \n",
    "\n",
    "There are 4 different types of directories from which only one type can be in a *space* directory.\n",
    "\n",
    "There are separated **whole** directories in each of which there **all** and **bug** **whole** trajectories; or, there are again separated **whole** directories in each of which there are **all** and **bug** **segment** trjaectories. Below there are two groups of scrips for **serial** and **parallel** runnung schemes.\n",
    "\n",
    "\n",
    "On a PC, the *whole* directories are located in a master *space-trjs* directory; however, one main python script probes all the *whole* directories in a parallel scheme via Dask. This is different from the *gnuparallel*-based approach in which each *whole* directory has its own copy of the required scripts and a main pytohn script is run to probe that direcotry individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumrule project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "linage = 'whole'\n",
    "save_to = './'\n",
    "#macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "bug_pairs = glob(macbookpro_path + '/N*' + group '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.sum_rule_bug(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        geometry,\n",
    "        whole,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### segment bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "bug_trjs = glob(macbookpro_path + '/N*' + group + '*')\n",
    "bug_trjs = organizer.sort_filenames(\n",
    "    bug_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob(macbookpro_path + '/N*' + group + '*')\n",
    "bug_topo = organizer.sort_filenames(bug_topo, fmts=['.' + group + '.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "max_segment_id = len(bug_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for bug_trj in bug_trjs[:1]:\n",
    "    trj_info = SumRule(\n",
    "        bug_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_bug(\n",
    "            bug_topo, bug_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_bug(\n",
    "            bug_topo,\n",
    "            bug_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 4 mins for ~4000 particles with one all trj\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(macbookpro_path + '/N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(macbookpro_path + '/N*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs[:1]:\n",
    "    trj_info = SumRule(\n",
    "        all_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all(\n",
    "            all_topo, all_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_all(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trans-Foci project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "linage = 'whole'\n",
    "save_to = './'\n",
    "#macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "bug_pairs = glob(macbookpro_path + '/eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        geometry,\n",
    "        whole,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(macbookpro_path + '/eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(macbookpro_path + '/eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs[:1]:\n",
    "    trj_info = TransFoci(\n",
    "        all_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all(\n",
    "            all_topo, all_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "\n",
    "        prober.trans_foci_all(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parallel scheme with dask\n",
    "\n",
    "There are 4 different types of directories from which only one type can be in a *space* directory.\n",
    "\n",
    "There are separated **whole** directories in each of which there **all** and **bug** **whole** trajectories; or, there are again separated **whole** directories in each of which there are **all** and **bug** **segment** trjaectories. Below there are two groups of scrips for **serial** and **parallel** runnung schemes.\n",
    "\n",
    "\n",
    "## *bug* *segment* trjs:\n",
    "\n",
    "On a PC, the *whole* directories are located in a master *space-trjs* directory; however, one main python script probes all the *whole* directories in a parallel scheme via Dask. This is different from the *gnuparallel*-based approach in which each *whole* directory has its own copy of the required scripts and a main pytohn script is run to probe that direcotry individually.\n",
    "\n",
    "## *bug* *whole* trjs: NOT tested 20220603: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## This approach from HERE\n",
    "path = pathlib.Path('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "## to HERE, does not work of * is used in the string input for Path.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.bug.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.bug.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "trjs_computed = []\n",
    "for topology in topologies:\n",
    "    print(topology[0])\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='whole')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            trj_delayed = delayed(prober.sum_rule_bug)(topology[0], trajectory[0], geometry, 'whole', save_to_whole, continuous=False)\n",
    "            trjs_computed.append(trj_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# it takes 9min and 34s.\n",
    "results = compute(trjs_computed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *bug* *segment* trjs: NONT written: NOT tested 20220603: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### *all* *segment* trjs: probe_all: NOT dask style: NOT tested 20220603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path('../test_data/trjs-continuous/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.all.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.all.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "for topology in topologies:\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.segment_id ==10:\n",
    "            prober.sum_rule_all(topology[0], trajectory[0], geometry, 'segment', save_to_whole)\n",
    "        else:\n",
    "            prober.sum_rule_all(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path('../test_data/trjs-continuous/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "hierarchy = '/N*/N*'\n",
    "observations = glob(input_database + hierarchy)\n",
    "all_tuples =  organizer.sort_filenames(observations,fmts=['all.lammpstrj'])\n",
    "all_trjs = [all_tuple[0] for all_tuple in all_tuples]\n",
    "all_data =  organizer.sort_filenames(observations,fmts=['all.data'])\n",
    "all_data = all_data[0][0]\n",
    "\n",
    "    \n",
    "for all_trj in all_trjs:\n",
    "    print(all_trj)\n",
    "    #PipeLine.extract_trj_all(all_data, all_trj, geom, save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### *all* *segment* trjs: probe_all_new:: NOT tested 20220603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = pathlib.Path('/Users/amirhsi_mini/trjs/N500D10.0ac0.8-trjs')\n",
    "path = path.resolve() # convert relative path to aabsolute one\n",
    "input_database = str(path)\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "hierarchy = '/N*/N*'\n",
    "if not pathlib.Path(input_database).exists():\n",
    "    raise OSError(f\"'{input_database}'\"\n",
    "                    \"path does not exist.\")\n",
    "observations = glob(input_database + hierarchy)\n",
    "if observations == []:\n",
    "    raise OSError(\n",
    "        \"File not found in \"\n",
    "        f\"'{input_database + hierarchy}'\"\n",
    "        )\n",
    "topologies = organizer.sort_filenames(observations, fmts=['.all.data'])\n",
    "trajectories = organizer.sort_filenames(observations, fmts=['.all.lammpstrj'])\n",
    "# 'bug' time series and historams\n",
    "save_to = analyzer.database_path(input_database, phase='probe', stage='segment', group=None)\n",
    "trjs_computed = []\n",
    "for topology in topologies:\n",
    "    topo_info = SumRule(topology[0],geometry=geometry, group=group, lineage='whole')\n",
    "    save_to_whole = save_to + '/' + topo_info.whole\n",
    "    save_to_whole = pathlib.Path(save_to_whole) \n",
    "    try:\n",
    "        save_to_whole.mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError as error:\n",
    "        print(error)\n",
    "        print(\n",
    "            f\"Directory '{save_to_whole}'\"\n",
    "            \" exist. Files are saved/overwritten to an existing directoy.\")\n",
    "    finally:\n",
    "        save_to_whole = str(save_to_whole) + '/'\n",
    "    for trajectory in trajectories:\n",
    "        trj_info = SumRule(trajectory[0],geometry=geometry, group=group, lineage='segment')\n",
    "        if trj_info.whole == topo_info.whole:\n",
    "            if trj_info.segment_id ==14:\n",
    "                trj_delayed = delayed(prober.probe_all_new)(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=False)\n",
    "                trjs_computed.append(trj_delayed)\n",
    "            else:\n",
    "                trj_delayed = delayed(prober.probe_all_new)(topology[0], trajectory[0], geometry, 'segment', save_to_whole, continuous=True)\n",
    "                trjs_computed.append(trj_delayed)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = compute(trjs_computed)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_v4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
