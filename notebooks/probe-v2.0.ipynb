{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The probe phase\n",
    "There are several ways of analyzing the topology and trajectory pairs, depending on the number of trajectory files per a topology file, the continuity of trjaectory files, organization of files in a directory, and the parallel or sequencial arrangement of the computation powerhorse.\n",
    "\n",
    "\n",
    "### To-do-list\n",
    "\n",
    "This notebook is a living documnent. It is an integration of all the past notebooks and scripts written for the *probe* phase in the *PolyPhys* package (or formerly-called *extraction* phase in the decryped *sumrule* package)\n",
    "\n",
    "BThe list below allows to review the past notebooks and scripts and combine them into this notebook:\n",
    "\n",
    "- [] Sum-rule: segments: bug test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: segments: all test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: wholes: bug test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: wholes: all test and run on **date:NODATE-YET**\n",
    "- [] Sum-rule: all_in_one: test and run on **date:NODATE-YET**\n",
    "- [X] Trans-Foci: segments: bug test and run on **date:20220621**\n",
    "- [] Trans-Foci: segments: all test and run on **date:NODATE-YET**\n",
    "- [] Trans-Foci: wholes: bug test and run on **date:NODATE-YET**\n",
    "- [] Trans-Foci: wholes: all test and run on **date:NODATE-YET**\n",
    "- [] Trans-Foci: all_in_one: test and run on **date:NODATE-YET**\n",
    "\n",
    "### Naming convention:\n",
    "\n",
    "This is the pattern of file or directory names:\n",
    "\n",
    "1. **whole** files: whole-group-property_[-measure][-stage][.ext]\n",
    "2. **ensemble** files: ensemble-group-property_[-measure][-stage][.ext]\n",
    "3. **ensemble_long** files: ensemble_long-group-property_[-measure][-stage][.ext]\n",
    "4. **space** files: space-group-property_[-measure][-stage][.ext]\n",
    "5. **all in one** files: space-group-**species**-**allInOne**-property-_[-measure][-stage][.ext]\n",
    "\n",
    "[keyword] means that the keyword in the file name is option. [-measure] is a physical measurement such as the auto correlation function (AFC) done on the physical 'property_'.\n",
    "\n",
    "### Settings for testing and running on a PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_CLXSgvVO_9"
   },
   "outputs": [],
   "source": [
    "# settings for testing and running on a PC.\n",
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import SumRule, TransFoci\n",
    "from polyphys.probe import prober"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# HPC Cluster: gnuparallel\n",
    "\n",
    "## Separated *whole* simulation directories\n",
    "\n",
    "On a cluster, *whole* simulations are organized into *whole* directories, where each *whole* directory contains all the files for a given *whole* simulation. The **gnuparallel** is used to parallalize the **probe** phase at the **shell** level. For this purpose, all the python modules and scripts are separatedly installed and run on each core. For instance, if 32 cores are available, then the files in 32 *whole* directories are simulatenously installed. However, each *whole* directory may contains multiple toplogy and trajectory pairs. Thus, there is parallelization at the level of *whole* directories, not at the levle of the *segment* or *whole* trajectories inside a *whole* directory. Inside each *whole* directory, a python **main_probe.py** script analyzes the trajectories in a sequencial way.\n",
    "\n",
    "- trj and all *segments* on a cluster\n",
    "\n",
    "For each *whole* directory, the following script is executed by means of *gnuparallel*. See these scripts: *probe-1.7-all_trj_segments.py* and *probe-1.7-bug_trj_segments*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum-rule project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "\n",
    "# analyzing bug files.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./N*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.sum_rule_bug(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        geometry,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### segment bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRule\n",
    "\n",
    "\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "bug_trjs = glob('./N*' + group + '*')\n",
    "bug_trjs = organizer.sort_filenames(\n",
    "    bug_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob('./N*' + group + '*')\n",
    "bug_topo = organizer.sort_filenames(bug_topo, fmts=['.' + group + '.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "max_segment_id = len(bug_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for bug_trj in bug_trjs:\n",
    "    trj_info = SumRule(\n",
    "        bug_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_bug(\n",
    "            bug_topo, bug_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_bug(\n",
    "            bug_topo,\n",
    "            bug_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRule\n",
    "\n",
    "\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./N*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = SumRule(\n",
    "        all_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all(\n",
    "            all_topo, all_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_all(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Trans-Foci project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whole bug trjs\n",
    "Each *bug topology* comes with only **one** *bug trajectory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "# analyzing bug files.\n",
    "geometry = 'biaxial'\n",
    "group='bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug(\n",
    "        bug_topo, bug_trj, lineage, group, geometry, save_to=save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFoci(\n",
    "        all_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all(\n",
    "            all_topo, all_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "\n",
    "        prober.trans_foci_all(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PC Serial scheme \n",
    "\n",
    "There are 4 different types of directories from which only one type can be in a *space* directory.\n",
    "\n",
    "There are separated **whole** directories in each of which there **all** and **bug** **whole** trajectories; or, there are again separated **whole** directories in each of which there are **all** and **bug** **segment** trjaectories. Below there are two groups of scrips for **serial** and **parallel** runnung schemes.\n",
    "\n",
    "\n",
    "On a PC, the *whole* directories are located in a master *space-trjs* directory; however, one main python script probes all the *whole* directories in a parallel scheme via Dask. This is different from the *gnuparallel*-based approach in which each *whole* directory has its own copy of the required scripts and a main pytohn script is run to probe that direcotry individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumrule project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "bug_pairs = glob(macbookpro_path + '/N*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.sum_rule_bug(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        geometry,\n",
    "        lineage,\n",
    "        continuous=False,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### segment bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "bug_trjs = glob(macbookpro_path + '/N*' + group + '*')\n",
    "bug_trjs = organizer.sort_filenames(\n",
    "    bug_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob(macbookpro_path + '/N*' + group + '*')\n",
    "bug_topo = organizer.sort_filenames(bug_topo, fmts=['.' + group + '.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "max_segment_id = len(bug_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for bug_trj in bug_trjs:\n",
    "    trj_info = SumRule(\n",
    "        bug_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_bug(\n",
    "            bug_topo, bug_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_bug(\n",
    "            bug_topo,\n",
    "            bug_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from typing import Callable, Optional, Tuple, Dict, Type\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from polyphys.manage.parser import SumRule, TransFoci\n",
    "from polyphys.manage.organizer import invalid_keyword\n",
    "from polyphys.analyze import clusters\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005bdump1000adump5000ens7.j01.all.lammpstrj', '/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005bdump1000adump5000ens7.j02.all.lammpstrj', '/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005bdump1000adump5000ens7.j03.all.lammpstrj', '/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005bdump1000adump5000ens7.j05.all.lammpstrj']\n",
      "['/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005bdump1000adump5000ens7.j02.all.lammpstrj', '/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005bdump1000adump5000ens7.j01.all.lammpstrj', '/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005bdump1000adump5000ens7.j05.all.lammpstrj', '/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005bdump1000adump5000ens7.all.data', '/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005bdump1000adump5000ens7.j03.all.lammpstrj']\n",
      "Setting the name of analyze file...\n",
      "\n",
      "\n",
      "N2000epsilon5.0r15.5lz379.5sig4.0nc3203dt0.005bdump1000adump5000ens7.j01-all is analyzing...\n"
     ]
    }
   ],
   "source": [
    "# 4 mins for ~4000 particles with one all trj\n",
    "# macbookmini\n",
    "parent = \"/Users/amirhsi_mini/research_data/trjs\"\n",
    "# macbookpro\n",
    "#parent = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "continuous = True\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(parent + '/N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "print(all_trjs)\n",
    "all_topo = glob(parent + '/N*' + group + '*')\n",
    "print(all_topo)\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs[:1]:\n",
    "    trj_info = SumRule(\n",
    "        all_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    trajectory = all_trj\n",
    "    topology = all_topo\n",
    "    if (lineage == 'segment') & (continuous is False):\n",
    "        print(\n",
    "            \"lineage is \"\n",
    "            f\"'{lineage}' \"\n",
    "            \"and 'continuous' is \"\n",
    "            f\"'{continuous}. \"\n",
    "            \"Please ensure the \"\n",
    "            f\"'{trajectory}' is NOT part of a sequence of trajectories.\")\n",
    "    print(\"Setting the name of analyze file...\\n\")\n",
    "    sim_info = SumRule(\n",
    "        trajectory,\n",
    "        geometry,\n",
    "        'all',\n",
    "        lineage\n",
    "    )\n",
    "    sim_name = sim_info.lineage_name + \"-\" + sim_info.group\n",
    "    print(\"\\n\" + sim_name + \" is analyzing...\")\n",
    "    # dict of bin edges:\n",
    "    bin_edges = {\n",
    "        'xEdge': {\n",
    "            'bin_size':  0.1 * min(sim_info.dmon, sim_info.dcrowd),\n",
    "            'lmin': -0.5 * sim_info.dcyl,\n",
    "            'lmax': 0.5 * sim_info.dcyl\n",
    "            },\n",
    "        'yEdge': {\n",
    "            'bin_size':  0.1 * min(sim_info.dmon, sim_info.dcrowd),\n",
    "            'lmin': -0.5 * sim_info.dcyl,\n",
    "            'lmax': 0.5 * sim_info.dcyl\n",
    "            },\n",
    "        'zEdge': {\n",
    "            'bin_size':  0.5 * min(sim_info.dmon, sim_info.dcrowd),\n",
    "            'lmin': -0.5 * sim_info.lcyl,\n",
    "            'lmax': 0.5 * sim_info.lcyl\n",
    "            }\n",
    "        }\n",
    "    # LJ time difference between two consecutive frames:\n",
    "    time_unit = \\\n",
    "        sim_info.dmon * np.sqrt(sim_info.mmon * sim_info.eps_others)\n",
    "    lj_nstep = sim_info.adump  # Sampling steps via dump command in Lammps\n",
    "    lj_dt = sim_info.dt\n",
    "    sim_real_dt = lj_nstep * lj_dt * time_unit\n",
    "    cell = mda.Universe(\n",
    "        topology,\n",
    "        trajectory,\n",
    "        topology_format='DATA',\n",
    "        format='LAMMPSDUMP',\n",
    "        lammps_coordinate_convention='unscaled',\n",
    "        atom_style=\"id resid type x y z\",\n",
    "        dt=sim_real_dt\n",
    "    )\n",
    "    # slicing trajectory based the continuous condition\n",
    "    if continuous:\n",
    "        sliced_trj = cell.trajectory[0: -1]\n",
    "    else:\n",
    "        sliced_trj = cell.trajectory\n",
    "    # selecting atom groups\n",
    "    crds = cell.select_atoms('resid 0')  # crowders\n",
    "    bug = cell.select_atoms('resid 1')  # the chain or monomers\n",
    "    # bin edges and histograms in different directions:\n",
    "    # x direction of the cylindrical coordinate system\n",
    "    x_hist_crd_info = prober.fixedsize_bins(\n",
    "        sim_name,\n",
    "        'xEdgeCrd',\n",
    "        bin_edges['xEdge']['bin_size'],\n",
    "        bin_edges['xEdge']['lmin'],\n",
    "        bin_edges['xEdge']['lmax'],\n",
    "        bin_type='ordinary',\n",
    "        save_edge=False,\n",
    "        save_to=save_to\n",
    "    )\n",
    "    x_hist_mon_info = prober.fixedsize_bins(\n",
    "        sim_name,\n",
    "        'xEdgeMon',\n",
    "        bin_edges['xEdge']['bin_size'],\n",
    "        bin_edges['xEdge']['lmin'],\n",
    "        bin_edges['xEdge']['lmax'],\n",
    "        bin_type='ordinary',\n",
    "        save_edge=False,\n",
    "        save_to=save_to\n",
    "    )\n",
    "    # y direction of the cylindrical coordinate system\n",
    "    y_hist_crd_info = prober.fixedsize_bins(\n",
    "        sim_name,\n",
    "        'yEdgeCrd',\n",
    "        bin_edges['yEdge']['bin_size'],\n",
    "        bin_edges['yEdge']['lmin'],\n",
    "        bin_edges['yEdge']['lmax'],\n",
    "        bin_type='ordinary',\n",
    "        save_edge=False,\n",
    "        save_to=save_to\n",
    "    )\n",
    "    y_hist_mon_info = prober.fixedsize_bins(\n",
    "        sim_name,\n",
    "        'yEdgeMon',\n",
    "        bin_edges['yEdge']['bin_size'],\n",
    "        bin_edges['yEdge']['lmin'],\n",
    "        bin_edges['yEdge']['lmax'],\n",
    "        bin_type='ordinary',\n",
    "        save_edge=False,\n",
    "        save_to=save_to\n",
    "    )\n",
    "    # z direction of the cylindrical coordinate system\n",
    "    z_hist_crd_info = prober.fixedsize_bins(\n",
    "        sim_name,\n",
    "        'zEdgeCrd',\n",
    "        bin_edges['zEdge']['bin_size'],\n",
    "        bin_edges['zEdge']['lmin'],\n",
    "        bin_edges['zEdge']['lmax'],\n",
    "        bin_type='ordinary',\n",
    "        save_edge=False,\n",
    "        save_to=save_to\n",
    "    )\n",
    "    z_hist_mon_info = prober.fixedsize_bins(\n",
    "        sim_name,\n",
    "        'zEdgeMon',\n",
    "        bin_edges['zEdge']['bin_size'],\n",
    "        bin_edges['zEdge']['lmin'],\n",
    "        bin_edges['zEdge']['lmax'],\n",
    "        bin_type='ordinary',\n",
    "        save_edge=False,\n",
    "        save_to=save_to\n",
    "    )\n",
    "    # check if any of the histograms are empty or not.\n",
    "    if any([\n",
    "            x_hist_mon_info['collector'].any() != 0,\n",
    "            x_hist_crd_info['collector'].any() != 0,\n",
    "            x_hist_mon_info['collector_std'].any() != 0,\n",
    "            x_hist_crd_info['collector_std'].any() != 0,\n",
    "            y_hist_mon_info['collector'].any() != 0,\n",
    "            y_hist_crd_info['collector'].any() != 0,\n",
    "            y_hist_mon_info['collector_std'].any() != 0,\n",
    "            y_hist_crd_info['collector_std'].any() != 0,\n",
    "            z_hist_mon_info['collector'].any() != 0,\n",
    "            z_hist_crd_info['collector'].any() != 0,\n",
    "            z_hist_mon_info['collector_std'].any() != 0,\n",
    "            z_hist_crd_info['collector_std'].any() != 0,\n",
    "            ]):\n",
    "        raise ValueError(\n",
    "            \"One of the histogram collectors is not empty!\")\n",
    "    # 3D hist\n",
    "    hist_crd_info_3d = {\n",
    "        'n_bins': (\n",
    "            x_hist_crd_info['n_bins'],\n",
    "            y_hist_crd_info['n_bins'],\n",
    "            z_hist_crd_info['n_bins']\n",
    "            ),\n",
    "        'bin_edges': [\n",
    "            x_hist_crd_info['bin_edges'],\n",
    "            y_hist_crd_info['bin_edges'],\n",
    "            z_hist_crd_info['bin_edges']\n",
    "            ],\n",
    "        'range':[\n",
    "            list(x_hist_crd_info['range']),\n",
    "            list(y_hist_crd_info['range']),\n",
    "            list(z_hist_crd_info['range'])\n",
    "        ] \n",
    "    }\n",
    "    hist_crd_info_3d['collector'] = np.zeros(hist_crd_info_3d['n_bins'])\n",
    "    hist_crd_info_3d['collector'] *= 0\n",
    "    hist_crd_info_3d['collector_std'] = hist_crd_info_3d['collector'].copy()\n",
    "    hist_mon_info_3d = {\n",
    "        'n_bins': (\n",
    "            x_hist_mon_info['n_bins'],\n",
    "            y_hist_mon_info['n_bins'],\n",
    "            z_hist_mon_info['n_bins']\n",
    "            ),\n",
    "        'bin_edges': [\n",
    "            x_hist_mon_info['bin_edges'],\n",
    "            y_hist_mon_info['bin_edges'],\n",
    "            z_hist_mon_info['bin_edges']\n",
    "            ],\n",
    "        'range': [\n",
    "            list(x_hist_mon_info['range']),\n",
    "            list(y_hist_mon_info['range']),\n",
    "            list(z_hist_mon_info['range'])\n",
    "        ]\n",
    "    }\n",
    "    hist_mon_info_3d['collector'] = np.zeros(hist_mon_info_3d['n_bins'])\n",
    "    hist_mon_info_3d['collector'] *= 0\n",
    "    hist_mon_info_3d['collector_std'] = hist_mon_info_3d['collector'].copy()\n",
    "    for _ in sliced_trj:\n",
    "        # histogram in 3 dimesional space\n",
    "        # crds\n",
    "        frame_hist, _ = np.histogramdd(\n",
    "            crds.positions,\n",
    "            bins=(x_hist_crd_info['bin_edges'],\n",
    "                  y_hist_crd_info['bin_edges'],\n",
    "                  z_hist_crd_info['bin_edges']),\n",
    "            range=(x_hist_crd_info['range'],\n",
    "                   y_hist_crd_info['range'],\n",
    "                   z_hist_crd_info['range'])\n",
    "        )\n",
    "        hist_crd_info_3d['collector'] += frame_hist\n",
    "        hist_crd_info_3d['collector_std'] += np.square(frame_hist)\n",
    "        # bug\n",
    "        frame_hist, _ = np.histogramdd(\n",
    "            bug.positions,\n",
    "            bins=(x_hist_mon_info['bin_edges'],\n",
    "                  y_hist_mon_info['bin_edges'],\n",
    "                  z_hist_mon_info['bin_edges']),\n",
    "            range=(x_hist_mon_info['range'],\n",
    "                   y_hist_mon_info['range'],\n",
    "                   z_hist_mon_info['range'])\n",
    "        )\n",
    "        hist_mon_info_3d['collector'] += frame_hist\n",
    "        hist_mon_info_3d['collector_std'] += np.square(frame_hist)\n",
    "\n",
    "    lastname = 'Crd'\n",
    "    np.save(\n",
    "        save_to + sim_name + '-XyzHist' + lastname + '.npy',\n",
    "        hist_crd_info_3d['collector']\n",
    "    )\n",
    "    np.save(\n",
    "        save_to + sim_name + '-XyzHistStd' + lastname + '.npy',\n",
    "        hist_crd_info_3d['collector_std']\n",
    "    )\n",
    "    np.save(\n",
    "        save_to + sim_name + '-XyzEdges' + lastname + '.npy',\n",
    "        hist_crd_info_3d['bin_edges']\n",
    "    )\n",
    "    lastname = 'Mon'\n",
    "    np.save(\n",
    "        save_to + sim_name + '-XyzHist' + lastname + '.npy',\n",
    "        hist_mon_info_3d['bin_edges']\n",
    "    )\n",
    "    np.save(\n",
    "        save_to + sim_name + '-XyzHistStd' + lastname + '.npy',\n",
    "        hist_mon_info_3d['collector_std']\n",
    "    )\n",
    "    np.save(\n",
    "        save_to + sim_name + '-XyzEdges' + lastname + '.npy',\n",
    "        hist_mon_info_3d['collector_std']\n",
    "    )\n",
    "    print('done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 mins for ~4000 particles with one all trj\n",
    "# macbookmini\n",
    "parent = \"/Users/amirhsi_mini/research_data/trjs\"\n",
    "# macbookpro\n",
    "#parent = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(parent + '/N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "print(all_trjs)\n",
    "all_topo = glob(parent + '/N*' + group + '*')\n",
    "print(all_topo)\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs[:1]:\n",
    "    trj_info = SumRule(\n",
    "        all_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        sum_rule_all_histdd(\n",
    "            all_topo, all_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        sum_rule_all_histdd(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trans-Foci project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "geometry = 'biaxial'\n",
    "group = 'bug'\n",
    "linage = 'whole'\n",
    "save_to = './'\n",
    "#macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "bug_pairs = glob(macbookpro_path + '/eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        geometry,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "#macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "macmini_path = '/Users/amirhsi_mini/research_data/test'\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(macmini_path + '/eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(macmini_path + '/eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFoci(\n",
    "        all_trj,\n",
    "        geometry=geometry,\n",
    "        group=group,\n",
    "        lineage=topo_lineage\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all(\n",
    "            all_topo, all_trj, geometry, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "\n",
    "        prober.trans_foci_all(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            geometry,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_v4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "905eddd834f47278e82c8803001c8cba7ff23ca6cd99b3eaaa45ba7f5342ab1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
