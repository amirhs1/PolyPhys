{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MDAnalysis as mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topology =  \"am5.0nm2ac1.0nc8953hl12.5sd0.1dt0.0005bdump2000adump5000tdump5000ens1.bug.data\"\n",
    "trajectory = \"am5.0nm2ac1.0nc8953hl12.5sd0.1dt0.0005bdump2000adump5000tdump5000ens1.bug.lammpstrj\"\n",
    "\n",
    "cell = mda.Universe(topology, trajectory, topology_format='DATA',\n",
    "        format='LAMMPSDUMP', lammps_coordinate_convention='unscaled',\n",
    "        atom_style=\"id type x y z\", dt=0.0005*2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[[10.36382  20.66004  11.28848 ]\n",
      " [10.37299  20.594189 16.41315 ]]\n",
      "[[10.36382  20.66004 ]\n",
      " [10.37299  20.594189]]\n"
     ]
    }
   ],
   "source": [
    "bug = cell.select_atoms(\"type 1\")\n",
    "odims = np.roll(np.arange(3),-2)[1:]\n",
    "print(odims)\n",
    "print(bug.positions)\n",
    "print(bug.positions[:, odims])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1058408, 1.1042049], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arctan2(bug.positions[:, odims[1]], bug.positions[:, odims[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDAnalysis.coordinates.base.FrameIteratorSliced"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliced_trj = cell.trajectory[0: -1]\n",
    "type(sliced_trj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Dict, List, Literal, ClassVar, Optional\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "\n",
    "def number_density_cube(\n",
    "    n_atom: float,\n",
    "    d_atom: float,\n",
    "    l_cube: float,\n",
    "    pbc: Optional[bool] = False\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the bulk number density of a species in a cubic box.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_atom : float\n",
    "        Number of particles.\n",
    "    d_atom : float\n",
    "        Diameter of the particle of the species.\n",
    "    l_cube : float\n",
    "        Length of one side of the cubic box.\n",
    "    pbc : bool, optional\n",
    "        Periodic boundary conditions along all box sides. If `True`,\n",
    "        :math:`v_{avail} = l_{cube}^3`; otherwise,\n",
    "        :math:`v_{avail} = (l_{cube} - d_{atom})^3`. Defaults to `False`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Bulk number density of the species in the cubic box.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The bulk number density is calculated as :math:`n_{atom} / v_{avail}`,\n",
    "    where `v_{avail}` is the available volume to the center of geometry of a\n",
    "    particle based on the presence of periodic boundary conditions.\n",
    "    \"\"\"\n",
    "    v_avail = (l_cube - int(pbc) * d_atom) ** 3\n",
    "    return n_atom / v_avail\n",
    "\n",
    "\n",
    "def volume_fraction_cube(\n",
    "    n_atom: float,\n",
    "    d_atom: float,\n",
    "    l_cube: float,\n",
    "    pbc: Optional[bool] = False\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the volume fraction of a species in a cubic box.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_atom : float\n",
    "        Number of particles.\n",
    "    d_atom : float\n",
    "        Diameter of the particle of the species.\n",
    "    l_cube : float\n",
    "        Length of one side of the cubic box.\n",
    "    pbc : bool, optional\n",
    "        Periodic boundary conditions along all box sides. If `True`,\n",
    "        :math:`v_{avail} = l_{cube}^3`; otherwise,\n",
    "        :math:`v_{avail} = (l_{cube} - d_{atom})^3`. Defaults to `False`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Volume fraction of the species in the cubic box.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The volume fraction is computed in the volume available to the center of\n",
    "    geometry of each particle. For point-like particles, the notion of volume\n",
    "    fraction is meaningless. For finite-size particles, the available volume\n",
    "    depends on whether periodic boundary conditions (PBCs) are applied.\n",
    "    \"\"\"\n",
    "    rho = number_density_cube(n_atom, d_atom, l_cube, pbc)\n",
    "    return rho * np.pi * d_atom ** 3 / 6\n",
    "\n",
    "\n",
    "def number_density_cylinder(\n",
    "    n_atom: float,\n",
    "    d_atom: float,\n",
    "    l_cyl: float,\n",
    "    d_cyl: float,\n",
    "    pbc: Optional[bool] = False\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the bulk number density of a species in a cylindrical confinement.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_atom : float\n",
    "        Number of particles.\n",
    "    d_atom : float\n",
    "        Diameter of the particle of the species.\n",
    "    l_cyl : float\n",
    "        Length of the cylindrical confinement.\n",
    "    d_cyl : float\n",
    "        Diameter of the cylindrical confinement.\n",
    "    pbc : bool, optional\n",
    "        Periodic boundary conditions along the longitudinal axis. If `True`,\n",
    "        :math:`v_{avail} = \\\\pi * l_{cyl} * (d_{cyl} - d_{atom})^2 / 4`;\n",
    "        otherwise, :math:`v_{avail} = \\\\pi * (l_{cyl} - d_{atom}) * (d_{cyl}\n",
    "        - d_{atom})^2 / 4`. Defaults to `False`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Bulk number density of the species in the cylindrical confinement.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The bulk number density is calculated as :math:`n_{atom} / v_{avail}`,\n",
    "    where `v_{avail}` is the available volume to the center of geometry of a\n",
    "    particle based on the presence of periodic boundary conditions.\n",
    "    \"\"\"\n",
    "    v_avail = np.pi * (l_cyl - int(pbc) * d_atom) * (d_cyl - d_atom) ** 2 / 4\n",
    "    return n_atom / v_avail\n",
    "\n",
    "\n",
    "def volume_fraction_cylinder(\n",
    "    n_atom: float,\n",
    "    d_atom: float,\n",
    "    l_cyl: float,\n",
    "    d_cyl: float,\n",
    "    pbc: Optional[bool] = False\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the volume fraction of a species in a cylindrical confinement.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_atom : float\n",
    "        Number of particles.\n",
    "    d_atom : float\n",
    "        Diameter of the particle of the species.\n",
    "    l_cyl : float\n",
    "        Length of the cylindrical confinement.\n",
    "    d_cyl : float\n",
    "        Diameter of the cylindrical confinement.\n",
    "    pbc : bool, optional\n",
    "        Periodic boundary conditions along the longitudinal axis. If `True`,\n",
    "        :math:`v_{avail} = \\\\pi * l_{cyl} * (d_{cyl} - d_{atom})^2 / 4`;\n",
    "        otherwise, :math:`v_{avail} = \\\\pi * (l_cyl - d_{atom}) * (d_{cyl}\n",
    "        - d_{atom})^2 / 4`. Defaults to `True`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Volume fraction of the species in the cylindrical confinement.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The volume fraction is computed in the volume available to the center of\n",
    "    geometry of each particle. For point-like particles, the notion of volume\n",
    "    fraction is meaningless. For finite-size particles, the available volume\n",
    "    depends on whether periodic boundary conditions (PBCs) are applied.\n",
    "    \"\"\"\n",
    "    rho = number_density_cylinder(n_atom, d_atom, l_cyl, d_cyl, pbc)\n",
    "    return rho * np.pi * d_atom ** 3 / 6\n",
    "\n",
    "def invalid_keyword(\n",
    "    keyword: str,\n",
    "    valid_keywords: List[str],\n",
    "    message: Optional[str] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Raises an error if `keyword` is not in `valid_keywords`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    keyword: str\n",
    "        Name of the `keyword`\n",
    "    valid_keywords: array of str\n",
    "        Array of valid keywords\n",
    "    message: str\n",
    "        Message to be printed.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `keyword` is not in `valid_keywords`.\n",
    "    \"\"\"\n",
    "    if message is None:\n",
    "        message = \" is an invalid option. Please select one of \" + \\\n",
    "            f\"{valid_keywords} options.\"\n",
    "    if keyword not in valid_keywords:\n",
    "        raise ValueError(f\"'{keyword}'\" + message)\n",
    "\n",
    "class ParserBase(ABC):\n",
    "    \"\"\"\n",
    "    Base parser class for extracting information from filenames or file paths\n",
    "    in a structured project. Designed to enforce lineage, geometry, and group\n",
    "    conventions across subclasses for specific project types.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    artifact : str\n",
    "        Artifact that is parsed for extracting information. Can be a filename\n",
    "        or filepath.\n",
    "    lineage : {'segment', 'whole', 'ensemble_long', 'ensemble', 'space'}\n",
    "        The lineage of the name, specifying the hierarchical level within the\n",
    "        project.\n",
    "    group : str\n",
    "        The particle group type in the project. Used for specific group-based\n",
    "        parsing.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    filepath : str\n",
    "        The filepath if `artifact` is a filepath, otherwise \"N/A\".\n",
    "    filename : str\n",
    "        The filename extracted from `artifact` if it is a filepath, otherwise\n",
    "        `artifact` itself.\n",
    "    group : {'bug', 'nucleoid', 'all'}\n",
    "        Particle group type in the project.\n",
    "    name : str\n",
    "        The unique name derived from `filename` based on `lineage` and `group`\n",
    "        conventions.\n",
    "    project_name : str\n",
    "        The name of the project class (subclass of `ParserBase`), automatically\n",
    "        assigned as the subclass's name.\n",
    "    lineage_genealogy: List[str]\n",
    "        List of parent lieages for an `artifact` with a given `lineage`.\n",
    "    attributes: List[str]\n",
    "        List of attributes specific to an `artifact` with a given `lineage`,\n",
    "        including parsed and computed attributes.\n",
    "\n",
    "    Class Attributes\n",
    "    ----------------\n",
    "    lineages : list of str\n",
    "        List of valid lineage types.\n",
    "    genealogy : dict of lists\n",
    "        Dictionary defining the hierarchical relationship between lineages.\n",
    "        Each lineage points to its parent lineages in a hierarchy.\n",
    "\n",
    "    Abstract Class Properties\n",
    "    -------------------------\n",
    "    geometry : str\n",
    "        Specifies geometry of the system\n",
    "    topology : str\n",
    "        Specifies how particles are connected (how) or not in the system.\n",
    "    groups : List[str]\n",
    "        Specifies particle groups in the system\n",
    "    genealogy_attributes : Dict[str, OrderedDict[str, str]]\n",
    "        Dictionary defining lineage-specific attributes for each lineage type.\n",
    "    project_attributes : Dict[str, List[str]]\n",
    "        Dictionary defining project-level attributes that remain constant but\n",
    "        are not extractable from a filename.\n",
    "\n",
    "    Abstract Instance Properties\n",
    "    ----------------------------\n",
    "    lineage_attributes: List[str]\n",
    "        List of attributes specific to an `artifact` with a given `lineage`,\n",
    "        including parsed attributes.\n",
    "    physical_attributes: List[str]\n",
    "        List of attributes specific to an `artifact` with a given `lineage`,\n",
    "        including computed attributes.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    _find_name() -> None\n",
    "        Parses and sets the unique name based on `lineage` and `group`.\n",
    "    _set_parents() -> None\n",
    "        Sets pattern names for each `lineage` based on `_genealogy`.\n",
    "    _initiate_attributes() -> None\n",
    "        Defines and initializes subclass-specific attributes. (Abstract method)\n",
    "    _parse_lineage_name() -> None\n",
    "        Parses lineage-specific attributes based on the filename.\n",
    "        (Abstract method)\n",
    "    _bulk_attributes() -> None\n",
    "        Computes physical attributes for the current lineage based on primary\n",
    "        attributes. (Abstract method)\n",
    "    \"\"\"\n",
    "    _lineages: ClassVar[List[str]] = \\\n",
    "        [\"segment\", \"whole\", \"ensemble_long\", \"ensemble\", \"space\"]\n",
    "    _genealogy: ClassVar[Dict[str, List[str]]] = {\n",
    "        \"segment\": [\"segment\", \"whole\", \"ensemble_long\", \"ensemble\", \"space\"],\n",
    "        \"whole\": [\"whole\", \"ensemble_long\", \"ensemble\", \"space\"],\n",
    "        \"ensemble_long\": [\"ensemble_long\", \"ensemble\", \"space\"],\n",
    "        \"ensemble\": [\"ensemble\", \"space\"],\n",
    "        \"space\": [\"space\"],\n",
    "    }\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def _geometry(self) -> str:\n",
    "        \"\"\"\n",
    "        Defines the system geometry for the parser subclass.\n",
    "        \"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def _groups(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        List of valid group names for the subclass.\n",
    "        \"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def _topology(self) -> str:\n",
    "        \"\"\"\n",
    "        Defines the polymer topology for the parser subclass.\n",
    "        \"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def _genealogy_attributes(self) -> Dict[str, OrderedDict[str, str]]:\n",
    "        \"\"\"\n",
    "        Dictionary of lineage-specific attributes. Each key is a lineage type,\n",
    "        and each value is an OrderedDict mapping attribute names to their\n",
    "        short-form representations.\n",
    "        \"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def _project_attributes(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Dictionary of project attributes. Each key is a lineage type,\n",
    "        and each value is an OrderedDict mapping attribute names to their\n",
    "        short-form representations.\n",
    "        \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        artifact: str,\n",
    "        lineage: Literal[\"segment\", \"whole\", \"ensemble_long\", \"ensemble\",\n",
    "                         \"space\"],\n",
    "        group: str\n",
    "    ) -> None:\n",
    "        self._filepath, self._filename = (\n",
    "            (\"N/A\", artifact) if '/' not in artifact and '\\\\' not in artifact\n",
    "            else os.path.split(artifact)\n",
    "        )\n",
    "        invalid_keyword(lineage, self._lineages)\n",
    "        invalid_keyword(group, self._groups)\n",
    "        self._lineage = lineage\n",
    "        self._group = group\n",
    "        self._project_name = self.__class__.__name__\n",
    "        self._lineage_genealogy = self._genealogy[lineage]\n",
    "        self._lineage_attributes = \\\n",
    "            list(self._genealogy_attributes[lineage].keys())\n",
    "        self._physical_attributes = self._project_attributes[lineage]\n",
    "        self._lineage_genealogy = self._genealogy[lineage]\n",
    "        self._attributes = \\\n",
    "            self._lineage_attributes + self._physical_attributes\n",
    "        self._find_name()\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"\n",
    "        Provides a formatted summary of the parser instance.\n",
    "        \"\"\"\n",
    "        observation = (\n",
    "            f\"Arifact:\\n\"\n",
    "            f\"    Name: '{self.filename}',\\n\"\n",
    "            f\"    Geometry: '{self._geometry}',\\n\"\n",
    "            f\"    Group: '{self._group}',\\n\"\n",
    "            f\"    Lineage: '{self._lineage}',\\n\"\n",
    "            f\"    Topology: '{self._topology}'\"\n",
    "        )\n",
    "        return observation\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (\n",
    "            f\"Artifact('{self.filename}' in geometry\"\n",
    "            f\" '{self._geometry}' from group '{self._group}' with\"\n",
    "            f\" lineage '{self._lineage}' and\"\n",
    "            f\" topology '{self._topology}')\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def filename(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns the filename, either extracted from the path or the name\n",
    "        itself.\n",
    "        \"\"\"\n",
    "        return self._filename\n",
    "\n",
    "    @property\n",
    "    def filepath(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns the full filepath or 'N/A' if not a valid path.\n",
    "        \"\"\"\n",
    "        return self._filepath\n",
    "\n",
    "    @property\n",
    "    def lineage(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns the current lineage.\n",
    "        \"\"\"\n",
    "        return self._lineage\n",
    "\n",
    "    def _find_name(self) -> None:\n",
    "        \"\"\"\n",
    "        Parses and sets the unique `lineage_name` from the filename\n",
    "        based on the `lineage` and `group`.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - For 'segment' and 'whole' lineages, names typically end with the\n",
    "          group keyword or a hyphen.\n",
    "        - For 'ensemble_long', 'ensemble', and 'space', names are derived\n",
    "          from the first substring in the filename.\n",
    "        \"\"\"\n",
    "        if self._lineage in [\"segment\", \"whole\"]:\n",
    "            self._name = \\\n",
    "                self.filename.split(\".\" + self._group)[0].split(\"-\")[0]\n",
    "        else:\n",
    "            self._name = self._filename.split(\"-\")[0]\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns the unique name parsed from the filename.\n",
    "        \"\"\"\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def project_name(self) -> str:\n",
    "        \"\"\"\n",
    "        Returns the project (parser class) name,\n",
    "        \"\"\"\n",
    "        return self._project_name\n",
    "\n",
    "    @property\n",
    "    def attributes(self) -> Dict[str, OrderedDict[str, str]]:\n",
    "        \"\"\"\n",
    "        Returns lineage-specific andp project attributes for an artifact.\n",
    "        \"\"\"\n",
    "        return self._attributes[self._lineage]\n",
    "\n",
    "    @property\n",
    "    def lineage_genealogy(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Returns the parents of a given `lineage`.\n",
    "        \"\"\"\n",
    "\n",
    "    @property\n",
    "    def lineage_attributes(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Returns lineage-specific attributes for an artifact with a given\n",
    "        `lineage`.\n",
    "        \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def physical_attributes(self) -> List[str]:\n",
    "        \"\"\"\n",
    "        Returns project-level attributes for an artifact with a given\n",
    "        `lineage`.\n",
    "        \"\"\"\n",
    "\n",
    "    @property\n",
    "    def genealogy_attributes(self) -> Dict[str, OrderedDict[str, str]]:\n",
    "        \"\"\"\n",
    "        Returns lineage-specific attributes for the all the lineages.\n",
    "        \"\"\"\n",
    "        return self._genealogy_attributes\n",
    "\n",
    "    @property\n",
    "    def project_attributes(self) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Returns project-level attributes for the all the lineages.\n",
    "        \"\"\"\n",
    "        return self._project_attributes\n",
    "\n",
    "    @abstractmethod\n",
    "    def _initiate_attributes(self) -> None:\n",
    "        \"\"\"\n",
    "        Defines and initiates the project attributes. Lineage attributes are\n",
    "        set dynamically via `_parse_name` method.\n",
    "        \"\"\"\n",
    "\n",
    "    def _set_parents(self) -> None:\n",
    "        \"\"\"\n",
    "        Sets parent lineage names for each lineage type, following the\n",
    "        hierarchy defined in `_genealogy`.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The `self._genealogy` defines the following parent-child hierarchy:\n",
    "\n",
    "            - space -> ensemble -> ensemble_long -> whole -> segment\n",
    "\n",
    "        Each lineage on the left has all the lineages on its right.\n",
    "        \"\"\"\n",
    "        for lineage_name in self._lineages:\n",
    "            lineage_value = \"N/A\"\n",
    "            if lineage_name in self._genealogy[self._lineage]:\n",
    "                lineage_value = \"\"\n",
    "                lineage_attr = self._genealogy_attributes[lineage_name]\n",
    "                for attr_long, attr_short in lineage_attr.items():\n",
    "                    lineage_value += \\\n",
    "                            f\"{attr_short}{getattr(self, attr_long)}\"\n",
    "            setattr(self, lineage_name, lineage_value)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _parse_name(self) -> None:\n",
    "        \"\"\"\n",
    "        Parses lineage attributes from the `name` attribute, assigning them\n",
    "        dynamically as class attributes.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Lineage attributes are macroscopic physical attributes of the systems.\n",
    "        They are added to the class dynamically as new class attribute upon\n",
    "        class instantiation.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def _dependant_attributes(self) -> None:\n",
    "        \"\"\"\n",
    "        Calculates system attributes based on parsed values.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "class TwoMonDep(ParserBase):\n",
    "    \"\"\"\n",
    "    Extracts structured information about an artifact from its name in the\n",
    "    *TwoMonDep* project, utilizing specific filename patterns.\n",
    "\n",
    "    Each lineage level has a unique naming pattern used to parse key physical\n",
    "    and system attributes:\n",
    "\n",
    "    - `segment`: am#nm#ac#nc#hl#sd#dt#bdump#adump$tdump#ens#.j#\n",
    "      One of multiple chunks of a complete artifact.\n",
    "    - `whole`: am#nm#ac#nc#hl#sd#dt#bdump#adump$tdump#ens#\n",
    "      A complete artifact. It may be a collection of segments.\n",
    "    - `ensemble_long`: am#nm#ac#nc#hl#sd#dt#bdump#adump$tdump#\n",
    "      Detailed name for an 'ensemble' artifact.\n",
    "    - `ensemble`: nm#am#ac#nc#sd#\n",
    "      Short name for an 'ensemble' artifact.\n",
    "    - `space`: nm#am#ac#\n",
    "      A 'space' artifact.\n",
    "\n",
    "    For the above four lineages, the short names (eywords) are physical\n",
    "    attributes where their values (shown by \"#\" sign) are float or integer\n",
    "    number. See `genealogy_attributes` below for long names of attribues.\n",
    "\n",
    "    Other than attributes inhertied from the parent class `ParserBase` as\n",
    "    explained below, this class dynamically defines new attributes based on the\n",
    "    list of physical attributes of a given `lineage` as define in the\n",
    "    `genealogy_attributes` class attribute.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    artifact : str\n",
    "        Name to be parsed, either a filename or filepath.\n",
    "    lineage : {'segment', 'whole', 'ensemble_long', 'ensemble', 'space'}\n",
    "        Type of the lineage of the name.\n",
    "    group : {\"bug\", \"all\"}\n",
    "        Particle group type, with `bug` representing a single polymer.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    dmon : float\n",
    "        Size (diameter) of a monomer. Its associated keyword is 'am'.\n",
    "    nmon : int\n",
    "        Number of monomers. Its associated keyword is 'N'.\n",
    "    dcrowd: float\n",
    "        Size (diameter) of a crowder. Its associated keyword is 'ac'.\n",
    "    ncrowd : int\n",
    "        Number of crowders. Its associated keyword is 'nc'.\n",
    "    lcube : float\n",
    "        Length of the simulation box, inferred from 'hl' keyword\n",
    "        (half-length of hthe simulation box).\n",
    "    d_sur : float\n",
    "        Surface-to-surface distance between two monomers fixed in space.\n",
    "        Its associated keyword is 'sd'.\n",
    "    dt : float\n",
    "        Simulation timestep. Its associated keyword is 'dt'.\n",
    "    bdump : int\n",
    "        Frequency by which 'bug' configurations are dumped in a 'bug'\n",
    "        trajectory file. Its associated keyword is 'bdump'.\n",
    "    adump : int\n",
    "        Frequency by which 'all' configurations are dumped in a 'segment'\n",
    "        trajectory file. Its associated keyword is 'adump'.\n",
    "    tdump : int\n",
    "        Frequency by which 'themo' variables are written in a 'lammps'\n",
    "        log file. Its associated keyword is 'tdump'.\n",
    "    ensemble_id : int\n",
    "        The ensemble number of a 'whole' artifact in an ensemble. Its\n",
    "        associated keyword is 'ens'.\n",
    "    segment_id : int\n",
    "        The 'segment_id' keyword starts with 'j', ends with a 'padded'\n",
    "        number such as '05' or '14', showing the succession of segments\n",
    "        in a artifact file. Its associated keyword is 'j'.\n",
    "    rho_bulk_m : float\n",
    "        Bulk number density fraction of monomers.\n",
    "    phi_bulk_m : float\n",
    "        Bulk volume fraction of monomers\n",
    "    rho_bulk_c : float\n",
    "        Bulk number density fraction of crowders\n",
    "    phi_bulk_c : float\n",
    "        Bulk volume fraction of crowders\n",
    "    space : str\n",
    "        A space's name.\n",
    "    ensemble : str, \"N/A\"\n",
    "        An ensemble's name if applicable, otherwise \"N/A\"\n",
    "    ensemble_long : str, \"N/A\"\n",
    "        The name of ensemble derived from 'whole' name if applicable,\n",
    "        otherwise \"N/A\"\n",
    "    whole : str, \"N/A\"\n",
    "        A whole's name if applicable, otherwise \"N/A\"\n",
    "    segment : str, \"N/A\"\n",
    "        A segment's name if applicable, otherwise \"N/A\"\n",
    "    lineage_attributes: List[str]\n",
    "        List of attributes specific to an `artifact` with a given `lineage`,\n",
    "        including parsed attributes.\n",
    "    physical_attributes: List[str]\n",
    "        List of attributes specific to an `artifact` with a given `lineage`,\n",
    "        including computed attributes.\n",
    "    attributes: List[str]\n",
    "        List of attributes specific to an `artifact` with a given `lineage`,\n",
    "        including parsed and computed attributes.\n",
    "    lineage_genealogy: List[str]\n",
    "        List of parent lieages for an `artifact` with a given `lineage`.\n",
    "\n",
    "    Class Attributes\n",
    "    ----------------\n",
    "    _geometry : str\n",
    "        Specifies geometry of the system\n",
    "    _topology : str\n",
    "        Specifies how particles are connected (how) or not in the system.\n",
    "    _groups : List[str]\n",
    "        Specifies particle groups in the system\n",
    "    _genealogy_attributes : Dict[str, Dict[str, str]]\n",
    "        Maps `lineage` names to attribute keywords for parsing.\n",
    "    _project_attributes : Dict[str, List[Optional[str]]]\n",
    "        Specifies additional physical attributes for each `lineage`.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Creating a instance to parse a filename with specified lineage and group.\n",
    "\n",
    "    >>> artifact = (\n",
    "    ...\"nm2am5.0ac1.0\"\n",
    "    ...\"space\",\n",
    "    ...\"bug\"\n",
    "    ... )\n",
    "    >>> print(artifact.nmon)\n",
    "    2\n",
    "    \"\"\"\n",
    "    _geometry: ClassVar[str] = \"cubic\"\n",
    "    _topology: ClassVar[str] = \"atomic\"\n",
    "    _groups: ClassVar[List[str]] = [\"bug\", \"all\"]\n",
    "\n",
    "    _genealogy_attributes: ClassVar[Dict[str, OrderedDict[str, str]]] = {\n",
    "        # Pattern: am#nm#ac#nc#hl#sd#dt#bdump#adump$tdump#ens#.j#\n",
    "        \"segment\": OrderedDict({\n",
    "            \"dmon\": \"am\", \"nmon\": \"nm\", \"dcrowd\": \"ac\", \"ncrowd\": \"nc\",\n",
    "            \"lcube\": \"hl\", \"d_sur\": \"sd\", \"dt\": \"dt\", \"bdump\": \"bdump\",\n",
    "            \"adump\": \"adump\", \"tdump\": \"tdump\", \"ensemble_id\": \"ens\",\n",
    "            \"segment_id\": \"j\"}\n",
    "            ),\n",
    "        # Pattern: am#nm#ac#nc#hl#sd#dt#bdump#adump$tdump#ens#\n",
    "        \"whole\": OrderedDict({\n",
    "            \"dmon\": \"am\", \"nmon\": \"nm\", \"dcrowd\": \"ac\", \"ncrowd\": \"nc\",\n",
    "            \"lcube\": \"hl\", \"d_sur\": \"sd\", \"dt\": \"dt\", \"bdump\": \"bdump\",\n",
    "            \"adump\": \"adump\", \"tdump\": \"tdump\", \"ensemble_id\": \"ens\"}\n",
    "            ),\n",
    "        # Pattern: am#nm#ac#nc#hl#sd#dt#bdump#adump$tdump# :\n",
    "        \"ensemble_long\": OrderedDict({\n",
    "            \"dmon\": \"am\", \"nmon\": \"nm\", \"dcrowd\": \"ac\", \"ncrowd\": \"nc\",\n",
    "            \"lcube\": \"hl\", \"d_sur\": \"sd\", \"dt\": \"dt\", \"bdump\": \"bdump\",\n",
    "            \"adump\": \"adump\", \"tdump\": \"tdump\"}\n",
    "            ),\n",
    "        # Pattern: nm#am#ac#nc#sd :\n",
    "        \"ensemble\": OrderedDict(\n",
    "            {\"dmon\": \"am\", \"nmon\": \"nm\", \"dcrowd\": \"ac\", \"ncrowd\": \"nc\",\n",
    "             \"d_sur\": \"sd\"}\n",
    "             ),\n",
    "        # pttern: nm#am#ac# :\n",
    "        \"space\": OrderedDict(\n",
    "            {\"dmon\": \"am\", \"nmon\": \"nm\", \"dcrowd\": \"ac\", \"ncrowd\": \"nc\"}\n",
    "            )\n",
    "    }\n",
    "\n",
    "    _project_attributes: ClassVar[Dict[str, List[str]]] = {\n",
    "        \"segment\": [\"phi_bulk_m\", \"rho_bulk_m\", \"phi_bulk_c\", \"rho_bulk_c\"],\n",
    "        \"whole\": [\"phi_bulk_m\", \"rho_bulk_m\", \"phi_bulk_c\", \"rho_bulk_c\"],\n",
    "        \"ensemble_long\": [\"phi_bulk_m\", \"rho_bulk_m\", \"phi_bulk_c\",\n",
    "                          \"rho_bulk_c\"],\n",
    "        \"ensemble\": [],\n",
    "        \"space\": []\n",
    "        }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        artifact: str,\n",
    "        lineage: str,\n",
    "        group: Literal[\"bug\", \"all\"]\n",
    "    ) -> None:\n",
    "        super().__init__(artifact, lineage, group)\n",
    "        self._initiate_attributes()\n",
    "        self._parse_name()\n",
    "        self._set_parents()\n",
    "        if self.lineage in [\"segment\", \"whole\", \"ensemble_long\"]:\n",
    "            self._dependant_attributes()\n",
    "\n",
    "    def _initiate_attributes(self) -> None:\n",
    "        \"\"\"\n",
    "        Defines and initiates the project attributes.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The negative initial values are unphysical.\n",
    "        \"\"\"\n",
    "        if self._lineage in [\"segment\", \"whole\", \"ensemble_long\"]:\n",
    "            self.phi_bulk_m: float = -1\n",
    "            self.rho_bulk_m: float = -1\n",
    "            self.phi_bulk_c: float = -1\n",
    "            self.rho_bulk_c: float = -1\n",
    "\n",
    "    def _parse_name(self) -> None:\n",
    "        \"\"\"\n",
    "        Parses lineage attributes from the `name` attribute, assigning them\n",
    "        dynamically as class attributes.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Lineage attributes are macroscopic physical attributes of the systems.\n",
    "        They are added to the class dynamically as new class attribute upon\n",
    "        class instantiation.\n",
    "        \"\"\"\n",
    "        name_strs = re.compile(r\"([a-zA-Z\\-]+)\")\n",
    "        words = name_strs.split(self._name)\n",
    "        attrs_float = [\"dmon\", \"lcube\", \"dcrowd\", \"dt\", \"d_sur\"]\n",
    "        for attr, keyword in self._genealogy_attributes[self._lineage].items():\n",
    "            try:\n",
    "                val = words[words.index(keyword) + 1]\n",
    "                setattr(self,\n",
    "                        attr,\n",
    "                        float(val) if attr in attrs_float else int(float(val)))\n",
    "                if keyword == \"hl\":\n",
    "                    # Cube full side from its half-side\n",
    "                    setattr(self, attr, 2 * getattr(self, attr))\n",
    "            except ValueError:\n",
    "                print(f\"'{keyword}' attribute not found in '{self._name}'\")\n",
    "\n",
    "    def _dependant_attributes(self) -> None:\n",
    "        \"\"\"\n",
    "        Calculates system attributes based on parsed values.\n",
    "        \"\"\"\n",
    "        self.rho_bulk_m = number_density_cube(\n",
    "            getattr(self, \"nmon\"),\n",
    "            getattr(self, \"dmon\"),\n",
    "            getattr(self, \"lcube\")\n",
    "        )\n",
    "        self.phi_bulk_m = volume_fraction_cube(\n",
    "            getattr(self, \"nmon\"),\n",
    "            getattr(self, \"dmon\"),\n",
    "            getattr(self, \"lcube\")\n",
    "        )\n",
    "        self.rho_bulk_c = number_density_cube(\n",
    "            getattr(self, \"ncrowd\"),\n",
    "            getattr(self, \"dcrowd\"),\n",
    "            getattr(self, \"lcube\")\n",
    "        )\n",
    "        self.phi_bulk_c = volume_fraction_cube(\n",
    "            getattr(self, \"ncrowd\"),\n",
    "            getattr(self, \"dcrowd\"),\n",
    "            getattr(self, \"lcube\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_filepath N/A\n",
      "_filename am5.0nm2ac1.0nc8953hl12.5sd5.0dt0.0005bdump2000adump5000tdump5000ens1\n",
      "_lineage whole\n",
      "_group bug\n",
      "_project_name TwoMonDep\n",
      "_lineage_genealogy ['whole', 'ensemble_long', 'ensemble', 'space']\n",
      "_lineage_attributes ['dmon', 'nmon', 'dcrowd', 'ncrowd', 'lcube', 'd_sur', 'dt', 'bdump', 'adump', 'tdump', 'ensemble_id']\n",
      "_physical_attributes ['phi_bulk_m', 'rho_bulk_m', 'phi_bulk_c', 'rho_bulk_c']\n",
      "_attributes ['dmon', 'nmon', 'dcrowd', 'ncrowd', 'lcube', 'd_sur', 'dt', 'bdump', 'adump', 'tdump', 'ensemble_id', 'phi_bulk_m', 'rho_bulk_m', 'phi_bulk_c', 'rho_bulk_c']\n",
      "_name am5.0nm2ac1.0nc8953hl12.5sd5.0dt0.0005bdump2000adump5000tdump5000ens1\n",
      "phi_bulk_m 0.008377580409572781\n",
      "rho_bulk_m 0.000128\n",
      "phi_bulk_c 0.3000179096276204\n",
      "rho_bulk_c 0.572992\n",
      "dmon 5.0\n",
      "nmon 2\n",
      "dcrowd 1.0\n",
      "ncrowd 8953\n",
      "lcube 25.0\n",
      "d_sur 5.0\n",
      "dt 0.0005\n",
      "bdump 2000\n",
      "adump 5000\n",
      "tdump 5000\n",
      "ensemble_id 1\n",
      "segment N/A\n",
      "whole am5.0nm2ac1.0nc8953hl25.0sd5.0dt0.0005bdump2000adump5000tdump5000ens1\n",
      "ensemble_long am5.0nm2ac1.0nc8953hl25.0sd5.0dt0.0005bdump2000adump5000tdump5000\n",
      "ensemble am5.0nm2ac1.0nc8953sd5.0\n",
      "space am5.0nm2ac1.0nc8953\n"
     ]
    }
   ],
   "source": [
    "a = TwoMonDep(\n",
    "    \"am5.0nm2ac1.0nc8953hl12.5sd5.0dt0.0005bdump2000adump5000tdump5000ens1\",\n",
    "    \"whole\",\n",
    "    \"bug\"\n",
    ")\n",
    "for key, val in a.__dict__.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "even mid point\n",
      "3\n",
      "odd mid point\n",
      "2\n",
      "Original DataFrame (even):\n",
      "   bin_center\n",
      "0          -2\n",
      "1          -1\n",
      "2          -1\n",
      "3           1\n",
      "4           2\n",
      "5           3\n",
      "\n",
      "Extracted ens_neg (even):\n",
      "   bin_center\n",
      "0          -2\n",
      "1          -1\n",
      "2          -1\n",
      "\n",
      "Extracted ens_pos (even):\n",
      "   bin_center\n",
      "3           1\n",
      "4           2\n",
      "5           3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrames with an odd and even number of rows\n",
    "data_odd = {'bin_center': [-2, -1, 0, 1, 2]}\n",
    "data_even = {'bin_center': [-2, -1, -1, 1, 2, 3]}\n",
    "\n",
    "ens_avg_even = pd.DataFrame(data_even)\n",
    "ens_avg_odd = pd.DataFrame(data_odd)\n",
    "\n",
    "\n",
    "# Finding the midpoints and extracting ens_pos for each case\n",
    "df_len_even = len(ens_avg_even)\n",
    "df_len_odd = len(ens_avg_odd)\n",
    "#print(df_len_odd)\n",
    "\n",
    "print(df_len_even % 2 == 0)\n",
    "print(df_len_odd % 2 == 0)\n",
    "\n",
    "mid_point_even = df_len_even // 2\n",
    "print(\"even mid point\")\n",
    "print(mid_point_even)\n",
    "mid_point_odd = df_len_odd // 2\n",
    "print(\"odd mid point\")\n",
    "print(mid_point_odd)\n",
    "\n",
    "# - (df_len_even % 2 == 0)\n",
    "ens_neg_even = ens_avg_even.iloc[:mid_point_even].copy()\n",
    "ens_pos_even = ens_avg_even.iloc[mid_point_even+(df_len_even % 2 == 1):].copy()\n",
    "\n",
    "ens_neg_odd = ens_avg_odd.iloc[:mid_point_odd].copy()\n",
    "ens_pos_odd = ens_avg_odd.iloc[mid_point_odd+(df_len_odd % 2 == 1):].copy() \n",
    "\n",
    "print(\"Original DataFrame (even):\")\n",
    "print(ens_avg_even)\n",
    "print(\"\\nExtracted ens_neg (even):\")\n",
    "print(ens_neg_even)\n",
    "print(\"\\nExtracted ens_pos (even):\")\n",
    "print(ens_pos_even)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original DataFrame (odd):\n",
      "   bin_center\n",
      "0          -2\n",
      "1          -1\n",
      "2           0\n",
      "3           1\n",
      "4           2\n",
      "\n",
      "Extracted ens_neg (odd):\n",
      "   bin_center\n",
      "0          -2\n",
      "1          -1\n",
      "\n",
      "Extracted ens_pos (odd):\n",
      "   bin_center\n",
      "3           1\n",
      "4           2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nOriginal DataFrame (odd):\")\n",
    "print(ens_avg_odd)\n",
    "print(\"\\nExtracted ens_neg (odd):\")\n",
    "print(ens_neg_odd)\n",
    "print(\"\\nExtracted ens_pos (odd):\")\n",
    "print(ens_pos_odd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['camel', 'Case']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re.findall(r'[A-Z]?[a-z]+|[A-Z]+(?=[A-Z]|$)', 'camelCase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e', 'f'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = {'a', 'b', 'c', 'd'}\n",
    "test_b = set({'a', 'b', 'c', 'd', 'e', 'f'})\n",
    "test_b.difference(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.55 -3.65 -2.75 -1.85 -0.95 -0.05  0.85  1.75  2.65  3.55  4.45  5.35]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "lmin = -5\n",
    "lmax = 5\n",
    "delta = 0.9\n",
    "bin_edges = np.arange(lmin, lmax + delta, delta)\n",
    "bin_center =  0.5 *(bin_edges[:-1] + bin_edges[1:])\n",
    "print(bin_center)\n",
    "len(bin_center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polylab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
