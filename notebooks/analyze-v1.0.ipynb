{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c72ab68",
   "metadata": {},
   "source": [
    "# The analyze phase:\n",
    "In this phase, if there are any segment files in the *probe* phase, they are merged into *whole* files. Then,  ensemble, ensemble-averaged, and space files are created from whole files.\n",
    "\n",
    "### To-do list:\n",
    "\n",
    "- [x] analyzing *bug* *segement* and *whole* files in both project in a serial manner.\n",
    "- [ ] analyzing *bug* *segement* and *whole* files in both project in a parallel manner with Dask: memory linkage problem\n",
    "- [ ] analyzing *all* *segement* and *whole* files in both project in a serial manner.\n",
    "- [ ] analyzing *all* *segement* and *whole* files in both project in a parallel manner with Dask\n",
    "\n",
    "### Naming convention:\n",
    "\n",
    "This is the pattern of file or directory names:\n",
    "\n",
    "1. **whole** files: whole-group-property_[-measure][-stage][.ext]\n",
    "2. **ensemble** files: ensemble-group-property_[-measure][-stage][.ext]\n",
    "3. **ensemble_long** files: ensemble_long-group-property_[-measure][-stage][.ext]\n",
    "4. **space** files: space-group-property_[-measure][-stage][.ext]\n",
    "5. **all in one** files: space-group-**species**-**allInOne**-property-_[-measure][-stage][.ext]\n",
    "\n",
    "[keyword] means that the keyword in the file name is option. [-measure] is a physical measurement such as the auto correlation function (AFC) done on the physical 'property_'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c655fe51-1d37-484d-a7f4-da15fb3b42a6",
   "metadata": {},
   "source": [
    "### Settings for testing and running on a PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48844557-6d5d-40f3-8263-c794302112ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parents_stamps(\n",
    "    stamps: pd.DataFrame,\n",
    "    geometry: str,\n",
    "    group: str,\n",
    "    lineage: str,\n",
    "    properties: Optional[Dict[str, Callable]] = None,\n",
    "    save_to: Optional[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"perform merging/ensemble-averaging over all the 'segment/'whole'\n",
    "    simulation stamps in a 'space' in a given `geometry` for a given\n",
    "    `group` basedon the given `lineage`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stamps: DataFrame\n",
    "        Dataframe of all the simulation stamps in the `group` in a space.\n",
    "    geometry : {'biaxial', 'slit', 'box'}\n",
    "        Shape of the simulation box\n",
    "    group: {'bug', 'all'}\n",
    "        Type of the particle group.\n",
    "    lineage: {('segment', 'whole'}\n",
    "        Lineage type of children's stamps.\n",
    "    properties: dict of str\n",
    "        A dictionary in which the keys are properties such as the time-\n",
    "        averaged radius of gyration which are measured during the 'probe'\n",
    "        phase and the values are user-defined or numpy functions which are\n",
    "        used as the aggregation function bu pandas.\n",
    "    save_to : str, default None\n",
    "        Absolute or relative path of a directory to which outputs are saved.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If `lineage='segment'`, then stamps are for 'segments' and they have only\n",
    "    different 'segment_id' for a given 'whole' parent. If `lineage='whole'`,\n",
    "    then stamps are for 'wholes' and they have only different 'ensemble_id'\n",
    "    for a given 'ensemble' parent. In either scenarios, the 'stamp' files\n",
    "    have 'segment' and 'segment_id' columns. If `lineage='whole'`, the\n",
    "    values of these two columns are \"N/A\".\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    stamps_avg: pd.DataFrame\n",
    "        Dataframe of all the parents stamps in the `group` in a space.\n",
    "    \"\"\"\n",
    "    invalid_keyword(geometry, ['biaxial', 'slit', 'box'])\n",
    "    invalid_keyword(group, ['bug', 'all'])\n",
    "    invalid_keyword(lineage, ['segment', 'whole'])\n",
    "    # attributes, properties and genealogy:\n",
    "    stamps_cols = list(stamps.columns)\n",
    "    try:\n",
    "        stamps_cols.remove(\"lineage_name\")\n",
    "        stamps_cols.remove(lineage)\n",
    "    except ValueError:\n",
    "        print(\n",
    "            f\"'lineage_name' and '{lineage}'\"\n",
    "            \" columns are not among in stamps column:\"\n",
    "            f\"'{stamps_cols}', they are probably removed in\"\n",
    "            \"a previous call of 'parents_stamps' function.\"\n",
    "        )\n",
    "    # aggregation dictionary: See Note above.\n",
    "    agg_funcs = dict()\n",
    "    attr_agg_funcs = ['last'] * len(stamps_cols)\n",
    "    agg_funcs.update(zip(stamps_cols, attr_agg_funcs))\n",
    "    if properties is not None:  # add/update agg funcs for properties.\n",
    "        agg_funcs.update(properties)\n",
    "    # Handing 'lineage'-specific details:\n",
    "    if lineage == 'whole':\n",
    "        parent_groupby = 'ensemble_long'\n",
    "        # If the 'whole' stamps are generated directly in the 'probe' phase,\n",
    "        # then 'segment' and 'segment_id' columns are \"N/A\" and are removed\n",
    "        # from the list of stamps columns that are added to the parents\n",
    "        # stamps.\n",
    "        # There is no need to have the \"n_segment\" column in the parent\n",
    "        # stamps, so it is removed. The \"whole\" stamps directly generated\n",
    "        # in the \"probe\" phase do not have such a column, but those generated\n",
    "        # from \"segment\" stamps have.\n",
    "        try:\n",
    "            stamps_cols.remove(\"segment_id\")  # segment_id is \"N/A\"\n",
    "            stamps_cols.remove(\"segment\")  # segment_id is \"N/A\"\n",
    "            agg_funcs.pop(\"segment_id\")\n",
    "            agg_funcs.pop(\"segment\")\n",
    "        except ValueError:\n",
    "            print(\n",
    "                \"'segment_id', 'segment' and 'n_segments'\"\n",
    "                \" columns are not among in stamps column:\"\n",
    "                f\"'{stamps_cols}', they are probably removed in\"\n",
    "                \"a previous call of 'parents_stamps' function.\"\n",
    "            )\n",
    "        # aggregating functions for properties\n",
    "        agg_funcs['ensemble_id'] = 'count'\n",
    "        agg_funcs['n_frames'] = 'last'\n",
    "        file_lastname = 'ensAvg'\n",
    "    else:\n",
    "        parent_groupby = 'whole'\n",
    "        # aggregating functions for properties\n",
    "        agg_funcs['segment_id'] = 'count'\n",
    "        agg_funcs['n_frames'] = 'sum'\n",
    "        file_lastname = 'whole'\n",
    "    agg_funcs.pop(parent_groupby)\n",
    "    parents_stamps = stamps.groupby([parent_groupby]).agg(agg_funcs)\n",
    "    parents_stamps.reset_index(inplace=True)\n",
    "    if lineage == 'whole':\n",
    "        parents_stamps.rename(\n",
    "            columns={'ensemble_id': 'n_ensembles'},\n",
    "            inplace=True\n",
    "        )\n",
    "        try:\n",
    "            parents_stamps.drop(columns=['n_segments'], inplace=True)\n",
    "        except KeyError:\n",
    "            print(\n",
    "                \"'n_segments' column is among the parents' stamps column:\"\n",
    "                f\"'{stamps_cols}', it is probably bot created in\"\n",
    "                \"a previous call of 'parents_stamps' function.\"\n",
    "            )\n",
    "    else:\n",
    "        parents_stamps.rename(\n",
    "            columns={'segment_id': 'n_segments'},\n",
    "            inplace=True\n",
    "        )\n",
    "    if save_to is not None:\n",
    "        space_name = parents_stamps.loc[0, 'space']\n",
    "        filename = '-'.join(\n",
    "            [space_name, group, 'stamps', file_lastname + '.csv']\n",
    "        )\n",
    "        parents_stamps.to_csv(save_to + filename, index=False)\n",
    "    return parents_stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2624c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import SumRule, TransFoci\n",
    "from polyphys.analyze import analyzer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cefd49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "client = Client(n_workers=4)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5f2b59-7fca-480f-8c4d-956b854e10e6",
   "metadata": {},
   "source": [
    "## PC: parallel scheme with Dask and serial scheme\n",
    "\n",
    "Files generated in the *probe* phase can be in *segment* or *whole* version. The analyze phase can be started from the *segmens* or *wholes* depending on the type of simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09af9d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### files in *segment* lineage/format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378327a9-117b-4741-9ada-a5f197cac3e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### bug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b2c27-d5d1-4c5a-b017-8f70e98593a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Sum-rule project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7becd-3fb7-42b2-9c0c-5d5028763b34",
   "metadata": {},
   "source": [
    "###### Serial with For-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9076758-ac3d-43a2-9b5a-af4e040264d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 10 mins on \n",
    "inupt_databases = glob(\"/Users/amirhsi_mini/research_data/probe/N*-probe-segment\")\n",
    "geometry = 'biaxial'\n",
    "tseries_properties_bug = [\n",
    "    # property_, species, group\n",
    "    ('fsdT', 'Mon', 'bug'),\n",
    "    ('gyrT', 'Mon', 'bug'),\n",
    "    ('rfloryT', 'Mon', 'bug'),\n",
    "    ('shapeT', 'Mon', 'bug'),\n",
    "    ('asphericityT', 'Mon', 'bug')\n",
    "]\n",
    "acf_tseries_properties_bug = [\n",
    "    # property_, species, group\n",
    "    ('fsdT', 'Mon', 'bug'),\n",
    "    ('gyrT', 'Mon', 'bug'),\n",
    "    ('rfloryT', 'Mon', 'bug'),\n",
    "    ('shapeT', 'Mon', 'bug'),\n",
    "    ('asphericityT', 'Mon', 'bug')\n",
    "]\n",
    "\n",
    "#hist_properties_bug = [\n",
    "    # direction, species, group\n",
    "#    ('rflory', 'Mon', 'bug')\n",
    "#]\n",
    "for input_database in inupt_databases:\n",
    "    print(input_database)\n",
    "    analyzer.analyze_bug(\n",
    "        input_database,\n",
    "        '/N*/N*',\n",
    "        SumRule,\n",
    "        geometry,\n",
    "        True,\n",
    "        #nonscalar_hist_properties=nonscalar_hist_properties,\n",
    "        #tseries_properties=tseries_properties_bug,\n",
    "        #acf_tseries_properties=acf_tseries_properties_bug,\n",
    "        #hist_properties=hist_properties_bug,\n",
    "        #,\n",
    "        #nlags=100000\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51e001-f8b2-4415-80e6-b64b97a6db7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "###### Dask: this has problem with memeory linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2856d3-90d0-4f6b-9604-cc9fe3094cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inupt_databases = glob(\"/Users/amirhsi_mini/research_data/probe/N*-probe-segment\")\n",
    "geometry = 'biaxial'\n",
    "analyses = []\n",
    "tseries_properties_bug = [\n",
    "    # property_, species, group\n",
    "    ('fsdT', 'Mon', 'bug'),\n",
    "    ('gyrT', 'Mon', 'bug'),\n",
    "    ('rfloryT', 'Mon', 'bug'),\n",
    "    ('shapeT', 'Mon', 'bug'),\n",
    "    ('asphericityT', 'Mon', 'bug')\n",
    "]\n",
    "acf_tseries_properties_bug = [\n",
    "    # property_, species, group\n",
    "#    ('fsdT', 'Mon', 'bug'),\n",
    "#    ('gyrT', 'Mon', 'bug'),\n",
    "#    ('rfloryT', 'Mon', 'bug'),\n",
    "#    ('shapeT', 'Mon', 'bug'),\n",
    "    ('asphericityT', 'Mon', 'bug')\n",
    "]\n",
    "\n",
    "#hist_properties_bug = [\n",
    "    # direction, species, group\n",
    "#    ('rflory', 'Mon', 'bug')\n",
    "#]\n",
    "for input_database in inupt_databases:\n",
    "    print(input_database)\n",
    "    analyze_delayed = delayed(analyzer.analyze_bug)(\n",
    "        input_database,\n",
    "        '/N*/N*',\n",
    "        SumRule,\n",
    "        geometry,\n",
    "        True,\n",
    "        #nonscalar_hist_properties=nonscalar_hist_properties,\n",
    "        #tseries_properties=tseries_properties_bug,\n",
    "        acf_tseries_properties=acf_tseries_properties_bug,\n",
    "        #hist_properties=hist_properties_bug,\n",
    "        #nlags=100000\n",
    "    )\n",
    "    analyses.append(analyze_delayed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9021ab27-3e12-41ce-ae7a-67c295dcde14",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# it takes 9min and 34s.\n",
    "results = compute(analyses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dffa88-32e6-4e25-ab4b-c632ed07b863",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Trans-foci project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8705842c-cc99-4f15-b122-a91532383a10",
   "metadata": {
    "tags": []
   },
   "source": [
    "### files in *whole* lineage/format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c83ee3-b672-4f01-beb2-3872dba73118",
   "metadata": {},
   "source": [
    "#### bug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e562b42-8113-4d60-9c5a-b5e951a4cf1b",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Sum-rule project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0cbfd-c834-4d73-ad38-bae79ae2d7af",
   "metadata": {},
   "source": [
    "##### Trans-Foci project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd4a915-5129-4c27-af1f-9207ead880f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# takes 25 min with nlags=100000\n",
    "input_database = \"/Users/amirhsi_mini/research_data/probe/ns400nl5al5D20ac1-probe-whole\"\n",
    "#input_database = '../test_data/probe/N2000D30.0ac4.0-segment/'\n",
    "nonscalar_hist_properties = [\n",
    "    # property_, species, group\n",
    "    ('bondsT', 'Foci', 'bug', 0),\n",
    "  #  ('clustersT', 'Foci', 'bug', 0)#,\n",
    "]\n",
    "\n",
    "#tseries_properties_bug = [\n",
    "    # property_, species, group\n",
    "#    ('fsdT', 'Mon', 'bug')#,\n",
    "#    ('gyrT', 'Mon', 'bug')#,\n",
    "#    ('rfloryT', 'Mon', 'bug'),\n",
    "#    ('shapeT', 'Mon', 'bug'),\n",
    "#    ('asphericityT', 'Mon', 'bug')\n",
    "#]\n",
    "\n",
    "acf_tseries_properties_bug = [\n",
    "    # property_, species, group\n",
    "    ('fsdT', 'Mon', 'bug'),\n",
    "    ('gyrT', 'Mon', 'bug'),\n",
    "    ('rfloryT', 'Mon', 'bug'),\n",
    "    ('shapeT', 'Mon', 'bug'),\n",
    "    ('asphericityT', 'Mon', 'bug')\n",
    "]\n",
    "\n",
    "#hist_properties_bug = [\n",
    "    # direction, species, group\n",
    "#    ('rflory', 'Mon', 'bug')\n",
    "#]\n",
    "geometry = 'biaxial'\n",
    "analyzer.analyze_bug(\n",
    "    input_database,\n",
    "    '/eps*/eps*',\n",
    "    TransFoci,\n",
    "    geometry,\n",
    "    False,\n",
    "    #nonscalar_hist_properties=nonscalar_hist_properties,\n",
    "    #tseries_properties=tseries_properties_bug,\n",
    "   # acf_tseries_properties=acf_tseries_properties_bug,\n",
    "    #hist_properties=hist_properties_bug,\n",
    "    #nlags=100000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aadaf9-908c-4db0-8605-19edbe241ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
