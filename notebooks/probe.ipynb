{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The probe phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# HPC Cluster: gnuparallel\n",
    "\n",
    "## Separated *whole* simulation directories\n",
    "\n",
    "On a cluster, *whole* simulations are organized into *whole* directories, where each *whole* directory contains all the files for a given *whole* simulation. The **gnuparallel** is used to parallelize the **probe** phase at the **shell** level. For this purpose, all the python modules and scripts are separatedly installed and run on each core. For instance, if 32 cores are available, then the files in 32 *whole* directories are simulatenously installed. However, each *whole* directory may contains multiple topology and trajectory pairs. Thus, there is parallelization at the level of *whole* directories, not at the level of the *segment* or *whole* trajectories inside a *whole* directory. Inside each *whole* directory, a python **main_probe.py** script analyzes the trajectories in a sequential way.\n",
    "\n",
    "- trj and all *segments* on a cluster\n",
    "\n",
    "For each *whole* directory, the following script is executed by means of *gnuparallel*. See these scripts: *probe-1.7-all_trj_segments.py* and *probe-1.7-bug_trj_segments*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sum-rule project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "\n",
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./N*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_pairs\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.sum_rule_bug_cyl(bug_topo, bug_trj, lineage, save_to=save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### segment bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRuleCyl\n",
    "\n",
    "\n",
    "group = 'bug'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "bug_trjs = glob('./N*' + group + '*')\n",
    "bug_trjs = organizer.sort_filenames(\n",
    "    bug_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob('./N*' + group + '*')\n",
    "bug_topo = organizer.sort_filenames(bug_topo, fmts=['.' + group + '.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "max_segment_id = len(bug_trjs)\n",
    "# analyzing all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for bug_trj in bug_trjs:\n",
    "    trj_info = SumRuleCyl(\n",
    "        bug_trj, topo_lineage, 'cylindrical', group, 'linear'\n",
    "        )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_bug_cyl(bug_topo, bug_trj, lineage, save_to=save_to)\n",
    "    else:\n",
    "        prober.sum_rule_bug_cyl(\n",
    "            bug_topo,\n",
    "            bug_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRuleCyl\n",
    "\n",
    "\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./N*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzing all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = SumRuleCyl(\n",
    "        all_trj, topo_lineage, 'cylindrical', group, 'linear'\n",
    "        )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all_cyl(all_topo, all_trj, lineage, save_to=save_to)\n",
    "    else:\n",
    "        prober.sum_rule_all_cyl(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs: hist_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import SumRuleCyl\n",
    "\n",
    "geometry = 'biaxial'\n",
    "group = 'all'\n",
    "top_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs, fmts=['.' + group + '.lammpstrj']\n",
    "    )\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_top = glob('./N*' + group + '*')\n",
    "all_top = organizer.sort_filenames(all_top, fmts=['.' + group + '.data'])\n",
    "all_top = all_top[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = SumRuleCyl(all_trj, top_lineage, 'cylindrical', group, 'linear')\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all_cyl_hist2d(\n",
    "            all_top, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_all_cyl_hist2d(\n",
    "            all_top,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trans-Foci project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cylindrical\n",
    "#### whole bug trjs\n",
    "Each *bug topology* comes with only **one** *bug trajectory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import TransFociCyl\n",
    "\n",
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cyl(bug_topo, bug_trj, lineage, save_to=save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCyl(all_trj, topo_lineage, 'cylindrical', group, 'ring')\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cyl(all_topo, all_trj, lineage, save_to=save_to)\n",
    "    else:\n",
    "        prober.trans_foci_all_cyl(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs: transverse_size\n",
    "Each *bug topology* comes with only **one** *bug trajectory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cyl_transverse_size(\n",
    "        bug_topo, bug_trj, lineage, save_to=save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs: hist_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCyl(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'ring'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cyl_hist2d(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "\n",
    "        prober.trans_foci_all_cyl_hist2d(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs\n",
    "Each *bug topology* comes with only **one** *bug trajectory*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import TransFociCub\n",
    "\n",
    "# analyzing bug files.\n",
    "geometry = 'biaxial'\n",
    "group='bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "bug_pairs = glob('./al*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cub(bug_topo, bug_trj, lineage, save_to=save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob('./al*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob('./al*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCub(all_trj, topo_lineage, 'cubic', group, 'ring')\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cub(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.trans_foci_all_cub(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PC Serial scheme\n",
    "\n",
    "There are 4 different types of directories from which only one type can be in a *space* directory.\n",
    "\n",
    "There are separated **whole** directories in each of which there **all** and **bug** **whole** trajectories; or, there are again separated **whole** directories in each of which there are **all** and **bug** **segment** trajectories. Below there are two groups of scrips for **serial** and **parallel** running schemes.\n",
    "\n",
    "\n",
    "On a PC, the *whole* directories are located in a master *space-trjs* directory; however, one main python script probes all the *whole* directories in a parallel scheme via Dask. This is different from the *gnuparallel*-based approach in which each *whole* directory has its own copy of the required scripts and a main python script is run to probe that directory individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sumrule project\n",
    "### Cylindrical\n",
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "#path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "path = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "bug_pairs = glob(path + '/N*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.sum_rule_bug_cyl(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        lineage,\n",
    "        continuous=False,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "input_path = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "group = 'bug'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "bug_trjs = glob(input_path + '/N*' + group + '*')\n",
    "bug_trjs = organizer.sort_filenames(\n",
    "    bug_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "bug_trjs = [bug_trj[0] for bug_trj in bug_trjs]\n",
    "bug_topo = glob(input_path + '/N*' + group + '*')\n",
    "bug_topo = organizer.sort_filenames(bug_topo, fmts=['.' + group + '.data'])\n",
    "bug_topo = bug_topo[0][0]\n",
    "max_segment_id = len(bug_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for bug_trj in bug_trjs:\n",
    "    trj_info = SumRuleCyl(\n",
    "        bug_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'linear'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_bug_cyl(\n",
    "            bug_topo, bug_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_bug_cyl(\n",
    "            bug_topo,\n",
    "            bug_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs: hist_1d and hist_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 mins for ~4000 particles with one all trj\n",
    "parent = \"/Users/amirhsi_mini/research_data/trjs\"\n",
    "#parent = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(parent + '/N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "print(all_trjs)\n",
    "all_topo = glob(parent + '/N*' + group + '*')\n",
    "print(all_topo)\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = SumRuleCyl(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'linear'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all_cyl(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.sum_rule_all_cyl(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs: hist_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 10 mins for N2000epsilon5.0r13.0lz259.0sig1.0nc133547dt0.005bdump1000adump5000ens1 2 all trjs\n",
    "trjs_db = \"/Users/amirhsi_mini/research_data/trjs/N2000epsilon5.0r13.0lz259.0sig1.0nc133547dt0.005bdump1000adump5000ens1\"\n",
    "#trjs_db = \"/Users/amirhsi/Downloads/N2000epsilon5.0r15.5lz379.5sig6.0nc1779dt0.005bdump1000adump5000ens7\"\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(trjs_db + '/N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "print(all_trjs)\n",
    "all_topo = glob(trjs_db + '/N*' + group + '*')\n",
    "print(all_topo)\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = SumRuleCyl(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'linear'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.sum_rule_all_cyl_hist2d(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        prober.sum_rule_all_cyl_hist2d(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trans-Foci project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cylindrical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "linage = 'whole'\n",
    "save_to = './'\n",
    "#macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "bug_pairs = glob(macbookpro_path + '/eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cyl(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "#macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "macmini_path = '/Users/amirhsi_mini/research_data/test'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(macmini_path + '/eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(macmini_path + '/eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCyl(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'ring'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cyl(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.trans_foci_all_cyl(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment bug trjs: transverse size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "linage = 'whole'\n",
    "save_to = './'\n",
    "#macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "bug_pairs = glob(macbookpro_path + '/eps*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cyl_transverse_size(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trjs: hist_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "#macbookpro_path = \"/Users/amirhsi/Downloads/epss5epsl5r10.5al5nl5ml125ns400ac1nc27720lz77dt0.005bdump2000adump5000ens8\"\n",
    "macmini_path = '/Users/amirhsi_mini/research_data/test'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(macmini_path + '/eps*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(macmini_path + '/eps*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCyl(\n",
    "        all_trj,\n",
    "        topo_lineage,\n",
    "        'cylindrical',\n",
    "        group,\n",
    "        'ring'\n",
    "    )\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cyl_hist2d(\n",
    "            all_topo, all_trj, lineage, save_to=save_to\n",
    "        )\n",
    "    else:\n",
    "        prober.trans_foci_all_cyl_hist2d(\n",
    "            all_topo,\n",
    "            all_trj,\n",
    "            lineage,\n",
    "            save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyzing bug files.\n",
    "group = 'bug'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "#macmini_path = \"/Users/amirhsi_mini/trjs/epss5.0epsl5.0r10.5al5.0nl5ml125ns200ac1.0nc*lz77.0dt0.005bdump5000adump5000ens1ring/*.bug*\"\n",
    "macbookpro_path = \"/Users/amirhsi_mini/research_data/al1nl5ml1ns400ac1nc160392l36dt0.005bdump2000adump5000ens1.ring\"\n",
    "bug_pairs = glob(macbookpro_path + '/al*' + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    prober.trans_fuci_bug_cub(\n",
    "        bug_topo,\n",
    "        bug_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 1 min and 45 s for ~30000 particles with one all trj\n",
    "macbookpro_path = \"/Users/amirhsi_mini/research_data/al1nl5ml1ns400ac1nc160392l36dt0.005bdump2000adump5000ens1.ring\"\n",
    "#macmini_path = '/Users/amirhsi_mini/research_data/test'\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(macbookpro_path + '/al*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj.gz']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(macbookpro_path + '/al*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = TransFociCub(all_trj, topo_lineage, 'cubic', group, 'ring')\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.trans_foci_all_cub(all_topo, all_trj, lineage, save_to=save_to)\n",
    "    else:\n",
    "        prober.trans_foci_all_cub(all_topo, all_trj, lineage, save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HNS project\n",
    "### Cubic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-21T16:25:07.676290Z",
     "iopub.status.busy": "2023-01-21T16:25:07.675154Z",
     "iopub.status.idle": "2023-01-21T16:25:07.687097Z",
     "shell.execute_reply": "2023-01-21T16:25:07.681899Z",
     "shell.execute_reply.started": "2023-01-21T16:25:07.676173Z"
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import HnsCub\n",
    "# analyzing bug files.\n",
    "group = 'nucleoid'\n",
    "lineage = 'whole'\n",
    "save_to = './'\n",
    "#probe_path = \"/Users/amirhsi_mini/research_data/hns_cubic-trjs/N*/N*\"\n",
    "#probe_path = \"../../Datasets/N200epshm29kbmm2nh48ac1nc95493l25dt0.005ndump2000adump5000ens1.ring\"\n",
    "probe_path = \"../../Datasets/TestTrajectories/N200epshm29kbmm2nh48ac1nc95493l25dt0.005ndump2000adump5000ens1.ring-truncated_for_tests-No_backup-Keep_it\"\n",
    "nuc_pairs = glob(probe_path + '/N*' + group + '*')\n",
    "nuc_pairs = organizer.sort_filenames(\n",
    "    nuc_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (nuc_topo, nuc_trj) in nuc_pairs:\n",
    "    prober.hns_nucleoid_cub(\n",
    "        nuc_topo,\n",
    "        nuc_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### segment all trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import HnsCub\n",
    "# ~6 min for 3 trjs, each with 100 frames\n",
    "probe_path = \"../../Datasets/TestTrajectories/N200epshm29kbmm2nh48ac1nc95493l25dt0.005ndump2000adump5000ens1.ring-truncated_for_tests-No_backup-Keep_it\"\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = './'\n",
    "all_trjs = glob(probe_path + '/N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(probe_path + '/N*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_trj in all_trjs:\n",
    "    trj_info = HnsCub(all_trj, topo_lineage, 'cubic', group, 'ring')\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.hns_all_cub(all_topo, all_trj, lineage, save_to=save_to)\n",
    "    else:\n",
    "        prober.hns_all_cub(all_topo, all_trj, lineage, save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cylindrical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### whole bug trjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import HnsCyl\n",
    "# analyzing bug files.\n",
    "group = 'nucleoid'\n",
    "lineage = 'whole'\n",
    "#save_to = './'\n",
    "save_to = '/Users/amirhsi_mini/research_data/hns_cyl-trjs/'\n",
    "probe_path = \"/Users/amirhsi_mini/research_data/hns_cyl-trjs/N*\"\n",
    "#probe_path = \"../../Datasets/N200kbmm2r4.5nh12ac2lz75nc552ens2.ring\"\n",
    "#probe_path = \"../../Datasets/TestTrajectories/N200epshm29kbmm2nh48ac1nc95493l25dt0.005ndump2000adump5000ens1.ring-truncated_for_tests-No_backup-Keep_it\"\n",
    "nuc_pairs = glob(probe_path + '/N*' + group + '*')\n",
    "nuc_pairs = organizer.sort_filenames(\n",
    "    nuc_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "print(nuc_pairs)\n",
    "for (nuc_topo, nuc_trj) in nuc_pairs:\n",
    "    prober.hns_nucleoid_cyl(\n",
    "        nuc_topo,\n",
    "        nuc_trj,\n",
    "        lineage,\n",
    "        save_to = save_to\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### segment all trj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import HnsCyl\n",
    "# ~6 min for 3 trjs, each with 100 frames\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = '/Users/amirhsi_mini/research_data/hns_cyl-trjs/'\n",
    "probe_path = \"/Users/amirhsi_mini/research_data/hns_cyl-trjs/N*\"\n",
    "all_trjs = glob(probe_path + '/N*' + group + '*')\n",
    "all_trjs = organizer.sort_filenames(\n",
    "    all_trjs,\n",
    "    fmts=['.' + group + '.lammpstrj']\n",
    ")\n",
    "all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "all_topo = glob(probe_path + '/N*' + group + '*')\n",
    "all_topo = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topo = all_topo[0][0]\n",
    "max_segment_id = len(all_trjs)\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "\n",
    "for all_trj in all_trjs:\n",
    "    print(all_trj)\n",
    "    trj_info = HnsCyl(all_trj, topo_lineage, 'cylindrical', group, 'ring')\n",
    "    # all the frames in the last segment are probed:\n",
    "    if trj_info.segment_id == max_segment_id:\n",
    "        prober.hns_all_cyl(all_topo, all_trj, lineage, save_to=save_to)\n",
    "    else:\n",
    "        prober.hns_all_cyl(all_topo, all_trj, lineage, save_to=save_to,\n",
    "            continuous=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Loop on all topos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/amirhsi_mini/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/special/_ufuncs.cpython-310-darwin.so, 2): Library not loaded: @rpath/liblapack.3.dylib\n  Referenced from: /Users/amirhsi_mini/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/special/_ufuncs.cpython-310-darwin.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m __email__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamirh.sadeghi@icloud.com\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.1.0\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyphys\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m analyze\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyphys\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m construct\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyphys\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m probe\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/analyze/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyphys\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyze\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m analyzer\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyphys\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyze\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyphys\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalyze\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m correlations\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/analyze/analyzer.py:33\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01morganizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     sort_filenames,\n\u001b[1;32m     16\u001b[0m     database_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     parents_stamps\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     ParserT,\n\u001b[1;32m     27\u001b[0m     TimeSeriesT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     EdgeT\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distributions_generator\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorrelations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m acf_generator\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtime_series\u001b[39m(\n\u001b[1;32m     38\u001b[0m     observations: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m     39\u001b[0m     parser: ParserT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     alpha: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m\n\u001b[1;32m     48\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/analyze/distributions.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrayLike\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrate\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mintegrate\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ParserT, FreqDataT, EdgeDataT)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mspherical_segment\u001b[39m(\n\u001b[1;32m     25\u001b[0m     r: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m     26\u001b[0m     a: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m     27\u001b[0m     b: \u001b[38;5;28mfloat\u001b[39m\n\u001b[1;32m     28\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/integrate/__init__.py:91\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m=============================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mIntegration and ODEs (:mod:`scipy.integrate`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m   solve_bvp     -- Solve a boundary value problem for a system of ODEs.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_quadrature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_odepack_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_quadpack_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/integrate/_quadrature.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m namedtuple\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roots_legendre\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gammaln, logsumexp\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _rng_spawn\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/special/__init__.py:663\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m========================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mSpecial functions (:mod:`scipy.special`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    658\u001b[0m \n\u001b[1;32m    659\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sf_error\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpecialFunctionWarning, SpecialFunctionError\n\u001b[0;32m--> 663\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _ufuncs\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ufuncs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _basic\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/amirhsi_mini/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/special/_ufuncs.cpython-310-darwin.so, 2): Library not loaded: @rpath/liblapack.3.dylib\n  Referenced from: /Users/amirhsi_mini/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/special/_ufuncs.cpython-310-darwin.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "from polyphys.manage.parser import HnsCyl\n",
    "# ~6 min for 3 trjs, each with 100 frames\n",
    "group = 'all'\n",
    "topo_lineage = 'whole'\n",
    "lineage = 'segment'\n",
    "save_to = '/Users/amirhsi_mini/research_data/HnsCyl-trjs/'\n",
    "probe_path = \"/Users/amirhsi_mini/research_data/HnsCyl-trjs/N*\"\n",
    "all_topo = glob(probe_path + '/N*' + group + '*')\n",
    "all_topos = organizer.sort_filenames(all_topo, fmts=['.' + group + '.data'])\n",
    "all_topos = [all_topo[0] for all_topo in all_topos]\n",
    "# analyzig all files\n",
    "# it is assumed that the all trjs are numbers from 1 to max_segment_id\n",
    "for all_topo in all_topos:\n",
    "    print(all_topo)\n",
    "    dir_name = all_topo.split('/')[-1].split('.all')[0]\n",
    "    all_trjs = glob(probe_path[:-2] + '/'+ dir_name + '/N*' + group + '*')\n",
    "    all_trjs = organizer.sort_filenames(\n",
    "        all_trjs,\n",
    "        fmts=['.' + group + '.lammpstrj']\n",
    "    )\n",
    "    all_trjs = [all_trj[0] for all_trj in all_trjs]\n",
    "    max_segment_id = len(all_trjs)\n",
    "    for all_trj in all_trjs:\n",
    "        trj_info = HnsCyl(all_trj, topo_lineage, 'cylindrical', group, 'ring')\n",
    "        # all the frames in the last segment are probed:\n",
    "        if trj_info.segment_id == max_segment_id:\n",
    "            prober.hns_all_cyl(all_topo, all_trj, lineage, save_to=save_to)\n",
    "        else:\n",
    "            prober.hns_all_cyl(all_topo, all_trj, lineage, save_to=save_to,\n",
    "                continuous=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirhsi_mini/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "dlopen(/Users/amirhsi_mini/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/sparse/linalg/_isolve/_iterative.cpython-310-darwin.so, 2): Library not loaded: @rpath/liblapack.3.dylib\n  Referenced from: /Users/amirhsi_mini/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/sparse/linalg/_isolve/_iterative.cpython-310-darwin.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mMDAnalysis\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmda\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/MDAnalysis/__init__.py:191\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# custom exceptions and warnings\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    186\u001b[0m     SelectionError, NoDataError, ApplicationError, SelectionWarning,\n\u001b[1;32m    187\u001b[0m     MissingDataWarning, ConversionWarning, FileFormatWarning,\n\u001b[1;32m    188\u001b[0m     StreamWarning\n\u001b[1;32m    189\u001b[0m )\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m log\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlog\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m start_logging, stop_logging\n\u001b[1;32m    194\u001b[0m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMDAnalysis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39maddHandler(log\u001b[38;5;241m.\u001b[39mNullHandler())\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/MDAnalysis/lib/__init__.py:40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NeighborSearch\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m formats\n\u001b[0;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pkdtree\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nsgrid\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpicklable_file_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (FileIOPicklable,\n\u001b[1;32m     43\u001b[0m                                 BufferIOPicklable,\n\u001b[1;32m     44\u001b[0m                                 TextIOPicklable)\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/MDAnalysis/lib/pkdtree.py:33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cKDTree\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unique_int_1d\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_augment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m augment_coordinates, undo_augment\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/spatial/__init__.py:105\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m=============================================================\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mSpatial algorithms and data structures (:mod:`scipy.spatial`)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m   QhullError\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_qhull\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/spatial/_kdtree.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright Anne M. Archibald 2008\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Released under the scipy license\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ckdtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cKDTree, cKDTreeNode\n\u001b[1;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance_p\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminkowski_distance\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRectangle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKDTree\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mminkowski_distance_p\u001b[39m(x, y, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m_ckdtree.pyx:10\u001b[0m, in \u001b[0;36minit scipy.spatial._ckdtree\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/sparse/__init__.py:283\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_arrays\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    279\u001b[0m     csr_array, csc_array, lil_array, dok_array, coo_array, dia_array, bsr_array\n\u001b[1;32m    280\u001b[0m )\n\u001b[1;32m    282\u001b[0m \u001b[38;5;66;03m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csgraph\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    287\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[1;32m    288\u001b[0m     lil, sparsetools, sputils\n\u001b[1;32m    289\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/sparse/csgraph/__init__.py:185\u001b[0m\n\u001b[1;32m    157\u001b[0m __docformat__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestructuredtext en\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnected_components\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    160\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaplacian\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    161\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshortest_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsgraph_to_masked\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    183\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegativeCycleError\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_laplacian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m laplacian\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shortest_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    187\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson,\n\u001b[1;32m    188\u001b[0m     NegativeCycleError\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traversal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    191\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[1;32m    192\u001b[0m     depth_first_tree, connected_components\n\u001b[1;32m    193\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/sparse/csgraph/_laplacian.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m isspmatrix\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Graph laplacian\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlaplacian\u001b[39m(\n\u001b[1;32m     13\u001b[0m     csgraph,\n\u001b[1;32m     14\u001b[0m     normed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     symmetrized\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     22\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/sparse/linalg/__init__.py:120\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m==================================================\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dsolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/sparse/linalg/_isolve/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#from info import __doc__\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minres\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlgmres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lgmres\n",
      "File \u001b[0;32m~/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/sparse/linalg/_isolve/iterative.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextwrap\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dedent\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _iterative\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_system\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/Users/amirhsi_mini/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/sparse/linalg/_isolve/_iterative.cpython-310-darwin.so, 2): Library not loaded: @rpath/liblapack.3.dylib\n  Referenced from: /Users/amirhsi_mini/miniconda3/envs/mdaanalysis2_3/lib/python3.10/site-packages/scipy/sparse/linalg/_isolve/_iterative.cpython-310-darwin.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import MDAnalysis as mda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mda.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_v4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cf582efbfbdef60505769a313a3ca49eebfd77179e86f4387bd11d254c0a990"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
