{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ae7f84",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5107e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import \\\n",
    "    SumRuleCyl, TransFociCyl, TransFociCub, HnsCub\n",
    "from polyphys.analyze import measurer\n",
    "import polyphys.api as api\n",
    "from polyphys.probe import logger\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#  Choose these two before running this script:\n",
    "#project = 'HnsCub'  # 'SumRuleCyl', 'TransFociCyl'\n",
    "project = 'TransFociCub'\n",
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "# List of physical properties: Set the project hierarchy\n",
    "project_details = {\n",
    "    'SumRuleCyl': {\n",
    "        'group': 'bug',\n",
    "        'geometry': 'cylindrical',\n",
    "        'topology': 'linear',\n",
    "        'parser': SumRuleCyl,\n",
    "        'space_pat': 'N*D*ac*',\n",
    "        'hierarchy': 'N*',\n",
    "        'space_hierarchy': 'N*',\n",
    "        'attributes': ['space', 'ensemble_long', 'ensemble', 'nmon', 'dcyl',\n",
    "                       'dcrowd', 'phi_c_bulk'\n",
    "                       ],\n",
    "        'time_varying_props': ['asphericityTMon', 'fsdTMon', 'gyrTMon',\n",
    "                               'rfloryTMon', 'shapeTMon', 'transSizeTMon'\n",
    "                               ],\n",
    "        'equil_measures': [np.mean, np.var, measurer.sem],\n",
    "        'equil_attributes': ['space', 'ensemble_long', 'ensemble', 'nmon',\n",
    "                             'dcyl', 'dcrowd', 'phi_c_bulk',\n",
    "                             'phi_c_bulk_round'\n",
    "                             ],\n",
    "        'equil_properties': ['asphericityMon-mean', 'asphericityMon-var',\n",
    "                             'asphericityMon-sem', 'fsdMon-mean','fsdMon-var',\n",
    "                             'fsdMon-sem', 'gyrMon-mean', 'gyrMon-var',\n",
    "                             'gyrMon-sem', 'rfloryMon-mean', 'rfloryMon-var',\n",
    "                             'rfloryMon-sem', 'shapeMon-mean', 'shapeMon-var',\n",
    "                             'shapeMon-sem', 'transSizeMon-mean',\n",
    "                             'transSizeMon-var', 'transSizeMon-sem'\n",
    "                             ],\n",
    "        'rhosPhisNormalizedScaled': [('Mon', 'dmon'), ('Crd', 'dcrowd')]\n",
    "    },\n",
    "    'TransFociCyl': {\n",
    "        'group': 'bug',\n",
    "        'geometry': 'cylindrical',\n",
    "        'topology': 'ring',\n",
    "        'parser': TransFociCyl,\n",
    "        'space_pat': 'ns*nl*al*D*ac*',\n",
    "        'hierarchy': 'eps*',\n",
    "        'space_hierarchy': 'ns*',\n",
    "        'attributes': ['space', 'ensemble_long', 'ensemble', 'nmon_small',\n",
    "                       'nmon_large', 'dmon_large', 'dcyl', 'dcrowd',\n",
    "                       'phi_c_bulk'\n",
    "                       ],\n",
    "        'time_varying_props': ['asphericityTMon', 'fsdTMon', 'gyrTMon',\n",
    "                               'shapeTMon'\n",
    "                               ],\n",
    "        'equil_measures': [np.mean, np.var, measurer.sem],\n",
    "        'equil_attributes': ['ensemble_long', 'ensemble', 'space', 'dcyl',\n",
    "                             'dmon_large', 'nmon_large', 'nmon_small',\n",
    "                             'dcrowd', 'phi_c_bulk', 'phi_c_bulk_round'\n",
    "                             ],\n",
    "        'equil_properties': ['asphericityMon-mean', 'asphericityMon-var',\n",
    "                             'asphericityMon-sem', 'fsdMon-mean',\n",
    "                             'fsdMon-var', 'fsdMon-sem', 'gyrMon-mean',\n",
    "                             'gyrMon-var', 'gyrMon-sem', 'shapeMon-mean',\n",
    "                             'shapeMon-var', 'shapeMon-sem'\n",
    "                             ],\n",
    "        'rhosPhisNormalizedScaled': [('Mon', 'dmon_small'), ('Crd', 'dcrowd'),\n",
    "                                     ('Foci', 'dmon_large')\n",
    "                                     ]\n",
    "    },\n",
    "    'TransFociCub': {\n",
    "        'group': 'bug',\n",
    "        'geometry': 'cubic',\n",
    "        'topology': 'ring',\n",
    "        'parser': TransFociCub,\n",
    "        'space_pat': 'ns*nl*al*ac*',\n",
    "        'hierarchy': 'al*',\n",
    "        'space_hierarchy': 'ns*',\n",
    "        'attributes': ['space', 'ensemble_long', 'ensemble', 'nmon_small',\n",
    "                       'nmon_large', 'dmon_large', 'dcrowd', 'phi_c_bulk'\n",
    "                       ],\n",
    "        'time_varying_props': ['asphericityTMon', 'gyrTMon', 'shapeTMon'],\n",
    "        'equil_measures': [np.mean],\n",
    "        'equil_attributes': ['ensemble_long', 'ensemble', 'space',\n",
    "                             'dmon_large', 'nmon_large', 'nmon_small',\n",
    "                             'dcrowd', 'phi_c_bulk', 'phi_c_bulk_round'\n",
    "                             ],\n",
    "        'equil_properties': ['asphericityMon-mean', 'asphericityMon-var',\n",
    "                             'asphericityMon-sem', 'gyrMon-mean',\n",
    "                             'gyrMon-var', 'gyrMon-sem', 'shapeMon-mean',\n",
    "                             'shapeMon-var', 'shapeMon-sem'\n",
    "                             ],\n",
    "        'rhosPhisNormalizedScaled': [('Mon', 'dmon_small'), ('Crd', 'dcrowd'),\n",
    "                                     ('Foci', 'dmon_large')\n",
    "                                     ]\n",
    "    },\n",
    "    'HnsCub': {\n",
    "        'group': 'nucleoid',\n",
    "        'geometry': 'cubic',\n",
    "        'topology': 'ring',\n",
    "        'parser': HnsCub,\n",
    "        'space_pat': 'N*epshm*nh*ac*',\n",
    "        'hierarchy': 'N*',\n",
    "        'space_hierarchy': 'N*',\n",
    "        'attributes': ['space', 'ensemble_long', 'ensemble', 'eps_hm',\n",
    "                       'nmon', 'nhns', 'dcrowd', 'phi_c_bulk'\n",
    "                       ],\n",
    "        'time_varying_props': ['asphericityTMon', 'gyrTMon', 'shapeTMon'],\n",
    "        'equil_measures': [np.mean],\n",
    "        'equil_attributes': ['ensemble_long', 'ensemble', 'space',\n",
    "                             'eps_hm', 'nmon', 'nhns', 'dcrowd', 'phi_c_bulk',\n",
    "                             'phi_c_bulk_round'\n",
    "                             ],\n",
    "        'equil_properties': ['asphericityMon-mean', 'asphericityMon-var',\n",
    "                             'asphericityMon-sem', 'gyrMon-mean',\n",
    "                             'gyrMon-var', 'gyrMon-sem', 'shapeMon-mean',\n",
    "                             'shapeMon-var', 'shapeMon-sem'\n",
    "                             ],\n",
    "        'rhosPhisNormalizedScaled': [('Mon', 'dmon'), ('Crd', 'dcrowd'),\n",
    "                                     ('Hns', 'dhns')\n",
    "                                     ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262003e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# allInOne *whole* and *ensAvg* stamps per project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7fab6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ensemble-averaged stamps per project (ensAvg phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details[project]['group'] + '-ensAvg'\n",
    "    )\n",
    "]\n",
    "allInOne_stamps = []\n",
    "for space_db in ens_avg_space_dbs:\n",
    "    stamp_path = project_details[project]['space_hierarchy'] + 'stamps*'\n",
    "    stamp_path = glob(space_db + \"/\" + stamp_path + '.csv')[0]\n",
    "    space_stamps = pd.read_csv(stamp_path)\n",
    "    allInOne_stamps.append(space_stamps)\n",
    "allInOne_stamps = pd.concat(allInOne_stamps, axis=0)\n",
    "allInOne_stamps.reset_index(inplace=True, drop=True)\n",
    "output = analysis_db + \"allInOne-\" + project + \"-stamps-ensAvg.csv\"\n",
    "allInOne_stamps.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c51724",
   "metadata": {
    "tags": []
   },
   "source": [
    "## whole stamps per project (ens phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf0a825-b48c-41d9-b954-7b988b1dea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details[project]['group'] + '-ens'\n",
    "    )\n",
    "]\n",
    "allInOne_stamps = []\n",
    "for space_db in ens_avg_space_dbs:\n",
    "    stamp_path = project_details[project]['space_hierarchy'] + 'stamps*'\n",
    "    stamp_path = glob(space_db + \"/\" + stamp_path + '.csv')[0]\n",
    "    space_stamps = pd.read_csv(stamp_path)\n",
    "    allInOne_stamps.append(space_stamps)\n",
    "allInOne_stamps = pd.concat(allInOne_stamps, axis=0)\n",
    "allInOne_stamps.reset_index(inplace=True, drop=True)\n",
    "output = analysis_db + \"allInOne-\" + project + \"-stamps-ens.csv\"\n",
    "allInOne_stamps.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57dcd1-c751-4641-9582-87444ad215ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Logs per project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f4943-c0c1-4b5b-b508-ca1b33a2071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_details = {\n",
    "    'SumRuleCyl': {\n",
    "        'space_pat': 'N*D*ac*',\n",
    "        'hierarchy': '/N*.log',  # dir/file\n",
    "        'parser': SumRuleCyl,\n",
    "        'group': 'bug',\n",
    "        'geometry': 'cylindrical',\n",
    "        'topology': 'linear',\n",
    "        'product_idx': 1\n",
    "    },\n",
    "    'TransFociCyl': {\n",
    "        'space_pat': 'ns*nl*al*D*ac*',\n",
    "        'hierarchy': '/eps*.log',  # dir/file\n",
    "        'parser': TransFociCyl,\n",
    "        'group': 'bug',\n",
    "        'geometry': 'cylindrical',\n",
    "        'topology': 'ring',\n",
    "        'product_idx': 2\n",
    "    },\n",
    "    'TransFociCub': {\n",
    "        'space_pat': 'ns*nl*al*ac*',\n",
    "        'hierarchy': '/al*.log',  # dir/file\n",
    "        'parser': TransFociCub,\n",
    "        'group': 'bug',\n",
    "        'geometry': 'cubic',\n",
    "        'topology': 'ring',\n",
    "        'product_idx': 2\n",
    "    },\n",
    "    'HnsCubWhole': {\n",
    "        'space_pat': 'N*epshm*nh*ac*',\n",
    "        'hierarchy': '/N*.log',  # dir/file\n",
    "        'parser': HnsCub,\n",
    "        'group': 'nucleoid',\n",
    "        'geometry': 'cubic',\n",
    "        'topology': 'ring',\n",
    "        'product_idx': 2\n",
    "    }\n",
    "}\n",
    "#log_db = \"/Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/Datasets/logs/\"\n",
    "log_db = '/Users/amirhsi_mini/research_data/TransFociCub/logs/'\n",
    "space_dbs = glob(log_db + log_details[project]['space_pat'] + '-logs')\n",
    "space_dbs.sort()\n",
    "space_with_segment_lineage = [\n",
    "    'N500D10.0ac0.6-logs',\n",
    "    'N500D10.0ac0.8-logs',\n",
    "    'N500D10.0ac1.0-logs',\n",
    "    'N2000D30.0ac4.0-logs',\n",
    "    'N2000D30.0ac6.0-logs'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c0657-7b02-4f40-b88d-f35e5593fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thermos = []\n",
    "run_stats = []\n",
    "wall_times = []\n",
    "save_to = './'\n",
    "\n",
    "for space_db in space_dbs:\n",
    "    print(space_db)\n",
    "    space = space_db.split(\"/\")[-1]\n",
    "    if space in space_with_segment_lineage:\n",
    "        lineage = 'segment'\n",
    "    else:\n",
    "        lineage = 'whole'\n",
    "    logs = glob(space_db + log_details[project]['hierarchy'])\n",
    "    logs = organizer.sort_filenames(logs,  fmts=['.log']) # sorted\n",
    "    logs = [log[0] for log in logs]\n",
    "    for log in logs:\n",
    "        log_info = log_details[project]['parser'](\n",
    "            log,\n",
    "            lineage,\n",
    "            log_details[project]['geometry'],\n",
    "            log_details[project]['group'],\n",
    "            log_details[project]['topology']\n",
    "        )\n",
    "        try:\n",
    "            product_idx = log_details[project]['product_idx']\n",
    "            if lineage == 'segment' and log_info.segment_id>1:\n",
    "                product_idx = 0\n",
    "            log_data = logger.LammpsLog(log, product_idx)\n",
    "        except (logger.BrokenLogError, IndexError):\n",
    "            print(\"broken log: \", log_info.filepath.split(\"/\")[-1])\n",
    "        log_data.extract_thermo()\n",
    "        log_data.extract_run_stat()\n",
    "        thermo = log_data.thermo\n",
    "        run_stat = log_data.run_stat\n",
    "        wall_time = log_data.wall_time\n",
    "        for attr_name in log_info._lineage_attributes[lineage].keys():\n",
    "            attr_value = getattr(log_info, attr_name)\n",
    "            thermo[attr_name] = attr_value\n",
    "        attr_names = ['phi_m_bulk', 'rho_m_bulk', 'phi_c_bulk', 'rho_c_bulk']\n",
    "        for attr_name in attr_names:\n",
    "            attr_value = getattr(log_info, attr_name)\n",
    "            thermo[attr_name] = attr_value\n",
    "        for lineage_name in log_info.genealogy:\n",
    "            attr_value = getattr(log_info, lineage_name)\n",
    "            thermo[lineage_name] = attr_value\n",
    "            run_stat[lineage_name] = attr_value\n",
    "            wall_time[lineage_name] = attr_value\n",
    "        thermos.append(thermo)\n",
    "        run_stats.append(run_stat)\n",
    "        wall_times.append(wall_time)\n",
    "\n",
    "output = \"-\".join([project, \"allInOne\", \"thermo\"])\n",
    "thermos = pd.concat(thermos)\n",
    "thermos.reset_index(inplace=True, drop=True)\n",
    "thermos.to_parquet(\n",
    "    save_to + output + \".parquet.brotli\", index=False, compression='brotli'\n",
    ")\n",
    "output = \"-\".join([project, \"allInOne\", \"runStat\"])\n",
    "run_stats = pd.concat(run_stats)\n",
    "run_stats.reset_index(inplace=True, drop=True)\n",
    "run_stats.to_csv(save_to + output + \".csv\", index=False)\n",
    "output = \"-\".join([project, \"allInOne\", \"wallTimeStat\"])\n",
    "wall_times = pd.concat(wall_times)\n",
    "wall_times.reset_index(inplace=True, drop=True)\n",
    "wall_times.to_csv(save_to + output + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d81b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ensAvg timeseries and their associated measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f538b6-83e3-443f-8d4e-612dc9bfaf07",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Measures of chain size timeseries properties per space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc9a63-48f6-45d6-9f30-f2a7d76b560f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### allInONe esnAvg ACFs of the chain-size properties per space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ee296-b30e-42a6-b594-bf5990c709ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 60 s for TransFoci\n",
    "# Wall time: 4 min for SumRule\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details[project]['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "# list of unique property_measures:\n",
    "filepath = ens_avg_space_dbs[0] + '*' + project_details[project]['hierarchy'] + '.csv'  # physical properties in all the\n",
    "_, uniq_props_measures = organizer.unique_property(\n",
    "    filepath, 2, [\"-\" + phase], drop_properties=['stamps'])\n",
    "print(uniq_props_measures)\n",
    "for ens_avg_space_db in ens_avg_space_dbs:\n",
    "    ens_avgs = list()\n",
    "    space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "    for property_ in uniq_props_measures:\n",
    "        ens_avg = organizer.space_tseries(\n",
    "            ens_avg_space_db,\n",
    "            property_,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            project_details[project]['group'],\n",
    "            project_details[project]['geometry'],\n",
    "            project_details[project]['topology'],\n",
    "            is_save = False  # if True, save per property per space\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=1)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:,~ens_avgs.columns.duplicated()]\n",
    "    output_name = analysis_db +  \"-\".join(\n",
    "        [space,\n",
    "         project_details[project]['group'],\n",
    "         \"chainSize-acf.parquet.brotli\"\n",
    "        ]\n",
    "    )\n",
    "    ens_avgs.to_parquet(output_name, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259588f1-c129-48c6-98d0-6a1f4990d1ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **allInOne** the chain-size properties per **space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844af7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 2 min s for TransFoci\n",
    "# Wall time: 7 min for SumRule\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details[project]['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "# list of unique property_measures:\n",
    "filepath = ens_avg_space_dbs[0] + '*' + project_details[project]['hierarchy'] + '.csv'  # physical properties in all the\n",
    "_, uniq_props_measures = organizer.unique_property(\n",
    "    filepath, 2, [\"-\" + phase], drop_properties=['stamps'])\n",
    "props_tseries = list(\n",
    "    set(\n",
    "        [prop.split(\"-acf\")[0] for prop in uniq_props_measures]\n",
    "    )\n",
    ")\n",
    "print(props_tseries)\n",
    "for ens_avg_space_db in ens_avg_space_dbs:\n",
    "    ens_avgs = list()\n",
    "    space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "    for property_ in props_tseries:\n",
    "        ens_avg = organizer.space_tseries(\n",
    "            ens_avg_space_db,\n",
    "            property_,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            project_details[project]['group'],\n",
    "            project_details[project]['geometry'],\n",
    "            project_details[project]['topology'],\n",
    "            is_save = False  # if True, save per property per space\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=1)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:,~ens_avgs.columns.duplicated()]\n",
    "    output_name = analysis_db +  \"-\".join(\n",
    "        [space,  project_details[project]['group'], \"chainSize.parquet.brotli\"]\n",
    "    )\n",
    "    ens_avgs.to_parquet(output_name, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3bcc1a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TransFoci Project: Pair distance time-series per project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836072fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details[project]['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "tseries_foci_props = ['pairDistTFoci']\n",
    "project_ens_avgs = []\n",
    "for prop in tseries_foci_props:\n",
    "    prop_ens_avgs = list()\n",
    "    for ens_avg_space_db in ens_avg_space_dbs:\n",
    "        space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "        ens_avg = organizer.space_tseries(\n",
    "            ens_avg_space_db,\n",
    "            prop,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            project_details[project]['group'],\n",
    "            project_details[project]['geometry'],\n",
    "            project_details[project]['topology'],\n",
    "            is_save = False  # if True, save per property per space\n",
    "        )\n",
    "        prop_ens_avgs.append(ens_avg)\n",
    "    prop_ens_avgs = pd.concat(prop_ens_avgs,axis=0)\n",
    "    # drop duplicated columns:\n",
    "    prop_ens_avgs = prop_ens_avgs.loc[:, ~prop_ens_avgs.columns.duplicated()]\n",
    "    prop_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    project_ens_avgs.append(prop_ens_avgs)\n",
    "project_ens_avgs = pd.concat(project_ens_avgs,axis=1)\n",
    "project_ens_avgs = \\\n",
    "    project_ens_avgs.loc[:, ~project_ens_avgs.columns.duplicated()]\n",
    "project_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "output ='-'.join(['allInOne', project, project_details[project]['group'], 'pairDistT.parquet.brotli'])\n",
    "output = analysis_db + output\n",
    "project_ens_avgs.to_parquet(output, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50541f3-23c6-493c-b03c-59791f0c8af9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Equilibrium timeseries properties per space AND per project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6550f1-7813-4bfb-8009-6955a89378ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Whole equilibrium properties allInOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8079e8a-9a4f-4fcd-861e-9c4a3ae02de7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Wall time: 23 s for TransFoci\n",
    "# Wall time: 10 min s for SumRule\n",
    "spaces = glob(analysis_db + project_details[project]['space_pat'])\n",
    "spaces = list(set([space.split('/')[-1].split('-')[0] for space in spaces]))\n",
    "save_space = True\n",
    "equili_props_wholes = api.all_in_one_equil_tseries(\n",
    "    project,\n",
    "    analysis_db,\n",
    "    project_details[project]['group'],\n",
    "    spaces,\n",
    "    project_details[project]['time_varying_props'],\n",
    "    project_details[project]['equil_measures'],\n",
    "    save_space=save_space,\n",
    "    divisor=0.025,\n",
    "    round_to=3,\n",
    "    save_to=analysis_db,\n",
    ")\n",
    "ens_avg = api.all_in_one_equil_tseries_ens_avg(\n",
    "    project,\n",
    "    equili_props_wholes,\n",
    "    project_details[project]['group'],\n",
    "    project_details[project]['equil_properties'],\n",
    "    project_details[project]['equil_attributes'],\n",
    "    save_to=analysis_db\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74045030",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce532e-3a29-4e50-8bdd-f2c1d5f73c2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Persistence lengths: HnsCub\n",
    "- Currently the **probe** phase is **HnsCub** project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4b231-656f-4c1a-a99d-a94d19cae3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "phase = 'ensAvg'\n",
    "ext = '.csv'\n",
    "property_ext = phase + '-mean' + ext\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details[project]['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "filepath = ens_avg_space_dbs[0] + project_details[project]['hierarchy'] + ext # physical properties in all the\n",
    "uniq_props,  _ = organizer.unique_property(\n",
    "    filepath, 2, [\"-\" + phase], drop_properties=['stamps'])\n",
    "bond_props = list(\n",
    "    set(\n",
    "        [prop for prop in uniq_props if prop.startswith(\"bondCosine\")]\n",
    "    )\n",
    ")\n",
    "print(bond_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f991b9-1225-4764-8933-3e91f9b92692",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_all_in_one = list()\n",
    "polymer_topo = project_details[project]['topology']\n",
    "for ens_avg_space_db in ens_avg_space_dbs:\n",
    "    ens_avgs = list()\n",
    "    space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "    space_info = project_details[project]['parser'](\n",
    "        space,\n",
    "        'space',\n",
    "        project_details[project]['geometry'],\n",
    "        project_details[project]['group'],\n",
    "        project_details[project]['topology'],\n",
    "        ispath=False\n",
    "    )\n",
    "    bonds_per_topology = {\n",
    "       'linear': np.arange(1, space_info.nmon, 1),\n",
    "       'ring': np.arange(1, space_info.nmon+1, 1)\n",
    "    }\n",
    "    for property_ in bond_props:\n",
    "        ens_avg = organizer.space_hists(\n",
    "            ens_avg_space_db,\n",
    "            property_,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            project_details[project]['group'],\n",
    "            project_details[project]['geometry'],\n",
    "            project_details[project]['topology'],\n",
    "            bin_center=bonds_per_topology[polymer_topo],\n",
    "            normalize=False,\n",
    "            is_save=False\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=1)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:,~ens_avgs.columns.duplicated()]\n",
    "    ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    project_all_in_one.append(ens_avgs)\n",
    "project_all_in_one = pd.concat(project_all_in_one,axis=0)\n",
    "project_all_in_one = \\\n",
    "    project_all_in_one.loc[:, ~project_all_in_one.columns.duplicated()]\n",
    "project_all_in_one.reset_index(inplace=True, drop=True)\n",
    "output = '-'.join(\n",
    "    ['allInOne', project, project_details[project]['group'], 'BondCosCorrVecMon.csv']\n",
    ")\n",
    "output = analysis_db + output\n",
    "project_all_in_one.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1612fd82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clusters and bonds per project: TransFoci\n",
    "\n",
    "- Applicable to any project in which clustering happens such as **HnsCub**, **TransFociCub**,and **TransFociCyl**.\n",
    "- The histograms of **Clusters** and **bonds** can **not** be combined in **one** dataset.\n",
    "- Since **per project** datasets are small, we create **one** per project dataset for each property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d12660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details[project]['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "\n",
    "nmon_large = 5\n",
    "hist_t_foci_bin_centers = {\n",
    "   'bondsHistFoci': np.arange(nmon_large),\n",
    "   'clustersHistFoci': np.arange(1, nmon_large + 1)\n",
    "}\n",
    "# Separate dataset for bonds and clusters per\n",
    "for prop, bin_center in hist_t_foci_bin_centers.items():\n",
    "    ens_avgs = list()\n",
    "    for ens_avg_space_db in ens_avg_space_dbs:\n",
    "        space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "        ens_avg = organizer.space_hists(\n",
    "            ens_avg_space_db,\n",
    "            prop,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            project_details[project]['group'],\n",
    "            project_details[project]['geometry'],\n",
    "            project_details[project]['topology'],\n",
    "            bin_center=bin_center,\n",
    "            normalize=True,\n",
    "            is_save = False\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=0)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:, ~ens_avgs.columns.duplicated()]\n",
    "    ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    output =  \"-\".join(['allInOne', project, project_details[project]['group'], prop + \".parquet.brotli\"])\n",
    "    output = analysis_db + output\n",
    "    ens_avgs.to_parquet(output, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f988b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TransFoci and HnsCub Projects: Pair Distance Statistics per project: **bug** or **nuceloid** groups\n",
    "\n",
    "- Applicable to any project in which oair distance matters such as **HnsCub**, **TransFociCub**,and **TransFociCyl**.\n",
    "- These **properties** can be **combined** in one file per project.\n",
    "- Since **per project** datasets are small, we create **one** per project dataset for **all** properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d009009",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details[project]['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "\n",
    "hist_foci_props = ['pairDistHistFoci', 'pairDistRdfFoci']\n",
    "# One per-project database for both property since they are small and related\n",
    "project_ens_avgs = []\n",
    "for prop in hist_foci_props:\n",
    "    prop_ens_avgs = list()\n",
    "    for ens_avg_space_db in ens_avg_space_dbs:\n",
    "        space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "        ens_avg = organizer.space_hists(\n",
    "            ens_avg_space_db,\n",
    "            prop,\n",
    "            project_details[project]['parser'],\n",
    "            project_details[project]['hierarchy'],\n",
    "            project_details[project]['attributes'],\n",
    "            project_details[project]['group'],\n",
    "            project_details[project]['geometry'],\n",
    "            project_details[project]['topology'],\n",
    "            bin_center=None,\n",
    "            normalize=False,\n",
    "            is_save=False\n",
    "        )\n",
    "        prop_ens_avgs.append(ens_avg)\n",
    "    prop_ens_avgs = pd.concat(prop_ens_avgs,axis=0)\n",
    "    # drop duplicated columns:\n",
    "    prop_ens_avgs = prop_ens_avgs.loc[:, ~prop_ens_avgs.columns.duplicated()]\n",
    "    prop_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    project_ens_avgs.append(prop_ens_avgs)\n",
    "project_ens_avgs = pd.concat(project_ens_avgs,axis=1)\n",
    "# drop duplicated columns:\n",
    "project_ens_avgs = project_ens_avgs.loc[:, ~project_ens_avgs.columns.duplicated()]\n",
    "project_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "output = '-'.join(\n",
    "    ['allInOne', project, project_details[project]['group'], 'pairDistStats.parquet.brotli']\n",
    ")\n",
    "output = analysis_db + output\n",
    "project_ens_avgs.to_parquet(output, index=False, compression='brotli')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e801139-3250-4ee2-bcdb-ec412aadf688",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spatial Distributions and the sum rule: **all** group\n",
    "\n",
    "- Finding the spatial histogram, number density, and local volume fraction in different geometries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237d3b9-7cb0-40cb-8d2f-6c86f747702c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cylindrical geometry: \n",
    "\n",
    "- This works for project such as **SumRuleCyl** and **TransFociCyl** in which the spherical beads are confined in a cylinder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d10a90-39c3-417e-870d-1551c2d42c07",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### NOT needed: allInOne Local Distributions: \n",
    "\n",
    "- ensAvg of Hists, Rhos, Phis with var and sem per project: Do not need to run this as the information already exist in the \"allIneOne Sum-Rule\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04ab64-afa1-45c2-8d2c-d0ab198a4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "phase = 'ensAvg'\n",
    "group = 'all'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "       group  + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "# list of unique properties and property_measures:\n",
    "# Local distributions do not have any property_measures:\n",
    "uniq_props, _ = organizer.unique_property(\n",
    "    ens_avg_space_dbs[0] + '*' + \\\n",
    "        project_details[project]['hierarchy'] + '.csv',\n",
    "    2,\n",
    "    [\"-\" + phase],\n",
    "    drop_properties=[\"stamps\"])\n",
    "print(uniq_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353b297-223a-4715-bb48-828ae76bf3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = ['theta', 'z', 'r']\n",
    "for direction in directions:\n",
    "    props_by_dir = [prop for prop in uniq_props if prop.startswith(direction)]\n",
    "    dir_ens_avgs = list()\n",
    "    for prop in props_by_dir:\n",
    "        prop_ens_avgs = list()\n",
    "        for ens_avg_space_db in ens_avg_space_dbs:\n",
    "            space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "            ens_avg = organizer.space_hists(\n",
    "                ens_avg_space_db,\n",
    "                prop,\n",
    "                project_details[project]['parser'],\n",
    "                project_details[project]['hierarchy'],\n",
    "                project_details[project]['attributes'],\n",
    "                group,\n",
    "                project_details[project]['geometry'],\n",
    "                project_details[project]['topology'],\n",
    "                normalize=True,\n",
    "                is_save=False\n",
    "            )\n",
    "            prop_ens_avgs.append(ens_avg)\n",
    "        prop_ens_avgs = pd.concat(prop_ens_avgs,axis=0)\n",
    "        # drop duplicated columns:\n",
    "        prop_ens_avgs = \\\n",
    "            prop_ens_avgs.loc[:, ~prop_ens_avgs.columns.duplicated()]\n",
    "        prop_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "        dir_ens_avgs.append(prop_ens_avgs)\n",
    "    dir_ens_avgs = pd.concat(dir_ens_avgs,axis=1)\n",
    "        # drop duplicated columns:\n",
    "    dir_ens_avgs = dir_ens_avgs.loc[:, ~dir_ens_avgs.columns.duplicated()]\n",
    "    dir_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    output = analysis_db +  \"-\".join([\n",
    "        'allInOne', project,  project_details[project]['group'],  direction + \"LocalDist.parquet.brotli\"\n",
    "    ])\n",
    "    dir_ens_avgs.to_parquet(output, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b4672-ba7b-4453-9f4f-6827487cbd74",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### allInONe Sum-Rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b767a-56de-45d0-8d66-be721b684c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "phase = 'ensAvg'\n",
    "group = 'all'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        group + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "species_dict = project_details[project]['rhosPhisNormalizedScaled']\n",
    "print('species_dict: ', species_dict)\n",
    "directions = ['r', 'z']\n",
    "props= ['Rho', 'Phi']\n",
    "dir_prop_pairs = list(product(props, directions))\n",
    "print('dir_prop_pairs: ', dir_prop_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160344e-b65b-4962-91e4-23334c3f22db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (prop, direction) in dir_prop_pairs:\n",
    "    all_in_one = list()\n",
    "    for (species, size_attr) in species_dict:\n",
    "        per_species = list()\n",
    "        for ens_avg_space_db in ens_avg_space_dbs:\n",
    "            space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "            per_space = organizer.space_sum_rule(\n",
    "                ens_avg_space_db,\n",
    "                prop,\n",
    "                project_details[project]['parser'],\n",
    "                project_details[project]['hierarchy'],\n",
    "                project_details[project]['attributes'],\n",
    "                species,\n",
    "                size_attr,\n",
    "                group,\n",
    "                project_details[project]['geometry'],\n",
    "                project_details[project]['topology'],\n",
    "                direction,\n",
    "                is_save=False\n",
    "            )\n",
    "            per_species.append(per_space)\n",
    "        per_species = pd.concat(per_species,axis=0)\n",
    "        per_species = per_species.loc[:, ~per_species.columns.duplicated()]\n",
    "        per_species.reset_index(inplace=True, drop=True)\n",
    "        all_in_one.append(per_species)\n",
    "    all_in_one = pd.concat(all_in_one,axis=1)\n",
    "    all_in_one = all_in_one.loc[:, ~all_in_one.columns.duplicated()]\n",
    "    all_in_one.reset_index(inplace=True, drop=True)\n",
    "    output = '-'.join(['allInOne', project, group, direction + prop])\n",
    "    output += '-NormalizedScaled.parquet.brotli'\n",
    "    output = analysis_db + output\n",
    "    all_in_one.to_parquet(output, index=False, compression='brotli')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e744e-85e3-480b-95f8-e17781284f94",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cubic geometry:\n",
    "\n",
    "- This works for project such as **TransFociCub** and **HnsCub** in which the spherical beads are in free space or a cubic box with the periodic boundary conditions in all directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e01af0d-0616-4061-a71e-7516825b0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "phase = 'ensAvg'\n",
    "group = 'all'\n",
    "space_dbs = glob(analysis_db + project_details[project]['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "       group + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "species_dict = project_details[project]['rhosPhisNormalizedScaled']\n",
    "print('species_dict: ', species_dict)\n",
    "directions = ['r']\n",
    "props= ['Rho', 'Phi']\n",
    "dir_prop_pairs = list(product(props, directions))\n",
    "print('dir_prop_pairs: ', dir_prop_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570f9325-ae7b-4d4e-a2f1-209c5fa1eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    List,\n",
    "    Dict,\n",
    "    Tuple,\n",
    "    Optional,\n",
    "    Union,\n",
    "    Callable,\n",
    ")\n",
    "import pathlib\n",
    "from glob import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from polyphys.manage.typer import WholeT, EnsembleT\n",
    "from polyphys.analyze.clusters import whole_dist_mat_foci\n",
    "from polyphys.manage.utilizer import round_up_nearest, invalid_keyword\n",
    "\n",
    "from polyphys.manage.organizer import normalize_r, normalize_z, sort_filenames\n",
    "\n",
    "def space_sum_rule(\n",
    "    input_database: str,\n",
    "    property_: str,\n",
    "    parser: Callable,\n",
    "    hierarchy: str,\n",
    "    physical_attrs: List[str],\n",
    "    species: str,\n",
    "    size_attr: str,\n",
    "    group: str,\n",
    "    geometry: str,\n",
    "    topology: str,\n",
    "    direction: str,\n",
    "    divisor: Optional[float] = 0.025,\n",
    "    round_to: Optional[int] = 3,\n",
    "    is_save: Optional[bool] = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Takes the `property_path` to 'ensAvg' local distribution of a given\n",
    "    `property_` in a given space `input_database`, normalize and scale that\n",
    "    distribution, adds the `physical_attrs` of interest as the new columns to\n",
    "    each 'ensAvg' distribution, and merges all the 'ensAvg' distributions into\n",
    "    one 'space' dataframe along the 0 (or 'row' or 'index') in pandas lingo,\n",
    "\n",
    "    In each 'ensemble-averaged' dataframe, there are 4 columns with this name\n",
    "    pattern:\n",
    "\n",
    "    column name = '[long_ensemble]-[property_][-measure]-[stat]'\n",
    "\n",
    "    , and sometimes\n",
    "\n",
    "    column name = 'bin_center'\n",
    "\n",
    "    where '[-measure]' is a physical measurement such as the auto correlation\n",
    "    function (AFC) done on the physical 'property_'. [...] means this keyword\n",
    "    in the column name can be optional. the 'stat' keyword is either 'mean',\n",
    "    'ver', or 'sem'. If the 'bin_center' presents as a column in a\n",
    "    'ensemble_averaged' dataframe, then it is inferred; otherwise, it should\n",
    "    be passed to the function. See `bin_center` kw argument below.\n",
    "\n",
    "    Issues\n",
    "    ------\n",
    "    Currently, `direction` is only defined for 'cylindrical' geometry.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_database: str\n",
    "        Path to the timeseries of the physical property of interest.\n",
    "    property_: str\n",
    "        Name of the physical property of interest.\n",
    "    parser: Callable\n",
    "        A class from 'PolyPhys.manage.parser' module that parses filenames\n",
    "        or filepaths to infer information about a file.\n",
    "    hierarchy: str\n",
    "        The pattern by which the filenames of timeseries are started with; for\n",
    "        instance, \"N*\" means files start with \"N\"\n",
    "    physical_attrs: list of str\n",
    "        The physical attributes that will be added as new columns to the\n",
    "        concatenated timeseries.\n",
    "    species: {'Mon', 'Crd', 'Foci', 'Dna'}\n",
    "        The species of the particles in a group.\n",
    "            'Mon': Monomers or small monomers\n",
    "            'Crd': Crowders\n",
    "            'Foci': Large monomers\n",
    "            'Dna': Small and large monomers\n",
    "    size_attr: str\n",
    "        The attribute of the `parser` object that is the size (diameter) of\n",
    "        species.\n",
    "    group: {'bug', 'nucleoid', 'all'}\n",
    "        The type of the particle group.\n",
    "    geometry : {'cylindrical', 'slit', 'cubic'}\n",
    "        The shape of the simulation box.\n",
    "    topology: str\n",
    "        Topology of the polymer.\n",
    "    direction: {'r', 'z'}\n",
    "        The direction along which operation is done.\n",
    "    divisor: float, default 0.025\n",
    "        The step by which the values of \"phi_c_bulk\" attribute are rounded.\n",
    "    round_to: int, default 3\n",
    "        The number of significant decimal digits in the values of \"phi_c_bulk\"\n",
    "        attribute.\n",
    "    is_save : bool, default False\n",
    "        whether to save output to file or not.\n",
    "\n",
    "    Return\n",
    "    ------\n",
    "    all_in_one: pandas.DataFrame\n",
    "        a dataframe in which all the timeseries are concatenated along `orient`\n",
    "        of interest, and \"properties and attributes\" of interest are added to\n",
    "        it as the new columns.\n",
    "\n",
    "    Requirements\n",
    "    ------------\n",
    "    PolyPhys, Pandas\n",
    "    \"\"\"\n",
    "    normalizer = {\n",
    "        'r': normalize_r,\n",
    "        'z': normalize_z\n",
    "    }\n",
    "    property_ext = \"-\" + group + \"-\" + direction + property_ + species\n",
    "    property_ext += \"-ensAvg.csv\"\n",
    "    prop = direction + property_ + species  # full name of physical property\n",
    "    ens_avg_csvs = glob(input_database + hierarchy + property_ext)\n",
    "    ens_avg_csvs = sort_filenames(ens_avg_csvs, fmts=[\n",
    "        property_ext])\n",
    "    property_db = []\n",
    "    # ens_csvs is a list of tuples, each has one member.\n",
    "    for ens_avg_csv in ens_avg_csvs:\n",
    "        ens_avg = pd.read_csv(ens_avg_csv[0], header=0)\n",
    "        property_info = parser(\n",
    "            ens_avg_csv[0],\n",
    "            'ensemble_long',\n",
    "            geometry,\n",
    "            group,\n",
    "            topology\n",
    "        )\n",
    "        if property_ == 'Phi':\n",
    "            scaler = getattr(property_info, size_attr)\n",
    "            ens_avg[prop + '-scaler'] = scaler\n",
    "            ens_avg[prop + '-scale'] = ens_avg[prop + '-mean'] / scaler\n",
    "        elif property_ == 'Rho':\n",
    "            scaler = getattr(property_info, size_attr)\n",
    "            ens_avg[prop + '-scaler'] = scaler ** 2\n",
    "            ens_avg[prop + '-scale'] = ens_avg[prop + '-mean'] * scaler ** 2\n",
    "        else:\n",
    "            raise NotImplementedError(\n",
    "                \"Sum rule's scaler is only defined for \"\n",
    "                \"'rho' (density) or 'phi' (volume fraction) properties.\"\n",
    "            )\n",
    "        ens_avg[prop + '-scale-normalized_curve'] = \\\n",
    "            ens_avg[prop + '-scale'] / ens_avg[prop + '-scale'].sum()\n",
    "        ens_avg = normalizer[direction](prop, ens_avg)\n",
    "        ens_avg[prop + '-sumrule_constant'] = \\\n",
    "            ens_avg[prop + '-normalizer'] / ens_avg[prop + '-scaler']\n",
    "        ens_avg['bin_center-norm'] = \\\n",
    "            ens_avg['bin_center'] / ens_avg['bin_center'].max()\n",
    "        for attr_name in physical_attrs:\n",
    "            ens_avg[attr_name] = getattr(property_info, attr_name)\n",
    "        ens_avg['bin_center-dcrowd'] = (\n",
    "            2 * ens_avg['bin_center'] / ens_avg['dcrowd']\n",
    "        )\n",
    "        ens_avg['phi_c_bulk_round'] = ens_avg['phi_c_bulk'].apply(\n",
    "            round_up_nearest, args=[divisor, round_to])\n",
    "        if geometry == 'cylindrical':\n",
    "            ens_avg['temp'] = (\n",
    "                (ens_avg['dcyl'] % ens_avg['dcrowd']) /\n",
    "                (ens_avg['dcrowd'])\n",
    "            )\n",
    "            ens_avg['bin_center-dcrowd-recentered'] = (\n",
    "                ens_avg['bin_center-dcrowd'] - ens_avg['temp']\n",
    "            )\n",
    "            ens_avg['bin_center-recentered-norm'] = (\n",
    "                ens_avg['bin_center'] - (ens_avg['dcyl'] % ens_avg['dcrowd'])\n",
    "            )\n",
    "            ens_avg['bin_center-recentered-norm'] = (\n",
    "                ens_avg['bin_center-recentered-norm'] /\n",
    "                ens_avg['bin_center-recentered-norm'].max()\n",
    "            )\n",
    "            ens_avg.drop(columns=['temp'], inplace=True)\n",
    "        property_db.append(ens_avg)\n",
    "    property_db = pd.concat(property_db, axis=0)\n",
    "    property_db.reset_index(inplace=True, drop=True)\n",
    "    if is_save is not False:\n",
    "        save_to_space = database_path(\n",
    "            input_database,\n",
    "            'analysis',\n",
    "            stage='space',\n",
    "            group=group\n",
    "        )\n",
    "        space = save_to_space.split(\"/\")[-2].split(\"-\")[0]\n",
    "        output = \"-\".join([space, group, property_, species])\n",
    "        output += \"-normalizedRescaled-space.csv\"\n",
    "        property_db.to_csv(save_to_space + output, index=False)\n",
    "        print(\"done\")\n",
    "    return property_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b851d34e-db4a-4f24-82ea-61392c97d847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (prop, direction) in dir_prop_pairs:\n",
    "    all_in_one = list()\n",
    "    for (species, size_attr) in species_dict:\n",
    "        per_species = list()\n",
    "        for ens_avg_space_db in ens_avg_space_dbs:\n",
    "            space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "            per_space = space_sum_rule(\n",
    "                ens_avg_space_db,\n",
    "                prop,\n",
    "                project_details[project]['parser'],\n",
    "                project_details[project]['hierarchy'],\n",
    "                project_details[project]['attributes'],\n",
    "                species,\n",
    "                size_attr,\n",
    "                group,\n",
    "                project_details[project]['geometry'],\n",
    "                project_details[project]['topology'],\n",
    "                direction,\n",
    "                is_save=False\n",
    "            )\n",
    "            per_species.append(per_space)\n",
    "        per_species = pd.concat(per_species,axis=0)\n",
    "        per_species = per_species.loc[:, ~per_species.columns.duplicated()]\n",
    "        per_species.reset_index(inplace=True, drop=True)\n",
    "        all_in_one.append(per_species)\n",
    "    all_in_one = pd.concat(all_in_one,axis=1)\n",
    "    all_in_one = all_in_one.loc[:, ~all_in_one.columns.duplicated()]\n",
    "    all_in_one.reset_index(inplace=True, drop=True)\n",
    "    output = '-'.join(['allInOne', project, group, direction + prop])\n",
    "    output += '-NormalizedScaled.parquet.brotli'\n",
    "    output = analysis_db + output\n",
    "    all_in_one.to_parquet(output, index=False, compression='brotli')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfda398-39c1-4a74-afec-414a120ec6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "905eddd834f47278e82c8803001c8cba7ff23ca6cd99b3eaaa45ba7f5342ab1c"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
