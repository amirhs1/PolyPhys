{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9ae7f84",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5107e38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage.parser import \\\n",
    "    SumRuleCyl, TransFociCyl, TransFociCub, HnsCub, HnsCyl\n",
    "from polyphys.analyze import measurer\n",
    "import polyphys.api as api\n",
    "from polyphys.api import PROJECTS_DETAILS as PSD\n",
    "from polyphys.probe import logger\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#  Choose these two before running this script:\n",
    "#project = 'HnsCub'  # 'SumRuleCyl', 'TransFociCyl'\n",
    "#project = 'TransFociCub'\n",
    "#project = 'TransFociCub'\n",
    "project = 'HnsCyl'\n",
    "analysis_db = '/Users/amirhsi_mini/research_data/do_not_delete/'+project+'-analysis/'\n",
    "#analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "#analysis_db = '../../Datasets/HnsCub-N200epshm29kbmm2ens1_2-analysis/'\n",
    "# List of physical properties: Set the project hierarchy\n",
    "project_details = PSD[project]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262003e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# allInOne *whole* and *ensAvg* stamps per project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7fab6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ensemble-averaged stamps per project (ensAvg phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa47d2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dbs = glob(analysis_db + project_details['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details['group'] + '-ensAvg'\n",
    "    )\n",
    "]\n",
    "allInOne_stamps = []\n",
    "for space_db in ens_avg_space_dbs:\n",
    "    stamp_path = project_details['space_hierarchy'] + 'stamps*'\n",
    "    stamp_path = glob(space_db + \"/\" + stamp_path + '.csv')[0]\n",
    "    space_stamps = pd.read_csv(stamp_path)\n",
    "    allInOne_stamps.append(space_stamps)\n",
    "allInOne_stamps = pd.concat(allInOne_stamps, axis=0)\n",
    "allInOne_stamps.reset_index(inplace=True, drop=True)\n",
    "output = analysis_db + \"allInOne-\" + project + \"-stamps-ensAvg.csv\"\n",
    "allInOne_stamps.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c51724",
   "metadata": {
    "tags": []
   },
   "source": [
    "## whole stamps per project (ens phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caf0a825-b48c-41d9-b954-7b988b1dea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_dbs = glob(analysis_db + project_details['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details['group'] + '-ens'\n",
    "    )\n",
    "]\n",
    "allInOne_stamps = []\n",
    "for space_db in ens_avg_space_dbs:\n",
    "    stamp_path = project_details['space_hierarchy'] + 'stamps*'\n",
    "    stamp_path = glob(space_db + \"/\" + stamp_path + '.csv')[0]\n",
    "    space_stamps = pd.read_csv(stamp_path)\n",
    "    allInOne_stamps.append(space_stamps)\n",
    "allInOne_stamps = pd.concat(allInOne_stamps, axis=0)\n",
    "allInOne_stamps.reset_index(inplace=True, drop=True)\n",
    "output = analysis_db + \"allInOne-\" + project + \"-stamps-ens.csv\"\n",
    "allInOne_stamps.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57dcd1-c751-4641-9582-87444ad215ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Logs per project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89344da9-45f7-4652-bf92-6944419d5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'HnsCub'  # 'SumRuleCyl', 'TransFociCyl'\n",
    "#project = 'TransFociCub'\n",
    "#project = 'TransFociCyl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f4943-c0c1-4b5b-b508-ca1b33a2071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_details = {\n",
    "    'SumRuleCyl': {\n",
    "        'space_pat': 'N*D*ac*',\n",
    "        'hierarchy': '/N*.log',  # dir/file\n",
    "        'parser': SumRuleCyl,\n",
    "        'group': 'bug',\n",
    "        'geometry': 'cylindrical',\n",
    "        'topology': 'linear',\n",
    "        'product_idx': 1\n",
    "    },\n",
    "    'TransFociCyl': {\n",
    "        'space_pat': 'ns*nl*al*D*ac*',\n",
    "        'hierarchy': '/eps*.log',  # dir/file\n",
    "        'parser': TransFociCyl,\n",
    "        'group': 'bug',\n",
    "        'geometry': 'cylindrical',\n",
    "        'topology': 'ring',\n",
    "        'product_idx': 2\n",
    "    },\n",
    "    'TransFociCub': {\n",
    "        'space_pat': 'ns*nl*al*ac*',\n",
    "        'hierarchy': '/al*.log',  # dir/file\n",
    "        'parser': TransFociCub,\n",
    "        'group': 'bug',\n",
    "        'geometry': 'cubic',\n",
    "        'topology': 'ring',\n",
    "        'product_idx': 2\n",
    "    },\n",
    "    'HnsCub': {\n",
    "        'space_pat': 'N*epshm*nh*ac*',\n",
    "        'hierarchy': '/N*.log',  # dir/file\n",
    "        'parser': HnsCub,\n",
    "        'group': 'nucleoid',\n",
    "        'geometry': 'cubic',\n",
    "        'topology': 'ring',\n",
    "        'product_idx': 2\n",
    "    }\n",
    "}\n",
    "#log_db = \"/Users/amirhsi_mini/OneDrive - University of Waterloo/PhD Research/Jupyter/Datasets/logs/\"\n",
    "#log_db = '/Users/amirhsi_mini/research_data/TransFociCub/logs/'\n",
    "log_db = '/Users/amirhsi_mini/research_data/do_not_delete/'+project+'-logs/'\n",
    "space_dbs = glob(log_db + log_details[project]['space_pat'] + '-logs')\n",
    "space_dbs.sort()\n",
    "space_with_segment_lineage = [\n",
    "    'N500D10.0ac0.6-logs',\n",
    "    'N500D10.0ac0.8-logs',\n",
    "    'N500D10.0ac1.0-logs',\n",
    "    'N2000D30.0ac4.0-logs',\n",
    "    'N2000D30.0ac6.0-logs'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5c0657-7b02-4f40-b88d-f35e5593fce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thermos = []\n",
    "run_stats = []\n",
    "wall_times = []\n",
    "save_to = './'\n",
    "\n",
    "for space_db in space_dbs:\n",
    "    print(space_db)\n",
    "    space = space_db.split(\"/\")[-1]\n",
    "    if space in space_with_segment_lineage:\n",
    "        lineage = 'segment'\n",
    "    else:\n",
    "        lineage = 'whole'\n",
    "    logs = glob(space_db + log_details[project]['hierarchy'])\n",
    "    logs = organizer.sort_filenames(logs,  fmts=['.log']) # sorted\n",
    "    logs = [log[0] for log in logs]\n",
    "    for log in logs:\n",
    "        log_info = log_details[project]['parser'](\n",
    "            log,\n",
    "            lineage,\n",
    "            log_details[project]['geometry'],\n",
    "            log_details[project]['group'],\n",
    "            log_details[project]['topology']\n",
    "        )\n",
    "        # handling product_idx in segmented logs:\n",
    "        if lineage == 'segment' and log_info.segment_id>1:\n",
    "            product_idx = 0\n",
    "        # handling product_idx in restart logs which do not have product phase\n",
    "        if  not (log.endswith('restart.log') | log.endswith('restart2ndRound.log')):\n",
    "            product_idx = log_details[project]['product_idx']\n",
    "        else:\n",
    "            product_idx = 0\n",
    "        try:\n",
    "            log_data = logger.LammpsLog(log, product_idx)\n",
    "        except (logger.BrokenLogError, IndexError):\n",
    "            print(\"broken log: \", log_info.filepath.split(\"/\")[-1])\n",
    "        log_data.extract_thermo()\n",
    "        log_data.extract_run_stat()\n",
    "        thermo = log_data.thermo\n",
    "        run_stat = log_data.run_stat\n",
    "        wall_time = log_data.wall_time\n",
    "        for attr_name in log_info._lineage_attributes[lineage].keys():\n",
    "            attr_value = getattr(log_info, attr_name)\n",
    "            thermo[attr_name] = attr_value\n",
    "        attr_names = ['phi_m_bulk', 'rho_m_bulk', 'phi_c_bulk', 'rho_c_bulk']\n",
    "        for attr_name in attr_names:\n",
    "            attr_value = getattr(log_info, attr_name)\n",
    "            thermo[attr_name] = attr_value\n",
    "        for lineage_name in log_info.genealogy:\n",
    "            attr_value = getattr(log_info, lineage_name)\n",
    "            thermo[lineage_name] = attr_value\n",
    "            run_stat[lineage_name] = attr_value\n",
    "            wall_time[lineage_name] = attr_value\n",
    "        thermos.append(thermo)\n",
    "        run_stats.append(run_stat)\n",
    "        wall_times.append(wall_time)\n",
    "\n",
    "output = \"-\".join([\"allInOne\", project, \"thermo\"])\n",
    "thermos = pd.concat(thermos)\n",
    "thermos.reset_index(inplace=True, drop=True)\n",
    "thermos.to_parquet(\n",
    "    save_to + output + \".parquet.brotli\", index=False, compression='brotli'\n",
    ")\n",
    "output = \"-\".join([\"allInOne\", project, \"runStat\"])\n",
    "run_stats = pd.concat(run_stats)\n",
    "run_stats.reset_index(inplace=True, drop=True)\n",
    "run_stats.to_csv(save_to + output + \".csv\", index=False)\n",
    "output = \"-\".join([\"allInOne\", project, \"wallTimeStat\"])\n",
    "wall_times = pd.concat(wall_times)\n",
    "wall_times.reset_index(inplace=True, drop=True)\n",
    "wall_times.to_csv(save_to + output + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624d81b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ensAvg timeseries and their associated measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f538b6-83e3-443f-8d4e-612dc9bfaf07",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Measures of chain size timeseries properties per space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc9a63-48f6-45d6-9f30-f2a7d76b560f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### allInONe esnAvg ACFs of the chain-size properties per space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a9ee296-b30e-42a6-b594-bf5990c709ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh16ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh4ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh20ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh0ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh12ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh20ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh0ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh12ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh16ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh4ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh8ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh30ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh30ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh8ac2.0-nucleoid-ensAvg/']\n",
      "['asphericityTMon-acf', 'asphericityTMon-acfLowerCi', 'asphericityTMon-acfUpperCi', 'fsdTMon-acf', 'fsdTMon-acfLowerCi', 'fsdTMon-acfUpperCi', 'gyrTMon-acf', 'gyrTMon-acfLowerCi', 'gyrTMon-acfUpperCi', 'shapeTMon-acf', 'shapeTMon-acfLowerCi', 'shapeTMon-acfUpperCi', 'transSizeTMon-acf', 'transSizeTMon-acfLowerCi', 'transSizeTMon-acfUpperCi']\n",
      "CPU times: user 30.3 s, sys: 3.66 s, total: 33.9 s\n",
      "Wall time: 35.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 60 s for TransFoci\n",
    "# Wall time: 4 min for SumRule\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "# list of unique property_measures:\n",
    "filepath = ens_avg_space_dbs[0] + '*' + project_details['hierarchy'] + '.csv'  # physical properties in all the\n",
    "_, uniq_props_measures = organizer.unique_property(\n",
    "    filepath, 2, [\"-\" + phase], drop_properties=['stamps'])\n",
    "print(uniq_props_measures)\n",
    "for ens_avg_space_db in ens_avg_space_dbs:\n",
    "    ens_avgs = list()\n",
    "    space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "    for property_ in uniq_props_measures:\n",
    "        ens_avg = organizer.space_tseries(\n",
    "            ens_avg_space_db,\n",
    "            property_,\n",
    "            project_details['parser'],\n",
    "            project_details['hierarchy'],\n",
    "            project_details['attributes'],\n",
    "            project_details['group'],\n",
    "            project_details['geometry'],\n",
    "            project_details['topology'],\n",
    "            is_save = False  # if True, save per property per space\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=1)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:,~ens_avgs.columns.duplicated()]\n",
    "    output_name = analysis_db +  \"-\".join(\n",
    "        [space,\n",
    "         project_details['group'],\n",
    "         \"chainSize-acf.parquet.brotli\"\n",
    "        ]\n",
    "    )\n",
    "    ens_avgs.to_parquet(output_name, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259588f1-c129-48c6-98d0-6a1f4990d1ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### **allInOne** the chain-size properties per **space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "844af7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh16ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh4ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh20ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh0ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh12ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh20ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh0ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh12ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh16ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh4ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh8ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh30ac1.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh30ac2.0-nucleoid-ensAvg/', '/Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh8ac2.0-nucleoid-ensAvg/']\n",
      "['gyrTMon', 'asphericityTMon', 'shapeTMon', 'fsdTMon', 'transSizeTMon']\n",
      "CPU times: user 24.8 s, sys: 2.88 s, total: 27.7 s\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 2 min s for TransFoci\n",
    "# Wall time: 7 min for SumRule\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "# list of unique property_measures:\n",
    "filepath = ens_avg_space_dbs[0] + '*' + project_details['hierarchy'] + '.csv'  # physical properties in all the\n",
    "_, uniq_props_measures = organizer.unique_property(\n",
    "    filepath, 2, [\"-\" + phase], drop_properties=['stamps'])\n",
    "props_tseries = list(\n",
    "    set(\n",
    "        [prop.split(\"-acf\")[0] for prop in uniq_props_measures]\n",
    "    )\n",
    ")\n",
    "print(props_tseries)\n",
    "for ens_avg_space_db in ens_avg_space_dbs:\n",
    "    ens_avgs = list()\n",
    "    space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "    for property_ in props_tseries:\n",
    "        ens_avg = organizer.space_tseries(\n",
    "            ens_avg_space_db,\n",
    "            property_,\n",
    "            project_details['parser'],\n",
    "            project_details['hierarchy'],\n",
    "            project_details['attributes'],\n",
    "            project_details['group'],\n",
    "            project_details['geometry'],\n",
    "            project_details['topology'],\n",
    "            is_save = False  # if True, save per property per space\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=1)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:,~ens_avgs.columns.duplicated()]\n",
    "    output_name = analysis_db +  \"-\".join(\n",
    "        [space,  project_details['group'], \"chainSize.parquet.brotli\"]\n",
    "    )\n",
    "    ens_avgs.to_parquet(output_name, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3bcc1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## TransFoci Project: Pair distance time-series per project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836072fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "analysis_db = '/Users/amirhsi_mini/research_data/analysis/'\n",
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "tseries_foci_props = ['pairDistTFoci']\n",
    "project_ens_avgs = []\n",
    "for prop in tseries_foci_props:\n",
    "    prop_ens_avgs = list()\n",
    "    for ens_avg_space_db in ens_avg_space_dbs:\n",
    "        space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "        ens_avg = organizer.space_tseries(\n",
    "            ens_avg_space_db,\n",
    "            prop,\n",
    "            project_details['parser'],\n",
    "            project_details['hierarchy'],\n",
    "            project_details['attributes'],\n",
    "            project_details['group'],\n",
    "            project_details['geometry'],\n",
    "            project_details['topology'],\n",
    "            is_save = False  # if True, save per property per space\n",
    "        )\n",
    "        prop_ens_avgs.append(ens_avg)\n",
    "    prop_ens_avgs = pd.concat(prop_ens_avgs,axis=0)\n",
    "    # drop duplicated columns:\n",
    "    prop_ens_avgs = prop_ens_avgs.loc[:, ~prop_ens_avgs.columns.duplicated()]\n",
    "    prop_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    project_ens_avgs.append(prop_ens_avgs)\n",
    "project_ens_avgs = pd.concat(project_ens_avgs,axis=1)\n",
    "project_ens_avgs = \\\n",
    "    project_ens_avgs.loc[:, ~project_ens_avgs.columns.duplicated()]\n",
    "project_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "output ='-'.join(['allInOne', project, project_details['group'], 'pairDistT.parquet.brotli'])\n",
    "output = analysis_db + output\n",
    "project_ens_avgs.to_parquet(output, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50541f3-23c6-493c-b03c-59791f0c8af9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Equilibrium timeseries properties per space AND per project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6550f1-7813-4bfb-8009-6955a89378ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Whole equilibrium properties allInOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8079e8a-9a4f-4fcd-861e-9c4a3ae02de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No matching files found in the specified path: /Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh0ac1.0-nucleoid-ens",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:7\u001b[0m\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/api.py:273\u001b[0m, in \u001b[0;36mall_in_one_equil_tseries\u001b[0;34m(project, analysis_db, group, spaces, properties, measures, kind, topology, divisor, round_to, save_space, save_to)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    270\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore than one \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhole\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m stamps dataset found. Which of the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    271\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m following is the correct one? \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwhole_stamps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    272\u001b[0m     whole_stamps \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(whole_stamps[\u001b[38;5;241m0\u001b[39m], header\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 273\u001b[0m     space_equil_props \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mequilibrium_wholes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace_db\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproperties\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwhole_stamps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtopology\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopology\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_space\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     all_in_one_equil_props\u001b[38;5;241m.\u001b[39mappend(space_equil_props)\n\u001b[1;32m    284\u001b[0m all_in_one_equil_props \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_in_one_equil_props)\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/analyze/analyzer.py:2100\u001b[0m, in \u001b[0;36mequilibrium_wholes\u001b[0;34m(space, space_db, physical_properties, stat_funcs, whole_stamps, output_type, topology, output_path)\u001b[0m\n\u001b[1;32m   2098\u001b[0m equil_properties \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m physical_property \u001b[38;5;129;01min\u001b[39;00m physical_properties:\n\u001b[0;32m-> 2100\u001b[0m     property_measurements \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m   2101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspace_measure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[43mphysical_property\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstat_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_type\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstat_func\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstat_funcs\u001b[49m\n\u001b[1;32m   2105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2106\u001b[0m     property_measurements \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(property_measurements, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2107\u001b[0m     equil_properties\u001b[38;5;241m.\u001b[39mappend(property_measurements)\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/analyze/analyzer.py:2101\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2098\u001b[0m equil_properties \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m physical_property \u001b[38;5;129;01min\u001b[39;00m physical_properties:\n\u001b[1;32m   2100\u001b[0m     property_measurements \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43mspace_measure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[43mphysical_property\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstat_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_type\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m stat_func \u001b[38;5;129;01min\u001b[39;00m stat_funcs\n\u001b[1;32m   2105\u001b[0m     ]\n\u001b[1;32m   2106\u001b[0m     property_measurements \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(property_measurements, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2107\u001b[0m     equil_properties\u001b[38;5;241m.\u001b[39mappend(property_measurements)\n",
      "File \u001b[0;32m~/OneDrive - University of Waterloo/PhD Research/Jupyter/PolyPhys/polyphys/analyze/analyzer.py:2009\u001b[0m, in \u001b[0;36mspace_measure\u001b[0;34m(property_, space_db, stat_func, kind)\u001b[0m\n\u001b[1;32m   2005\u001b[0m property_paths \u001b[38;5;241m=\u001b[39m sort_filenames(\n\u001b[1;32m   2006\u001b[0m     property_paths, fmts\u001b[38;5;241m=\u001b[39m[property_pat]\n\u001b[1;32m   2007\u001b[0m     )\n\u001b[1;32m   2008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m property_paths:\n\u001b[0;32m-> 2009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   2010\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo matching files found in the specified path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspace_db\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2011\u001b[0m         )\n\u001b[1;32m   2013\u001b[0m meas_name \u001b[38;5;241m=\u001b[39m stat_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m   2014\u001b[0m last_t_index \u001b[38;5;241m=\u001b[39m property_\u001b[38;5;241m.\u001b[39mrfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# index of the last 'T'\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No matching files found in the specified path: /Users/amirhsi_mini/research_data/do_not_delete/HnsCyl-analysis/N200D8.0nh0ac1.0-nucleoid-ens"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 23 s for TransFociCyl\n",
    "# Wall time: 10 min s for SumRule\n",
    "# Wall time: 5 s for TransFociCub\n",
    "spaces = glob(analysis_db + project_details['space_pat'])\n",
    "spaces = sorted(list(set([space.split('/')[-1].split('-')[0] for space in spaces])))\n",
    "save_space = True\n",
    "equili_props_wholes = api.all_in_one_equil_tseries(\n",
    "    project,\n",
    "    analysis_db,\n",
    "    project_details['group'],\n",
    "    spaces,\n",
    "    project_details['time_varying_props'],\n",
    "    project_details['equil_measures'],\n",
    "    save_space=save_space,\n",
    "    divisor=project_details['divisor'],\n",
    "    round_to=3,\n",
    "    kind='dataframe',\n",
    "    save_to=analysis_db,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905bec5d-bb71-445e-adac-3b2374bdf2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_avg = api.all_in_one_equil_tseries_ens_avg(\n",
    "    project,\n",
    "    equili_props_wholes,\n",
    "    project_details['group'],\n",
    "    project_details['equil_properties'],\n",
    "    project_details['equil_attributes'],\n",
    "    save_to=analysis_db\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74045030",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ce532e-3a29-4e50-8bdd-f2c1d5f73c2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Persistence lengths: Hns Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4b231-656f-4c1a-a99d-a94d19cae3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'ensAvg'\n",
    "ext = '.csv'\n",
    "property_ext = phase + '-mean' + ext\n",
    "space_dbs = glob(analysis_db + project_details['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "filepath = ens_avg_space_dbs[0] + project_details['hierarchy'] + ext # physical properties in all the\n",
    "uniq_props,  _ = organizer.unique_property(\n",
    "    filepath, 2, [\"-\" + phase], drop_properties=['stamps'])\n",
    "bond_props = list(\n",
    "    set(\n",
    "        [prop for prop in uniq_props if prop.startswith(\"bondCosine\")]\n",
    "    )\n",
    ")\n",
    "print(bond_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f991b9-1225-4764-8933-3e91f9b92692",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_all_in_one = list()\n",
    "polymer_topo = project_details['topology']\n",
    "for ens_avg_space_db in ens_avg_space_dbs:\n",
    "    ens_avgs = list()\n",
    "    space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "    space_info = project_details['parser'](\n",
    "        space,\n",
    "        'space',\n",
    "        project_details['geometry'],\n",
    "        project_details['group'],\n",
    "        project_details['topology'],\n",
    "        ispath=False\n",
    "    )\n",
    "    bonds_per_topology = {\n",
    "       'linear': np.arange(1, space_info.nmon, 1),\n",
    "       'ring': np.arange(1, space_info.nmon+1, 1)\n",
    "    }\n",
    "    for property_ in bond_props:\n",
    "        ens_avg = organizer.space_hists(\n",
    "            ens_avg_space_db,\n",
    "            property_,\n",
    "            project_details['parser'],\n",
    "            project_details['hierarchy'],\n",
    "            project_details['attributes'],\n",
    "            project_details['group'],\n",
    "            project_details['geometry'],\n",
    "            project_details['topology'],\n",
    "            bin_center=bonds_per_topology[polymer_topo],\n",
    "            normalize=False,\n",
    "            is_save=False\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=1)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:,~ens_avgs.columns.duplicated()]\n",
    "    ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    project_all_in_one.append(ens_avgs)\n",
    "project_all_in_one = pd.concat(project_all_in_one,axis=0)\n",
    "project_all_in_one = \\\n",
    "    project_all_in_one.loc[:, ~project_all_in_one.columns.duplicated()]\n",
    "project_all_in_one.reset_index(inplace=True, drop=True)\n",
    "output = '-'.join(\n",
    "    ['allInOne', project, project_details['group'], 'BondCosCorrVecMon.csv']\n",
    ")\n",
    "output = analysis_db + output\n",
    "project_all_in_one.to_csv(output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1612fd82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Clusters and bonds per project: TransFoci\n",
    "\n",
    "- Applicable to any project in which clustering happens such as **HnsCub**, **TransFociCub**,and **TransFociCyl**.\n",
    "- The histograms of **Clusters** and **bonds** can **not** be combined in **one** dataset.\n",
    "- Since **per project** datasets are small, we create **one** per project dataset for each property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d12660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "\n",
    "nmon_large = 5\n",
    "hist_t_foci_bin_centers = {\n",
    "   'bondsHistFoci': np.arange(nmon_large),\n",
    "   'clustersHistFoci': np.arange(1, nmon_large + 1)\n",
    "}\n",
    "# Separate dataset for bonds and clusters per\n",
    "for prop, bin_center in hist_t_foci_bin_centers.items():\n",
    "    ens_avgs = list()\n",
    "    for ens_avg_space_db in ens_avg_space_dbs:\n",
    "        space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "        ens_avg = organizer.space_hists(\n",
    "            ens_avg_space_db,\n",
    "            prop,\n",
    "            project_details['parser'],\n",
    "            project_details['hierarchy'],\n",
    "            project_details['attributes'],\n",
    "            project_details['group'],\n",
    "            project_details['geometry'],\n",
    "            project_details['topology'],\n",
    "            bin_center=bin_center,\n",
    "            normalize=True,\n",
    "            is_save = False\n",
    "        )\n",
    "        ens_avgs.append(ens_avg)\n",
    "    ens_avgs = pd.concat(ens_avgs,axis=0)\n",
    "    # drop duplicated columns:\n",
    "    ens_avgs = ens_avgs.loc[:, ~ens_avgs.columns.duplicated()]\n",
    "    ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    output =  \"-\".join(['allInOne', project, project_details['group'], prop + \".parquet.brotli\"])\n",
    "    output = analysis_db + output\n",
    "    ens_avgs.to_parquet(output, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f988b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## TransFoci and HnsCub Projects: Pair Distance Statistics per project: **bug** or **nuceloid** groups\n",
    "\n",
    "- Applicable to any project in which oair distance matters such as **HnsCub**, **TransFociCub**,and **TransFociCyl**.\n",
    "- These **properties** can be **combined** in one file per project.\n",
    "- Since **per project** datasets are small, we create **one** per project dataset for **all** properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d009009",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'ensAvg'\n",
    "space_dbs = glob(analysis_db + project_details['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        project_details['group'] + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "hist_foci_props = ['pairDistHistFoci', 'pairDistRdfFoci']\n",
    "# One per-project database for both property since they are small and related\n",
    "project_ens_avgs = []\n",
    "for prop in hist_foci_props:\n",
    "    prop_ens_avgs = list()\n",
    "    for ens_avg_space_db in ens_avg_space_dbs:\n",
    "        space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "        ens_avg = organizer.space_hists(\n",
    "            ens_avg_space_db,\n",
    "            prop,\n",
    "            project_details['parser'],\n",
    "            project_details['hierarchy'],\n",
    "            project_details['attributes'],\n",
    "            project_details['group'],\n",
    "            project_details['geometry'],\n",
    "            project_details['topology'],\n",
    "            bin_center=None,\n",
    "            normalize=False,\n",
    "            is_save=False\n",
    "        )\n",
    "        prop_ens_avgs.append(ens_avg)\n",
    "    prop_ens_avgs = pd.concat(prop_ens_avgs,axis=0)\n",
    "    # drop duplicated columns:\n",
    "    prop_ens_avgs = prop_ens_avgs.loc[:, ~prop_ens_avgs.columns.duplicated()]\n",
    "    prop_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    project_ens_avgs.append(prop_ens_avgs)\n",
    "project_ens_avgs = pd.concat(project_ens_avgs,axis=1)\n",
    "# drop duplicated columns:\n",
    "project_ens_avgs = project_ens_avgs.loc[:, ~project_ens_avgs.columns.duplicated()]\n",
    "project_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "output = '-'.join(\n",
    "    ['allInOne', project, project_details['group'], 'pairDistStats.parquet.brotli']\n",
    ")\n",
    "output = analysis_db + output\n",
    "project_ens_avgs.to_parquet(output, index=False, compression='brotli')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e801139-3250-4ee2-bcdb-ec412aadf688",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spatial Distributions and the sum rule: **all** group\n",
    "\n",
    "- Finding the spatial histogram, number density, and local volume fraction in different geometries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d10a90-39c3-417e-870d-1551c2d42c07",
   "metadata": {
    "tags": []
   },
   "source": [
    "### NOT needed: allInOne Local Distributions: \n",
    "\n",
    "- ensAvg of Hists, Rhos, Phis with var and sem per project: Do not need to run this as the information already exist in the \"allIneOne Sum-Rule\" section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04ab64-afa1-45c2-8d2c-d0ab198a4c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'ensAvg'\n",
    "group = 'all'\n",
    "space_dbs = glob(analysis_db + project_details['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "       group  + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "# list of unique properties and property_measures:\n",
    "# Local distributions do not have any property_measures:\n",
    "uniq_props, _ = organizer.unique_property(\n",
    "    ens_avg_space_dbs[0] + '*' + \\\n",
    "        project_details['hierarchy'] + '.csv',\n",
    "    2,\n",
    "    [\"-\" + phase],\n",
    "    drop_properties=[\"stamps\"])\n",
    "print(uniq_props)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9353b297-223a-4715-bb48-828ae76bf3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "directions = ['theta', 'z', 'r']\n",
    "for direction in directions:\n",
    "    props_by_dir = [prop for prop in uniq_props if prop.startswith(direction)]\n",
    "    dir_ens_avgs = list()\n",
    "    for prop in props_by_dir:\n",
    "        prop_ens_avgs = list()\n",
    "        for ens_avg_space_db in ens_avg_space_dbs:\n",
    "            space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "            ens_avg = organizer.space_hists(\n",
    "                ens_avg_space_db,\n",
    "                prop,\n",
    "                project_details['parser'],\n",
    "                project_details['hierarchy'],\n",
    "                project_details['attributes'],\n",
    "                group,\n",
    "                project_details['geometry'],\n",
    "                project_details['topology'],\n",
    "                normalize=True,\n",
    "                is_save=False\n",
    "            )\n",
    "            prop_ens_avgs.append(ens_avg)\n",
    "        prop_ens_avgs = pd.concat(prop_ens_avgs,axis=0)\n",
    "        # drop duplicated columns:\n",
    "        prop_ens_avgs = \\\n",
    "            prop_ens_avgs.loc[:, ~prop_ens_avgs.columns.duplicated()]\n",
    "        prop_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "        dir_ens_avgs.append(prop_ens_avgs)\n",
    "    dir_ens_avgs = pd.concat(dir_ens_avgs,axis=1)\n",
    "        # drop duplicated columns:\n",
    "    dir_ens_avgs = dir_ens_avgs.loc[:, ~dir_ens_avgs.columns.duplicated()]\n",
    "    dir_ens_avgs.reset_index(inplace=True, drop=True)\n",
    "    output = analysis_db +  \"-\".join([\n",
    "        'allInOne', project,  project_details['group'],  direction + \"LocalDist.parquet.brotli\"\n",
    "    ])\n",
    "    dir_ens_avgs.to_parquet(output, index=False, compression='brotli')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b4672-ba7b-4453-9f4f-6827487cbd74",
   "metadata": {
    "tags": []
   },
   "source": [
    "### allInONe Sum-Rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2b767a-56de-45d0-8d66-be721b684c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase = 'ensAvg'\n",
    "group = 'all'\n",
    "space_dbs = glob(analysis_db + project_details['space_pat'])\n",
    "ens_avg_space_dbs = [\n",
    "    space_db + \"/\" for space_db in space_dbs if space_db.endswith(\n",
    "        group + '-' + phase\n",
    "    )\n",
    "]\n",
    "print(ens_avg_space_dbs)\n",
    "species_dict = project_details['rhosPhisNormalizedScaled']\n",
    "print('species_dict: ', project_details['rhosPhisNormalizedScaled'])\n",
    "dir_prop_pairs = list(\n",
    "    product(project_details['props'],\n",
    "            project_details['directions'])\n",
    ")\n",
    "print('dir_prop_pairs: ', dir_prop_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160344e-b65b-4962-91e4-23334c3f22db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (prop, direction) in dir_prop_pairs:\n",
    "    all_in_one = list()\n",
    "    for (species, size_attr) in species_dict:\n",
    "        per_species = list()\n",
    "        for ens_avg_space_db in ens_avg_space_dbs:\n",
    "            space = ens_avg_space_db.split('/')[-2].split('-')[0]\n",
    "            per_space = organizer.space_sum_rule(\n",
    "                ens_avg_space_db,\n",
    "                prop,\n",
    "                project_details['parser'],\n",
    "                project_details['hierarchy'],\n",
    "                project_details['attributes'],\n",
    "                species,\n",
    "                size_attr,\n",
    "                group,\n",
    "                project_details['geometry'],\n",
    "                project_details['topology'],\n",
    "                direction,\n",
    "                is_save=False\n",
    "            )\n",
    "            per_species.append(per_space)\n",
    "        per_species = pd.concat(per_species,axis=0)\n",
    "        per_species = per_species.loc[:, ~per_species.columns.duplicated()]\n",
    "        per_species.reset_index(inplace=True, drop=True)\n",
    "        all_in_one.append(per_species)\n",
    "    all_in_one = pd.concat(all_in_one,axis=1)\n",
    "    all_in_one = all_in_one.loc[:, ~all_in_one.columns.duplicated()]\n",
    "    all_in_one.reset_index(inplace=True, drop=True)\n",
    "    output = '-'.join(['allInOne', project, group, direction + prop])\n",
    "    output += '-NormalizedScaled.parquet.brotli'\n",
    "    output = analysis_db + output\n",
    "    all_in_one.to_parquet(output, index=False, compression='brotli')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "905eddd834f47278e82c8803001c8cba7ff23ca6cd99b3eaaa45ba7f5342ab1c"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
