{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39283dc0-6a1b-42d8-a160-990f6eb5d961",
   "metadata": {},
   "source": [
    "# Theoretical background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a147ac00-6dfc-4d45-b760-16668304b7e9",
   "metadata": {},
   "source": [
    "## Statistical Confidence in MD measurement\n",
    "Due to the finite time of a molecular dynamics, there is always some degree of correlation within a set of computational measurement. To esimate this correlation and incorporate it in the error analysis, *statistical inefficiency (SI)* is defined based on the relation between the variance of the mean and the autocorrelation function of the quantity of interest, and then, it is measured using different computational techniques ([Tildesley](https://doi.org/10.1093/oso/9780198803195.001.0001), [Rapaport](https://doi.org/10.1017/CBO9780511816581))\n",
    "\n",
    "\n",
    "Assuming $\\{R_N\\}$ as the data set of chain size $R$, the mean and variance of the mean are respectively\n",
    "$$\\langle R\\rangle=\\frac{1}{N}\\sum_{i=1}^{N}X_i$$\n",
    "$$\\sigma^2(\\langle R\\rangle)=\\frac{s}{N}\\sigma^2(R)$$\n",
    "where $\\sigma$ is the bias-corrected variance of the data set\n",
    "$$\\sigma^2(R)=\\frac{1}{N-1}\\sum_{i=1}^{N}(R_i-\\langle R\\rangle)^2$$\n",
    "and $s$ is the SI and estimated by means of the blocking method ([Flyvbjerg](https://doi.org/10.1063/1.457480)). In this method, the original data set is sequentially chunked in $N_{block}=\\{1,2,4,8, 2^{M}\\dots <N\\}$ blocks. The data in each set of new blocks are the mean of $N_{block}$ data in the original data set. In each blocking tranform, the SE $s$ is measured in the following way\n",
    "$$s_{block} = \\frac{L_{block}\\sigma^2_{block}}{\\sigma^2(R)}$$\n",
    "Where $L_{block}$ is the size of blocks after $M-\\text{th}$ transfrom and $\\sigma^2_{block}$ is variance of the block mean. For $M=1$, we have the trivial value of $1$. Using the blocking method, it is also possible to find error in $\\sigma^2_{block}$ \n",
    "$$\\Delta\\sigma^2_{block}=\\sqrt{\\frac{2}{L_{block}-1}}\\sigma^2_{block}$$\n",
    " the SI of the original data $s$ is the integer found by fitting a line to the platuae of $s_{block}$ vs $\\frac{1}{L_{block}}$ diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a9024-bd7f-46f3-bfa6-03115598f7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import  matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from polyphys.analyze import analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61675df-69a5-42c5-8275-3e144d5a7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tseries = glob(\"./N*TMon.csv\")\n",
    "database = \"/Users/amirhsi_mini/research_data/hns_cubic/N200epshm29nh36ac2nc5969mc8l25dt0.005ndump2000adump5000ens1\"\n",
    "data_file = glob(database + \"/*gyrTDna.txt\")[0]\n",
    "data = pd.DataFrame(np.loadtxt(data_file), columns=[\"t\", \"gyr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f6cff-dd0b-40f0-b784-a411fe981bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv(tseries[0],header=0)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1a9647-cdda-4ff6-8f62-e9d73b761eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(nrows=1, ncols=1, figsize=(16, 9))\n",
    "axes.grid(True, which=\"both\")\n",
    "for idx in range(1,2):\n",
    "    result = analyzer.error_calc_block(data.iloc[:,idx].to_numpy(), './block_analysis')\n",
    "    result['si'].plot()\n",
    "\n",
    "    axes.errorbar(result['ntransfroms'], result['si'], yerr=result['si_err'], fmt='--o')\n",
    "axes.set_xlabel(r\"Number of transformation: $n_{block}}$\")\n",
    "axes.set_ylabel(r\"Statistical inefficiency: $s(n_{block})$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c86e6-3406-4f13-ab6b-07832ff52f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data.iloc[:,1].to_numpy()\n",
    "result = analyzer.error_calc_block(a,'./block_analysis')\n",
    "result['si'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf123b-c5c7-4160-ad8a-3a0ed6b9dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213cb774-8761-4dbd-b979-231417515c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "nstep = len(a)\n",
    "# Simple calculation of average and variance\n",
    "a_avg   = np.sum(a)/nstep        # Sample average\n",
    "a       = a - a_avg              # Centre the data\n",
    "a_var_1 = np.sum(a**2)/(nstep-1) # Bias-corrected sample variance\n",
    "a_err   = np.sqrt(a_var_1/nstep) # Error estimate neglecting any correlations\n",
    "print( \"{:40}{:15.6f}\".format('Sample average value', a_avg ) )\n",
    "print( 'Deviation should (typically) lie within +/- exact error estimate' )\n",
    "print( \"{:40}{:15.6f}\".format('Sample variance', a_var_1 ) )\n",
    "print( \"{:40}{:15.6f}\".format('Error estimate neglecting correlations', a_err ) )\n",
    "print( 'This should be very over-optimistic!' )\n",
    "\n",
    "\n",
    "nblock = nstep\n",
    "tblock = 1\n",
    "\n",
    "print( \"{:>15}{:>15}{:>15}{:>15}\".format('tblock', 'nblock', 'error estimate', 'estimate of SI') )\n",
    "\n",
    "while True: # Loop over number, and hence length, of blocks\n",
    "    nblock = nblock // 2 # Halve the number of blocks, rounding down if nblock is odd\n",
    "    tblock = tblock*2    # Double the block length\n",
    "    if nblock < 3:\n",
    "        break\n",
    "    a[0:nblock] = ( a[0:2*nblock-1:2] + a[1:2*nblock:2] ) / 2.0 # Blocking transformation, halving the data set\n",
    "    a_avg       = np.sum ( a[0:nblock] ) / nblock               # Re-compute sample average\n",
    "    a[0:nblock] = a[0:nblock] - a_avg                           # Re-centre in case of dropped points (odd nblock)\n",
    "    a_var       = np.sum ( a[0:nblock]**2 ) / (nblock-1)        # Bias-corrected variance of block averages\n",
    "    a_err       = np.sqrt ( a_var / nblock )                    # Estimate of error from block average variance\n",
    "    si          = tblock * a_var / a_var_1                      # Statistical inefficiency\n",
    "    print( \"{:15d}{:15d}{:15.6f}{:15.6f}\".format(tblock, nblock, a_err, si) )\n",
    "\n",
    "print('Plateau at large tblock (small nblock)')\n",
    "print('should agree quite well with exact error estimate')\n",
    "print('Can plot SI or error**2 against 1/tblock or log2(tblock)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7baf657-3f24-4366-a4c1-cb19de9f6daf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (XPython)",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
