{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.manage import utilizer \n",
    "from polyphys.manage.parser import HnsCyl, HnsCub\n",
    "from polyphys.analyze import clusters\n",
    "from polyphys.analyze import measurer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monomer patch direct contact\n",
    "D=np.array([[\n",
    "0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ],[\n",
    "0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0\n",
    "]], dtype=np.int_)\n",
    "# monomer core direct contact absed on the above matrix\n",
    "M=np.array([[\n",
    "0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 ],[\n",
    "1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 ],[\n",
    "0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 0 , 0 , 0 ]],dtype=np.int_)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check created M by the function is equal to the M contructed above by hand\n",
    "M_created = clusters.generate_mon_bind_direct(D,2)\n",
    "print(M_created)\n",
    "print(M_created.shape)\n",
    "print(np.sum(M_created==M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decompse M_created based on dangling/brdiging binders\n",
    "M_created_dangler, M_created_bridger = clusters.split_binder_matrix(M_created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_created_bridger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_created_dangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bind_bind_dir_mat = clusters.find_binder_clusters(M_created)\n",
    "print(bind_bind_dir_mat)\n",
    "print()\n",
    "bind_bind_full_mat = \\\n",
    "    clusters.generate_contact_matrix(bind_bind_dir_mat)\n",
    "print(bind_bind_full_mat)\n",
    "bind_clusters = clusters.count_foci_clusters(bind_bind_full_mat)\n",
    "print(bind_clusters)\n",
    "bind_contacts = clusters.count_foci_bonds(bind_bind_dir_mat)\n",
    "print(bind_contacts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workding with real files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From Mon-HNS-Patch distance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probe-like script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this file to probe trj bug wholes in cubic geometry\n",
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "import numpy as np\n",
    "from polyphys.manage.parser import HnsCub\n",
    "from polyphys.analyze import clusters\n",
    "\n",
    "save_to = \"/Users/amirhsi_mini/research_data/\"\n",
    "database = '/Users/amirhsi_mini/research_data/hns_distance/'\n",
    "wholes = organizer.sort_filenames(\n",
    "    glob(database+\"N*.npy\"),fmts=['npy'])\n",
    "for idx in range(len(wholes)):\n",
    "    whole = wholes[idx][0]\n",
    "    print(whole)\n",
    "    dist_m_hp = np.load(whole)\n",
    "    sim_info = HnsCub(\n",
    "            whole,\n",
    "            'whole',\n",
    "            'cubic',\n",
    "            'nucleoid',\n",
    "            'ring'\n",
    "        )\n",
    "    sim_name = sim_info.lineage_name + \"-\" + sim_info.group\n",
    "    lj_cut = 2**(1/6)\n",
    "    r_cutoff = np.round(\n",
    "        0.5 * lj_cut * (sim_info.dmon + sim_info.dhns_patch), 3\n",
    "        )\n",
    "    n_frames , n_mon, n_hpatch = dist_m_hp.shape\n",
    "    n_hcore = n_hpatch // 2\n",
    "    # Process each time step\n",
    "    foci_t = np.zeros((n_frames, n_hcore, n_hcore))\n",
    "    dir_contacts_t = np.zeros(\n",
    "        (n_frames, n_hcore, n_hcore), dtype=int\n",
    "    )\n",
    "    bonds_t = np.zeros((n_frames, n_hcore), dtype=int)\n",
    "    clusters_t = np.zeros((n_frames, n_hcore+1), dtype=int)\n",
    "\n",
    "    bonds_dangler_t = np.zeros((n_frames, n_hcore), dtype=int)\n",
    "    clusters_dangler_t = np.zeros((n_frames, n_hcore+1), dtype=int)\n",
    "\n",
    "    bonds_bridger_t = np.zeros((n_frames, n_hcore), dtype=int)\n",
    "    clusters_bridger_t = np.zeros((n_frames, n_hcore+1), dtype=int)\n",
    "    for idx in range(n_frames):\n",
    "        dir_m_hp_dirty = clusters.find_direct_contacts(\n",
    "            dist_m_hp[idx], r_cutoff, inclusive=False\n",
    "            )\n",
    "        dir_m_hp = clusters.enforce_single_patch_dir_contact(dir_m_hp_dirty)\n",
    "        dir_m_hc = clusters.generate_mon_bind_direct(dir_m_hp,2)\n",
    "        dir_m_hc_dangler, dir_m_hc_bridger = clusters.split_binder_matrix(dir_m_hc)\n",
    "        \n",
    "        # bound binder direct contact matirx\n",
    "        dir_hc_hc = clusters.find_binder_clusters(dir_m_hc)\n",
    "        bonds_stat = clusters.count_foci_bonds(dir_hc_hc)\n",
    "        bonds_t[idx] = bonds_stat \n",
    "        full_hc_hc = clusters.generate_contact_matrix_new(dir_hc_hc)\n",
    "        clusters_stat = clusters.count_foci_clusters(full_hc_hc)\n",
    "        clusters_t[idx] = clusters_stat\n",
    "        # dangling binder direct contact matirx\n",
    "        dir_hc_hc = clusters.find_binder_clusters(dir_m_hc_dangler)\n",
    "        bonds_stat = clusters.count_foci_bonds(dir_hc_hc)\n",
    "        bonds_dangler_t[idx] = bonds_stat\n",
    "        full_hc_hc = clusters.generate_contact_matrix_new(dir_hc_hc)\n",
    "        clusters_stat = clusters.count_foci_clusters(full_hc_hc)\n",
    "        clusters_dangler_t[idx] = clusters_stat\n",
    "        # bridging binder direct contact matirx\n",
    "        dir_hc_hc = clusters.find_binder_clusters(dir_m_hc_bridger) \n",
    "        bonds_stat = clusters.count_foci_bonds(dir_hc_hc)\n",
    "        bonds_bridger_t[idx] = bonds_stat\n",
    "        full_hc_hc = clusters.generate_contact_matrix_new(dir_hc_hc)\n",
    "        clusters_stat = clusters.count_foci_clusters(full_hc_hc)\n",
    "        clusters_bridger_t[idx] = clusters_stat\n",
    "    \n",
    "    np.save(save_to + sim_name + '-bondsHistTHnsCore.npy', bonds_t)\n",
    "    np.save(save_to + sim_name + '-clustersHistTHnsCore.npy', clusters_t)\n",
    "    np.save(save_to + sim_name + '-bondsHistDangleTHnsCore.npy',\n",
    "            bonds_dangler_t)\n",
    "    np.save(save_to + sim_name + '-clustersHistDangleTHnsCore.npy',\n",
    "            clusters_dangler_t)\n",
    "    np.save(save_to + sim_name + '-bondsHistBridgeTHnsCore.npy',\n",
    "            bonds_bridger_t)\n",
    "    np.save(save_to + sim_name + '-clustersHistBridgeTHnsCore.npy',\n",
    "            clusters_bridger_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback       \n",
    "        \n",
    "# Pre-allocate some space\n",
    "database = '/Users/amirhsi_mini/research_data/hns_distance/'\n",
    "wholes = organizer.sort_filenames(glob(database+\"N*.npy\"),fmts=['npy'])\n",
    "for idx in range(len(wholes)):\n",
    "    whole = wholes[idx][0]\n",
    "    print(whole)\n",
    "    dist_m_hp = np.load(whole)\n",
    "    sim_info = HnsCub(\n",
    "            whole,\n",
    "            'whole',\n",
    "            'cubic',\n",
    "            'nucleoid',\n",
    "            'ring'\n",
    "        )\n",
    "    sim_name = sim_info.lineage_name + \"-\" + sim_info.group\n",
    "    lj_cut = 2**(1/6)\n",
    "    r_cutoff = np.round(\n",
    "        0.5 * lj_cut * (sim_info.dmon + sim_info.dhns_patch), 3\n",
    "        )\n",
    "    n_frames , n_mon, n_hpatch = dist_m_hp.shape\n",
    "    n_hcore = n_hpatch // 2\n",
    "    # Process each time step\n",
    "    foci_t = np.zeros((n_frames, n_hcore, n_hcore))\n",
    "    dir_contacts_t = np.zeros(\n",
    "        (n_frames, n_hcore, n_hcore), dtype=int\n",
    "    )\n",
    "    bonds_t = np.zeros((n_frames, n_hcore), dtype=int)\n",
    "    clusters_t = np.zeros((n_frames, n_hcore+1), dtype=int)\n",
    "\n",
    "    bonds_dangler_t = np.zeros((n_frames, n_hcore), dtype=int)\n",
    "    clusters_dangler_t = np.zeros((n_frames, n_hcore+1), dtype=int)\n",
    "\n",
    "    bonds_bridger_t = np.zeros((n_frames, n_hcore), dtype=int)\n",
    "    clusters_bridger_t = np.zeros((n_frames, n_hcore+1), dtype=int)\n",
    "    save_to = \"/Users/amirhsi_mini/research_data/\"\n",
    "    error_logs = pd.DataFrame(columns=['Frame_Index', 'Error_Message'])\n",
    "    for idx in range(n_frames):\n",
    "        dir_m_hp_dirty = clusters.find_direct_contacts(\n",
    "            dist_m_hp[idx], r_cutoff, inclusive=False\n",
    "            )\n",
    "        dir_m_hp = clusters.enforce_single_patch_dir_contact(dir_m_hp_dirty)\n",
    "        dir_m_hc = clusters.generate_mon_bind_direct(dir_m_hp, 2)\n",
    "        dir_m_hc_dangler, dir_m_hc_bridger = \\\n",
    "            clusters.split_binder_matrix(dir_m_hc)\n",
    "        try:\n",
    "            # bound binder direct contact matirx\n",
    "            dir_hc_hc = clusters.find_binder_clusters(dir_m_hc)\n",
    "            bonds_stat = clusters.count_foci_bonds(dir_hc_hc)\n",
    "            bonds_t[idx] = bonds_stat\n",
    "            full_hc_hc = clusters.generate_contact_matrix(dir_hc_hc)\n",
    "            if not clusters.is_symmetric(full_hc_hc):\n",
    "                print(\"bridge\")\n",
    "                print(idx)\n",
    "                break\n",
    "            clusters_stat = clusters.count_foci_clusters(full_hc_hc)\n",
    "            clusters_t[idx] = clusters_stat\n",
    "            # dangling binder direct contact matirx\n",
    "            dir_hc_hc = clusters.find_binder_clusters(dir_m_hc_dangler)\n",
    "            bonds_stat = clusters.count_foci_bonds(dir_hc_hc)\n",
    "            bonds_dangler_t[idx] = bonds_stat\n",
    "            full_hc_hc = clusters.generate_contact_matrix(dir_hc_hc)\n",
    "            clusters_stat = clusters.count_foci_clusters(full_hc_hc)\n",
    "            if not clusters.is_symmetric(full_hc_hc):\n",
    "                print(\"dangle\")\n",
    "                print(idx)\n",
    "                break\n",
    "            clusters_dangler_t[idx] = clusters_stat\n",
    "            # bridging binder direct contact matirx\n",
    "            dir_hc_hc = clusters.find_binder_clusters(dir_m_hc_bridger)\n",
    "            bonds_stat = clusters.count_foci_bonds(dir_hc_hc)\n",
    "            bonds_bridger_t[idx] = bonds_stat\n",
    "            full_hc_hc = clusters.generate_contact_matrix(dir_hc_hc)\n",
    "            if not clusters.is_symmetric(full_hc_hc):\n",
    "                print(\"bridge\")\n",
    "                print(idx)\n",
    "                break\n",
    "            clusters_stat = clusters.count_foci_clusters(full_hc_hc)\n",
    "            clusters_bridger_t[idx] = clusters_stat\n",
    "        except Exception as e:\n",
    "            # Log the error with frame index\n",
    "            error_message = \\\n",
    "                f\"Error at frame {idx} in whole {idx}: {str(e)}\\n\" + \\\n",
    "                f\"Traceback: {traceback.format_exc()}\"\n",
    "            print(error_message)\n",
    "            #new_row = pd.DataFrame({'Frame_Index': [idx], 'Error_Message': [error_message]})\n",
    "            #error_logs = pd.concat([error_logs, new_row], ignore_index=True)\n",
    "            break\n",
    "            #continue\n",
    "    \n",
    "    np.save(save_to + sim_name + '-bondsHistTHnsCore.npy', bonds_t)\n",
    "    np.save(save_to + sim_name + '-clustersHistTHnsCore.npy', clusters_t)\n",
    "    np.save(save_to + sim_name + '-bondsHistDangleTHnsCore.npy', bonds_dangler_t)\n",
    "    np.save(save_to + sim_name + '-clustersHistDangleTHnsCore.npy', clusters_dangler_t)\n",
    "    np.save(save_to + sim_name + '-bondsHistBridgeTHnsCore.npy', bonds_bridger_t)\n",
    "    np.save(save_to + sim_name + '-clustersHistBridgeTHnsCore.npy', clusters_bridger_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prober"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this file to probe trj bug wholes in cubic geometry\n",
    "from glob import glob\n",
    "from polyphys.manage import organizer\n",
    "from polyphys.probe import prober\n",
    "\n",
    "# analyzing bug files.\n",
    "group = 'nucleoid'\n",
    "lineage = 'whole'\n",
    "save_to = '/Users/amirhsi_mini/research_data/' \n",
    "database = '/Users/amirhsi_mini/research_data/HnsCub/N*'\n",
    "bug_pairs = glob(database + group + '*')\n",
    "bug_pairs = organizer.sort_filenames(\n",
    "    bug_pairs,\n",
    "    fmts=['.' + group + '.data', '.' + group + '.lammpstrj']\n",
    ")\n",
    "for (bug_topo, bug_trj) in bug_pairs:\n",
    "    print(bug_trj)\n",
    "    prober.hns_nucleoid_cub_dis_hc_hc_cluster(bug_topo, bug_trj, lineage, save_to=save_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mon-HNS-Patch-Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = '/Users/amirhsi_mini/research_data/hns_clusters/N*/N*/'\n",
    "suffices = [\"bondsHistBridgeTHnsCore\", \"bondsHistDangleTHnsCore\", \n",
    "            \"bondsHistTHnsCore\", \"clustersHistBridgeTHnsCore\",\"clustersHistDangleTHnsCore\",\"clustersHistTHnsCore\"]\n",
    "#suffices = [\"bondsHistTHnsCore\", \"clustersHistTHnsCore\"]\n",
    "wholes = organizer.sort_filenames(glob(database+\"N*error_logs.csv\"),fmts=['error_logs.csv']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "dfs = []\n",
    "for f in wholes:\n",
    "    #print(f)\n",
    "    df = pd.read_csv(f[0])\n",
    "    sim_info = HnsCub(\n",
    "                f[0],\n",
    "                'whole',\n",
    "                'cubic',\n",
    "                'nucleoid',\n",
    "                'ring'\n",
    "            )\n",
    "    if not df.empty:\n",
    "        #print(sim_info.whole)\n",
    "        df[\"whole\"] = sim_info.whole\n",
    "        df[\"nhns\"] =  sim_info.nhns\n",
    "        df[\"phi_c_bulk_round\"] = round(sim_info.phi_c_bulk,3)\n",
    "        df[\"eps_hc\"] = sim_info.eps_hc\n",
    "        df[\"ens\"] = sim_info.ensemble_id\n",
    "        dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.groupby(['nhns','phi_c_bulk_round', 'eps_hc', \"ens\"]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "database = '/Users/amirhsi_mini/research_data/'\n",
    "#suffices = [\"bondsHistBridgeTHnsCore\", \"bondsHistDangleTHnsCore\", \n",
    "#            \"bondsHistTHnsCore\", \"clustersHistBridgeTHnsCore\",\"clustersHistDangleTHnsCore\",\"clustersHistTHnsCore\"]\n",
    "suffices = [\"bondsHistTHnsCore\", \"clustersHistTHnsCore\"]\n",
    "df = defaultdict(list)\n",
    "for suffix in suffices:\n",
    "    wholes = organizer.sort_filenames(glob(database+\"N*.npy\"),fmts=[suffix+'.npy']) \n",
    "    for whole in wholes:\n",
    "        sim_info = HnsCub(\n",
    "                whole[0],\n",
    "                'whole',\n",
    "                'cubic',\n",
    "                'nucleoid',\n",
    "                'ring'\n",
    "            )\n",
    "        whole_array = np.load(whole[0])\n",
    "        whole_mean = np.mean(whole_array,axis=0)\n",
    "        for idx in range(len(whole_mean)):\n",
    "            df[\"bin_center\"].append(idx)\n",
    "            df[\"value\"].append(whole_mean[idx])\n",
    "            df[\"property\"].append(suffix)\n",
    "            df[\"whole\"].append(sim_info.whole)\n",
    "            df[\"nhns\"].append(sim_info.nhns)\n",
    "            df[\"phi_c_bulk_round\"].append(round(sim_info.phi_c_bulk,3))\n",
    "            df[\"eps_hc\"].append(sim_info.eps_hc)\n",
    "        \n",
    "df = pd.DataFrame.from_dict(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.load(wholes[0][0])\n",
    "a.sum(axis=0)/ a.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = '/Users/amirhsi_mini/research_data/'\n",
    "#suffices = [\"bondsHistBridgeTHnsCore\", \"bondsHistDangleTHnsCore\", \n",
    "#            \"bondsHistTHnsCore\", \"clustersHistBridgeTHnsCore\",\"clustersHistDangleTHnsCore\",\"clustersHistTHnsCore\"]\n",
    "suffices = [\"bondsHistTHnsCore\", \"clustersHistTHnsCore\"]\n",
    "df = defaultdict(list)\n",
    "for suffix in suffices:\n",
    "    wholes = organizer.sort_filenames(glob(database+\"N*.npy\"),fmts=[suffix+'.npy']) \n",
    "    for whole in wholes:\n",
    "        sim_info = HnsCub(\n",
    "                whole[0],\n",
    "                'whole',\n",
    "                'cubic',\n",
    "                'nucleoid',\n",
    "                'ring'\n",
    "            )\n",
    "        whole_array = np.load(whole[0])\n",
    "        whole_mean = np.mean(whole_array,axis=0)\n",
    "        for idx in range(len(whole_mean)):\n",
    "            df[\"bin_center\"].append(idx)\n",
    "            df[\"value\"].append(whole_mean[idx])\n",
    "            df[\"property\"].append(suffix)\n",
    "            df[\"whole\"].append(sim_info.whole)\n",
    "            df[\"nhns\"].append(sim_info.nhns)\n",
    "            df[\"phi_c_bulk_round\"].append(round(sim_info.phi_c_bulk,3))\n",
    "            df[\"eps_hc\"].append(sim_info.eps_hc)\n",
    "        \n",
    "df = pd.DataFrame.from_dict(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[\"phi_c_bulk_round\"]==0.4)&(df[\"bin_center\"].isin([1,2,3,4,5]))].groupby([\"property\",\"bin_center\"])[\"value\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    style='ticks',\n",
    "    rc={'axes.grid': True}\n",
    ")\n",
    "grid = sns.relplot(\n",
    "    data=df,\n",
    "    x=\"bin_center\",\n",
    "    y=\"value\",\n",
    "    col=\"property\",\n",
    "    col_wrap=3,\n",
    "    hue=\"phi_c_bulk_round\",\n",
    "    legend=\"full\",\n",
    "    kind=\"line\",\n",
    "    marker=\"s\",\n",
    "    height=4,\n",
    "    aspect=1\n",
    ")\n",
    "grid.savefig(\"../../test_plots/cluster.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wholes[5][0])\n",
    "whole_array = np.load(wholes[0][0])\n",
    "whole_array.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "database = '/Users/amirhsi_mini/research_data/results/'\n",
    "#suffices = [\"bondsHistBridgeTHnsCore\", \"bondsHistDangleTHnsCore\", \n",
    "#            \"bondsHistTHnsCore\", \"clustersHistBridgeTHnsCore\",\"clustersHistDangleTHnsCore\",\"clustersHistTHnsCore\"]\n",
    "suffices = [\"bondsHistDirDepTHnsCore\", \"clustersHistDirDepTHnsCore\"]\n",
    "df = defaultdict(list)\n",
    "for suffix in suffices[:1]:\n",
    "    wholes = organizer.sort_filenames(glob(database+\"N*.npy\"),fmts=[suffix+'.npy']) \n",
    "    for whole in wholes:\n",
    "        sim_info = HnsCub(\n",
    "                whole[0],\n",
    "                'whole',\n",
    "                'cubic',\n",
    "                'nucleoid',\n",
    "                'ring'\n",
    "            )\n",
    "        whole_array = np.load(whole[0])\n",
    "        whole_mean = np.mean(whole_array,axis=0)\n",
    "        for idx in range(len(whole_mean)):\n",
    "            df[\"bin_center\"].append(idx)\n",
    "            df[\"value\"].append(whole_mean[idx])\n",
    "            df[\"property\"].append(suffix)\n",
    "            df[\"whole\"].append(sim_info.whole)\n",
    "            df[\"nhns\"].append(sim_info.nhns)\n",
    "            df[\"phi_c_bulk_round\"].append(round(sim_info.phi_c_bulk,3))\n",
    "            df[\"eps_hc\"].append(sim_info.eps_hc)\n",
    "        \n",
    "df = pd.DataFrame.from_dict(df)\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_values = df_clean.groupby(['property','nhns','phi_c_bulk_round','eps_hc'])['value'].transform('max')\n",
    "# Normalize 'value' by the maximum 'value' in each group\n",
    "#df_clean['normalized_value'] = df_clean['value'] / max_values\n",
    "\n",
    "\n",
    "#grouped = df.groupby(['property', 'nhns'])\n",
    "\n",
    "# Normalize 'value' by 'nhns' within each group\n",
    "df['normalized_nhns'] = df.groupby(['property','nhns','phi_c_bulk_round','eps_hc'])['value'].transform(lambda x: x / x.name[1])\n",
    "df['normalized_max'] = df.groupby(['property','nhns','phi_c_bulk_round','eps_hc'])['value'].transform(lambda x: x / x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(\n",
    "    style='ticks',\n",
    "    rc={'axes.grid': True}\n",
    ")\n",
    "grid = sns.relplot(\n",
    "    data=df,\n",
    "    x=\"bin_center\",\n",
    "    y=\"normalized_nhns\",\n",
    "    col=\"property\",\n",
    "    hue=\"phi_c_bulk_round\",\n",
    "    row=\"nhns\",\n",
    "    legend=\"full\",\n",
    "    kind=\"line\",\n",
    "    marker=\"s\",\n",
    "    height=4,\n",
    "    aspect=1.5\n",
    ")\n",
    "grid.tight_layout()\n",
    "grid.savefig(\"../../test_plots/cluster.pdf\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polylab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
