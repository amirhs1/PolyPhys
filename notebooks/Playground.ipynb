{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dce1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyphys.manage import parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e836ddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\\\n",
    "generate_test_data\n",
    "==================\n",
    "\n",
    "Utility functions for generating and preparing LAMMPS test data files.\n",
    "\n",
    "This module contains tools to transform large raw simulation data files\n",
    "(e.g., LAMMPS trajectory files) into smaller, compressed test data files\n",
    "used internally in the PolyPhys test suite. The original source data files\n",
    "are not part of the repository, but the functions here document and \n",
    "automate the generation process for transparency and reproducibility.\n",
    "\n",
    "Functions\n",
    "---------\n",
    "- read_n_atoms(trj_path)\n",
    "    Read number of atoms from line 4 of a LAMMPS trajectory file.\n",
    "\n",
    "- split_trj_gz(trj_path, n_frames, n_files, output_prefix)\n",
    "    Extract the last N frames from a LAMMPS trajectory file and write them\n",
    "    as compressed `.trj.gz` test files, optionally overlapping frames between\n",
    "    files.\n",
    "\n",
    "Notes\n",
    "-----\n",
    "This module is intended for development use only and should not be imported\n",
    "as part of the core PolyPhys package.\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def read_n_atoms(trj_path) -> int:\n",
    "    trj_path = Path(trj_path)\n",
    "    with trj_path.open() as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i == 3:\n",
    "                return int(line.strip())\n",
    "    raise ValueError(\"File too short to contain number of atoms at line 4.\")\n",
    "\n",
    "\n",
    "def split_trj(\n",
    "    trj_path,\n",
    "    sim_name: str,\n",
    "    group: str,\n",
    "    topology: str,\n",
    "    n_wholes: int = 1,\n",
    "    n_segments: int = 2,\n",
    "    frames_per_segment: int = 50,\n",
    ") -> None:\n",
    "    trj_path = Path(trj_path)\n",
    "    n_atoms = read_n_atoms(trj_path)\n",
    "    lines_per_frame = n_atoms + 9\n",
    "    n_files = n_wholes * n_segments\n",
    "    n_frames = n_files * frames_per_segment\n",
    "    n_frames = (n_files - 1) * (frames_per_segment - 1) + frames_per_segment\n",
    "    total_lines = n_frames * lines_per_frame\n",
    "\n",
    "    with trj_path.open() as f:\n",
    "        all_lines = [next(f) for _ in range(total_lines)]\n",
    "\n",
    "    frames = [\n",
    "        all_lines[i * lines_per_frame: (i + 1) * lines_per_frame]\n",
    "        for i in range(n_frames)\n",
    "    ]\n",
    "\n",
    "    for i in range(n_wholes):\n",
    "        for j in range(n_segments):\n",
    "            file_index = i * n_segments + j\n",
    "            start = file_index * (frames_per_segment - 1)\n",
    "            end = start + frames_per_segment\n",
    "            chunk = frames[start:end]\n",
    "            out_path = trj_path.parent / f\"{sim_name}.ens{i+1}.j{j+1}.{topology}.{group}.lammpstrj\"\n",
    "            with out_path.open(\"w\") as f:\n",
    "                for frame in chunk:\n",
    "                    f.writelines(frame)\n",
    "            print(f\"Wrote {len(chunk)} frames to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0074841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 51 frames to /Users/amirhsi/research_data/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.ring/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.j20.ring.ens1.j1.ring.all.lammpstrj\n",
      "Wrote 51 frames to /Users/amirhsi/research_data/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.ring/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.j20.ring.ens1.j2.ring.all.lammpstrj\n",
      "Wrote 51 frames to /Users/amirhsi/research_data/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.ring/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.j20.ring.ens1.j3.ring.all.lammpstrj\n",
      "Wrote 51 frames to /Users/amirhsi/research_data/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.ring/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.j20.ring.ens1.j4.ring.all.lammpstrj\n",
      "Wrote 51 frames to /Users/amirhsi/research_data/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.ring/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.j20.ring.ens1.j5.ring.all.lammpstrj\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "trj_path = '/Users/amirhsi/research_data/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.ring/epss5epsl5r10.5al6nl5ml216ns400ac1nc25650lz57dt0.005bdump2000adump5000ens2.j20.ring.all.lammpstrj'\n",
    "\n",
    "sim = parser.TransFociCyl(\n",
    "    trj_path,\n",
    "    'segment',\n",
    "    'all',\n",
    "    True\n",
    ")\n",
    "\n",
    "split_trj(\n",
    "    trj_path,\n",
    "    sim.name,\n",
    "    sim.group,\n",
    "    sim.topology,\n",
    "    1,\n",
    "    5,\n",
    "    51)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9955bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "polylab_air",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
