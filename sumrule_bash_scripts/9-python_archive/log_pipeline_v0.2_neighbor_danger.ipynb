{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I gonna test the *neighbor*, *neigh_modify*, and *processors* commands of *Lammps*. To this end, I choose the details of these commands in the following way:\n",
    "1. processors Px Py Pz:\n",
    "\n",
    "    1.1. Px, Py, and Pz are the # of processors in direction x, y, and z, respectively.\n",
    "    \n",
    "    1.2. For 2 and 4 cores, I use _processors 1 1 *_.\n",
    "    \n",
    "    1.3. For 8, 16, 32 cores, I use _processors 2 2 *_.\n",
    "2. neigbor rskin bin:\n",
    "\n",
    "    2.1 rskin is the extra distance beyond the rcutoff of the potential. I use WCA (purely repulsive Lennard-Jones potential) with $r_{cutoff}=2^{1/6}\\sigma$ where the size (diameter) of an LJ bead $\\sigma=a_m=1.0$ and $a_m$ is the monomers size size, so $r_{skin}=rskin*\\sigma$.\n",
    "    \n",
    "    2.2 In my test, $rskin=0.2,0.3,0.4,$ and $0.5$.\n",
    " \n",
    "3. neigh_modify delay every check page one:\n",
    "\n",
    "    3.1 *delay* can be 0 or a multiple of every. Here, $delay=0,1,2,4,10,20$.\n",
    "    \n",
    "    3.2 *every* is set to $1,2,$ or $4$.\n",
    "    \n",
    "    3.3 *page* is set to $3000$, or $100000$.\n",
    "    \n",
    "    3.4 check is always *yes*.\n",
    "    \n",
    "    3.5. *one* is set to $300$, or $2000$.\n",
    "\n",
    "4. I also test *recenter* off and on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_CLXSgvVO_9"
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "%matplotlib inline\n",
    "# Importing necessary packages:\n",
    "import sys\n",
    "import os\n",
    "#import scipy.integrate as integrate\n",
    "#import scipy.special as special\n",
    "#from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import math\n",
    "import re\n",
    "from glob import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "print(path)\n",
    "try:\n",
    "    os.mkdir('results')\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob('../log_D26_no_backup/*.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if rskin needed\n",
    "neighfile=open(\"neighbor_testing_D26.txt\", \"w\")\n",
    "# neigh_modify delay NUM every NUM check YES/NO page NUM one NUM:\n",
    "neighfile.write('filename,shortname,recenter,rskin,delay,every,check,page,one,temp_last_ts,total_eng_last_ts,press_last_ts,total_time(s),cores,timestep,atoms,ts_per_sec,')\n",
    "# Section columns: min time, avg time, max time, %varavg, %total\"\n",
    "# Section rows: Pair, Bond, Neigh, Comm, Output, Modify, Other\n",
    "neighfile.write('pair_avg(s),pair_pct,bond_avg(s),bond_pct,neigh_avg(s),neigh_pct,comm_avg(s),comm_pct,output_avg(s),output_pct,modify_avg(s),modify_pct,other_avg(s),other_pct,dangerous\\n')\n",
    "neighfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rskin\n",
    "for file in files:\n",
    "    if len(file.split('rskin')) == 1:\n",
    "        words=file.split('cpu')\n",
    "        filename = words[0]+'rskin0.2cpu'+words[-1]\n",
    "        filename = filename.split('.log')\n",
    "        filename = filename[0]\n",
    "        filename = filename.split('/')[-1]\n",
    "        shortname = filename.split('page')[0]+'rskin'+filename.split('rskin')[-1]\n",
    "        rskin = filename.split('rskin')[-1].split('cpu')[0]\n",
    "        recenter = filename.split('_')[-1]\n",
    "    else:\n",
    "        filename = file.split('.log')\n",
    "        filename = filename[0]\n",
    "        filename = filename.split('/')[-1]\n",
    "        shortname = filename.split('page')[0]+'rskin'+filename.split('rskin')[-1]\n",
    "        rskin = filename.split('rskin')[-1].split('cpu')[0]\n",
    "        recenter = filename.split('_')[-1]\n",
    "    #with open(\"neighbor_testing.txt\", \"a\") as neigh_write:\n",
    "    #print(filename)\n",
    "    with open(file,'r') as log,\\\n",
    "    open(\"neighbor_testing.txt\", \"a\") as neighfile:\n",
    "    \n",
    "        neighfile.write(filename)\n",
    "        neighfile.write(\",\")\n",
    "        neighfile.write(shortname)\n",
    "        neighfile.write(\",\")\n",
    "        neighfile.write(recenter)\n",
    "        neighfile.write(\",\")\n",
    "        neighfile.write(rskin)\n",
    "        neighfile.write(\",\")\n",
    "        \n",
    "        line = log.readline()\n",
    "        \n",
    "        # The other of while loop are important\n",
    "        #neigh_modify delay NUM every NUM check YES/NO page NUM one NUM:\n",
    "        while not(line.startswith('neigh_modify')):\n",
    "            line = log.readline()\n",
    "            \n",
    "        words = line.split()\n",
    "        # picking the NUMs and Yes/No from neigh_modify command:\n",
    "        for i in range(int(len(words)/2)): \n",
    "            neighfile.write(words[2*i+2])\n",
    "            neighfile.write(\",\")\n",
    "            \n",
    "        if 'rskin' in file:    \n",
    "            while not(line.startswith(\"  100000\")):\n",
    "                line = log.readline()\n",
    "            words = line.split() # tep Temp E_pair E_mol TotEng Press\n",
    "            neighfile.write(words[1])#temp_last_ts\n",
    "            neighfile.write(\",\")\n",
    "            neighfile.write(words[4])# total_energy_last_ts\n",
    "            neighfile.write(\",\")\n",
    "            neighfile.write(words[5])# press_last_ts\n",
    "            neighfile.write(\",\")\n",
    "            \n",
    "        else:\n",
    "            while not(line.startswith(\"   10000\")):\n",
    "                line = log.readline()\n",
    "            words = line.split() # tep Temp E_pair E_mol TotEng Press\n",
    "            neighfile.write(words[1])#temp_last_ts\n",
    "            neighfile.write(\",\")\n",
    "            neighfile.write(words[4])# total_energy_last_ts\n",
    "            neighfile.write(\",\")\n",
    "            neighfile.write(words[5])# press_last_ts\n",
    "            neighfile.write(\",\")\n",
    "            \n",
    "\n",
    "        while not(line.startswith('Loop time')):\n",
    "            line = log.readline()\n",
    "            \n",
    "        words = line.split()\n",
    "        neighfile.write(words[3])#total time\n",
    "        neighfile.write(\",\")\n",
    "        neighfile.write(words[5])# # of cores\n",
    "        neighfile.write(\",\")\n",
    "        neighfile.write(words[8])# total timesteps\n",
    "        neighfile.write(\",\")\n",
    "        neighfile.write(words[11])# total atoms\n",
    "        neighfile.write(\",\")\n",
    "        \n",
    "        while not(line.startswith('Performance:')):\n",
    "            line = log.readline()\n",
    "            \n",
    "        words = line.split()\n",
    "        neighfile.write(words[3])# timesteps per second\n",
    "        neighfile.write(\",\")\n",
    "       \n",
    "\n",
    "        while not(line.startswith('Section')):\n",
    "            line = log.readline()\n",
    "        _ = log.readline()\n",
    "        for i in range(6): # Section rows: Pair, Bond, Neigh, Comm, Output, Modify, Other\n",
    "            # Section columns: min time, avg time, max time, %varavg, %total\"\n",
    "            line = log.readline()\n",
    "            sect_min = line.split('|')[2].strip()\n",
    "            neighfile.write(sect_min)\n",
    "            neighfile.write(\",\")\n",
    "            \n",
    "            sect_pct = line.split()[-1] # Pair pct of total time\n",
    "            neighfile.write(sect_pct)\n",
    "            neighfile.write(\",\")\n",
    "        \n",
    "        line = log.readline()\n",
    "        sect_min = line.split('|')[2].strip()\n",
    "        neighfile.write(sect_min)\n",
    "        neighfile.write(\",\")\n",
    "        sect_pct = line.split()[-1] # Pair pct of total time\n",
    "        neighfile.write(sect_pct)\n",
    "        \n",
    "        while not(line.startswith('Dangerous')):\n",
    "            line = log.readline()\n",
    "        words = line.split()\n",
    "        neighfile.write(words[-1]) # # number of dangerous builds\n",
    "        neighfile.write(\"\\n\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dangerous build needed \n",
    "neighfile=open(\"neighbor_testing_D26.txt\", \"w\")\n",
    "# neigh_modify delay NUM every NUM check YES/NO page NUM one NUM:\n",
    "neighfile.write('filename,ens,run_seg,total_time_s,cores,timestep,atoms,ts_per_sec,')\n",
    "# Section columns: min time, avg time, max time, %varavg, %total\"\n",
    "# Section rows: Pair, Bond, Neigh, Comm, Output, Modify, Other\n",
    "neighfile.write('pair_avg_s,pair_pct,bond_avg_s,bond_pct,neigh_avg_s,neigh_pct,comm_avg_s,comm_pct,output_avg_s,output_pct,modify_avg_s,modify_pct,other_avg_s,other_pct,dangerous\\n')\n",
    "neighfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dangerous lists\n",
    "for file in files:\n",
    "    filename = file.split('.log')\n",
    "    filename = filename[0]\n",
    "    filename = filename.split('/')[-1]\n",
    "    ens = filename.split('ens')[-1]\n",
    "    with open(file,'r') as log,\\\n",
    "    open(\"neighbor_testing_D26.txt\", \"a\") as neighfile:    \n",
    "        line = log.readline()\n",
    "        \n",
    "        # The other of while loop are important\n",
    "        #neigh_modify delay NUM every NUM check YES/NO page NUM one NUM: \n",
    "        j = 1\n",
    "        while line: \n",
    "            if line.startswith('Loop time'):\n",
    "                neighfile.write(filename)\n",
    "                neighfile.write(\",\")\n",
    "                neighfile.write(ens)\n",
    "                neighfile.write(\",\")\n",
    "                neighfile.write(str(j))#total time\n",
    "                neighfile.write(\",\")\n",
    "                j += 1\n",
    "                words = line.split()\n",
    "                neighfile.write(words[3])#total time\n",
    "                neighfile.write(\",\")\n",
    "                neighfile.write(words[5])# # of cores\n",
    "                neighfile.write(\",\")\n",
    "                neighfile.write(words[8])# total timesteps\n",
    "                neighfile.write(\",\")\n",
    "                neighfile.write(words[11])# total atoms\n",
    "                neighfile.write(\",\")\n",
    "\n",
    "            if line.startswith('Performance:'):\n",
    "                words = line.split()\n",
    "                neighfile.write(words[3])# timesteps per second\n",
    "                neighfile.write(\",\")\n",
    "\n",
    "            if line.startswith('Section'):\n",
    "                _ = log.readline()\n",
    "                for i in range(6): # Section rows: Pair, Bond, Neigh, Comm, Output, Modify, Other\n",
    "                    # Section columns: min time, avg time, max time, %varavg, %total\"\n",
    "                    line = log.readline()\n",
    "                    sect_min = line.split('|')[2].strip()\n",
    "                    neighfile.write(sect_min)\n",
    "                    neighfile.write(\",\")\n",
    "\n",
    "                    sect_pct = line.split()[-1] # Pair pct of total time\n",
    "                    neighfile.write(sect_pct)\n",
    "                    neighfile.write(\",\")\n",
    "\n",
    "                line = log.readline()\n",
    "                sect_min = line.split('|')[2].strip()\n",
    "                neighfile.write(sect_min)\n",
    "                neighfile.write(\",\")\n",
    "                sect_pct = line.split()[-1] # Pair pct of total time\n",
    "                neighfile.write(sect_pct)\n",
    "                neighfile.write(\",\")\n",
    "\n",
    "            if line.startswith('Dangerous'):\n",
    "                words = line.split()\n",
    "                neighfile.write(str(int(words[-1]))) # # number of dangerous builds\n",
    "                neighfile.write(\"\\n\") \n",
    "            line = log.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_data = pd.read_csv(\"neighbor_testing_D26.txt\")\n",
    "neigh_data['sum_pct']=neigh_data['neigh_pct']+neigh_data['comm_pct']\n",
    "neigh_data['sum_ave_s']=neigh_data['neigh_avg_s']+neigh_data['comm_avg_s']\n",
    "neigh_data['est_ttotal_s']=5e7/neigh_data['ts_per_sec']\n",
    "neigh_data['est_ttotal_h'] = neigh_data['est_ttotal_s'] / 3600\n",
    "cols_sort = ['cores','sum_pct','neigh_pct','comm_pct','ts_per_sec','atoms']\n",
    "cols_ascending = [True,True,True,True,False,False]\n",
    "neigh_data.sort_values(cols_sort,inplace=True,ascending=cols_ascending)\n",
    "neigh_data.reset_index(inplace=True,drop=True)\n",
    "cols = ['cores','sum_pct','neigh_pct','comm_pct','ts_per_sec','total_time_s','sum_ave_s','est_ttotal_s','dangerous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_data.loc[(neigh_data.atoms==42407) &  (neigh_data.ens==2)]['total_time_s'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh_data.loc[neigh_data.atoms==42407].groupby('ens')['total_time_s'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_atoms = neigh_data.atoms.drop_duplicates().values\n",
    "runtime_dict = {'natoms':[],'ncores':[],'nens':[],'runtime_count_sampling':[],'runtime_avg_sampling_h':[],'runtime_count':[],'runtime_avg_h':[]}\n",
    "for atoms in unique_atoms:\n",
    "    data = neigh_data.loc[(neigh_data.atoms == atoms) & (neigh_data.run_seg > 1)]\n",
    "    natoms = atoms\n",
    "    ncores = data.cores.drop_duplicates().values[0]\n",
    "    nens = 8\n",
    "    runtime_count = data.groupby('ens')['total_time_s'].count().sum() # shoud be 8*10=80\n",
    "    runtime_avg_h = data.groupby('ens')['total_time_s'].sum().mean()/3600\n",
    "    runtime_dict['natoms'].append(natoms)\n",
    "    runtime_dict['ncores'].append(ncores)\n",
    "    runtime_dict['nens'].append(nens)\n",
    "    runtime_dict['runtime_count_sampling'].append(runtime_count)\n",
    "    runtime_dict['runtime_avg_sampling_h'].append(runtime_avg_h)\n",
    "    \n",
    "    data = neigh_data.loc[(neigh_data.atoms == atoms)]\n",
    "    natoms = atoms\n",
    "    ncores = data.cores.drop_duplicates().values[0]\n",
    "    nens = 8\n",
    "    runtime_count = data.groupby('ens')['total_time_s'].count().sum() # shoud be 8*11=88\n",
    "    runtime_avg_h = data.groupby('ens')['total_time_s'].sum().mean()/3600\n",
    "    runtime_dict['runtime_count'].append(runtime_count)\n",
    "    runtime_dict['runtime_avg_h'].append(runtime_avg_h)\n",
    "runtime_df = pd.DataFrame.from_dict(runtime_dict)\n",
    "runtime_df['runtime_avg_equilibration_h'] = runtime_df['runtime_avg_h'] - runtime_df['runtime_avg_sampling_h']\n",
    "jnum = int(7e7/5e6) # total n# of timestep / # of timestep in one loop\n",
    "print(jnum)\n",
    "runtime_df['runtime_avg_sampling_10times_h'] = runtime_df['runtime_avg_sampling_h']*jnum/(runtime_df['runtime_count_sampling']/8)\n",
    "runtime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df.groupby('ncores')['runtime_avg_sampling_10times_h'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition2 = (neigh_data.run_seg == 11)\n",
    "condition2 = \n",
    "default_cpu2 = neigh_data.loc[(neigh_data.cores == 2)]\n",
    "default_cpu4 = neigh_data.loc[(neigh_data.cores == 4)]\n",
    "default_cpu8 = neigh_data.loc[(neigh_data.cores == 8)]\n",
    "#default_cpu16 = default_page.loc[default_page.cores == 16]\n",
    "#default_cpu32 = default_page.loc[default_page.cores == 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cpu2.ts_per_sec.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = default_cpu2\n",
    "facet_grid = sns.relplot(x=\"run_seg\", y=\"ts_per_sec\", hue='atoms',col=\"ens\",col_wrap=4, data=data)\n",
    "facet_grid.tight_layout()\n",
    "facet_grid.savefig(\"facet_plot.pdf\")\n",
    "#g = sns.FacetGrid(attend, col=\"subject\", col_wrap=4, height=2, ylim=(0, 10))\n",
    "#g.map(sns.pointplot, \"solutions\", \"score\", order=[1, 2, 3], color=\".3\", ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['cores','total_time_s','sum_pct','neigh_pct','comm_pct','ts_per_sec','atoms','dangerous','est_ttotal_s','est_ttotal_h']\n",
    "cols_sort =  ['ts_per_sec','sum_pct','neigh_pct','comm_pct','sum_ave_s']\n",
    "cols_ascending = [False,True,True,True,False]\n",
    "default_cpu2.reset_index(inplace=True,drop=True)\n",
    "default_cpu2.sort_values(cols_sort,ascending=cols_ascending)[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column with the highest timestep_per_second on a 2 core machine\n",
    "default_cpu2.iloc[default_cpu2.ts_per_sec.idxmax()]\n",
    "# The difference in neigh_pct of this column with the column with lowest neigh_pct is less than 5% \n",
    "# however its comm_pct is half of that with the lowest neigh_pct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above analyze is for a system with 100080 atoms run for 100000 timesteps with timestep/sec=47.309\n",
    "# what about a system with 10000 atoms that run for 7*10^7 timesteps?\n",
    "# To answer this question we assume all the algorithm are of order O(N) where N is the number of atoms.\n",
    "data = default_cpu2\n",
    "col = 'ts_per_sec'\n",
    "idx = data[col].idxmax()\n",
    "idx = 7\n",
    "col = 'ts_per_sec'\n",
    "tp_per_sec_mean = default_cpu2[col].min()\n",
    "print(tp_per_sec_mean)\n",
    "test_natoms = data.loc[idx,'atoms']\n",
    "test_nsteps = data.loc[idx,'timestep']\n",
    "test_ttotal = data.loc[idx,'total_time_s']\n",
    "test_cores = data.loc[idx,'cores']\n",
    "#print(test_nsteps/test_ttotal)\n",
    "natoms = 2e3\n",
    "nsteps = 5e7\n",
    "ttotal = (nsteps/tp_per_sec_mean) # seconds\n",
    "ttotal_hr = ttotal/3600 # hours \n",
    "print(\"The estimated simulation time for a system with {} atoms in {} timesteps on {}-core machine is {} seconds or {} hours.\".format(natoms,nsteps,test_cores,ttotal,ttotal_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cpu4.reset_index(inplace=True,drop=True)\n",
    "default_cpu4.sort_values(cols_sort,ascending=cols_ascending)[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cpu2.est_ttotal_h.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column with the highest timestep_per_second on a 4-core machine\n",
    "default_cpu4.iloc[default_cpu4.ts_per_sec.idxmax()]\n",
    "# The difference in neigh_pct of this column with the column with lowest neigh_pct is less than 5% \n",
    "# however its comm_pct is half of that with the lowest neigh_pct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cpu4.iloc[default_cpu4[col].idxmin()]['atoms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above analyze is for a system with 100080 atoms run for 100000 timesteps with timestep/sec=47.309\n",
    "# what about a system with 10000 atoms that run for 7*10^7 timesteps?\n",
    "# To answer this question we assume all the algorithm are of order O(N) where N is the number of atoms.\n",
    "data = default_cpu4\n",
    "col = 'ts_per_sec'\n",
    "idx = data[col].idxmax()\n",
    "#idx = 7\n",
    "col = 'ts_per_sec'\n",
    "tp_per_sec_mean = default_cpu4[col].min()\n",
    "test_atoms = default_cpu4.iloc[default_cpu4[col].idxmin()]['atom']\n",
    "print(tp_per_sec_mean)\n",
    "print(test_atoms)\n",
    "test_natoms = data.loc[idx,'atoms']\n",
    "test_nsteps = data.loc[idx,'timestep']\n",
    "test_ttotal = data.loc[idx,'total_time_s']\n",
    "test_cores = data.loc[idx,'cores']\n",
    "#print(test_nsteps/test_ttotal)\n",
    "natoms = 45000\n",
    "nsteps = 5e7\n",
    "ttotal = (45000/)(nsteps/tp_per_sec_mean) # seconds\n",
    "ttotal_hr = ttotal/3600 # hours \n",
    "print(\"The estimated simulation time for a system with {} atoms in {} timesteps on {}-core machine is {} seconds or {} hours.\".format(natoms,nsteps,test_cores,ttotal,ttotal_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cpu8.reset_index(inplace=True,drop=True)\n",
    "default_cpu8.sort_values(cols_sort,ascending=cols_ascending)[cols][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The column with the highest timestep_per_second on a 2 core machine\n",
    "default_cpu8.iloc[default_cpu8.ts_per_sec.idxmax()]\n",
    "# The difference in neigh_pct of this column with the column with lowest neigh_pct is less than 5% \n",
    "# however its comm_pct is half of that with the lowest neigh_pct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above analyze is for a system with 100080 atoms run for 100000 timesteps with timestep/sec=47.309\n",
    "# what about a system with 10000 atoms that run for 7*10^7 timesteps?\n",
    "# To answer this question we assume all the algorithm are of order O(N) where N is the number of atoms.\n",
    "data = default_cpu8\n",
    "col = 'ts_per_sec'\n",
    "idx = data[col].idxmax()\n",
    "#idx = 7\n",
    "col = 'ts_per_sec'\n",
    "tp_per_sec_mean = default_cpu8[col].min()\n",
    "print(tp_per_sec_mean)\n",
    "test_natoms = data.loc[idx,'atoms']\n",
    "test_nsteps = data.loc[idx,'timestep']\n",
    "test_ttotal = data.loc[idx,'total_time_s']\n",
    "test_cores = data.loc[idx,'cores']\n",
    "#print(test_nsteps/test_ttotal)\n",
    "natoms = 45000\n",
    "nsteps = 5e7\n",
    "ttotal = (nsteps/tp_per_sec_mean) # seconds\n",
    "ttotal_hr = ttotal/3600 # hours \n",
    "print(\"The estimated simulation time for a system with {} atoms in {} timesteps on {}-core machine is {} seconds or {} hours.\".format(natoms,nsteps,test_cores,ttotal,ttotal_hr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cpu16.reset_index(inplace=True,drop=True)\n",
    "default_cpu16.sort_values(cols_sort,ascending=cols_ascending)[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1='neigh_avg(s)'\n",
    "col2='comm_avg(s)'\n",
    "col3='sum_ave(s)'\n",
    "col4='ts_per_sec'\n",
    "default_cpu2_bar = default_cpu2[['shortname',col1,col2,col3,col4]]\n",
    "default_cpu4_bar = default_cpu4[['shortname',col1,col2,col3,col4]]\n",
    "default_cpu8_bar = default_cpu8[['shortname',col1,col2,col3,col4]]\n",
    "default_cpu16_bar = default_cpu16[['shortname',col1,col2,col3,col4]]\n",
    "default_cpu32_bar = default_cpu32[['shortname',col1,col2,col3,col4]]\n",
    "default_page_bar = default_page[['shortname',col1,col2,col3,col4]]\n",
    "default_cpu2_bar.sort_values([col3,col2,col1],inplace=True,ascending=False)\n",
    "default_cpu4_bar.sort_values([col3,col2,col1],inplace=True,ascending=False)\n",
    "default_cpu8_bar.sort_values([col3,col2,col1],inplace=True,ascending=False)\n",
    "default_cpu16_bar.sort_values([col3,col2,col1],inplace=True,ascending=False)\n",
    "default_cpu32_bar.sort_values([col3,col2,col1],inplace=True,ascending=False)\n",
    "default_page_bar.sort_values([col3,col2,col1],inplace=True,ascending=False)\n",
    "\n",
    "default_cpu2_bar = default_cpu2_bar[['shortname',col1,col2]]\n",
    "default_cpu4_bar = default_cpu4_bar[['shortname',col1,col2]]\n",
    "default_cpu8_bar = default_cpu8_bar[['shortname',col1,col2]]\n",
    "default_cpu16_bar = default_cpu16_bar[['shortname',col1,col2]]\n",
    "default_cpu32_bar = default_cpu32_bar[['shortname',col1,col2]]\n",
    "default_page_bar = default_page_bar[['shortname',col1,col2]]\n",
    "\n",
    "default_cpu2_bar.set_index('shortname',drop=True,inplace=True)\n",
    "default_cpu4_bar.set_index('shortname',drop=True,inplace=True)\n",
    "default_cpu8_bar.set_index('shortname',drop=True,inplace=True)\n",
    "default_cpu16_bar.set_index('shortname',drop=True,inplace=True)\n",
    "default_cpu32_bar.set_index('shortname',drop=True,inplace=True)\n",
    "default_page_bar.set_index('shortname',drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cpu2[['filename','ts_per_sec']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16,9))\n",
    "ax = default_cpu2_bar.plot.barh(stacked=True,figsize=(20, 30))\n",
    "ax.text(1700,30,\"For rskin=0.2, # of timesteps = 10000\")\n",
    "name = 'avg_min'\n",
    "ax.set_xlabel('Time (sec)')\n",
    "plt.savefig('neighbor_cpu2_'+name+'.pdf',dpi=300,format='pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "pipeline_v4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
