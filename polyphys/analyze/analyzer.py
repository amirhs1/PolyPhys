from typing import (
    Callable,
    List,
    Tuple,
    Optional,
)
from glob import glob
from polyphys.manage.organizer import (
    invalid_keyword,
    sort_filenames,
    database_path,
    whole,
    ensemble,
    ensemble_avg,
    children_stamps,
    parents_stamps
)

from polyphys.analyze.distributions import distributions_generator
from polyphys.analyze.correlations import acf_generator
import numpy as np
import pandas as pd


def time_series(
    observations: List[str],
    save_to: Tuple[str, str, str],
    tseries_properties: List[Tuple[str, str, str]] = None,
    acf_tseries_properties: List[Tuple[str, str, str]] = None,
    geometry: str = 'biaxial',
    nlags: int = 7000,
    alpha: float = 0.05
) -> None:
    """
    runs overs all 'segment' `observations` resulted from 'probing' a
    `group` in a given `geometry`, merges time series vertically to
    create 'whole' files, do different analyses on time series
    including auto correlation function (AFC) analysis, and finally
    writes the ensembles and ensembles averages of time series and its
    associated analyses to file.

    Issue
    -----
    If the order of the acf_generator and the first ensemble_avg is
    change, the column names in each ensemble dataframe in 'ensembles'
    changes.

    Parameters
    ----------
    observations: list of str
        List of path to different observations generated by 'probed'
        trajectory files.
    save_to : tuple of three str
        Absolute or relative path of the directories to which wholes,
        ensembles, and ensemble-aveages are saved.
    tseries_properties: list of tuple of str
        A list of tumple where each tumple has three members: the property
        name, species, and group of a 'time-series' property.
    acf_tseries_properties: list of tuple of str
        A list of tumple where each tumple has three members: the property
        name, species, and group of a 'time-series' property. For
        `cls_tseries_properties`, the the auto correlation function (AFC) is
        also computed.
    geometry : {'biaxial', 'slit', 'box'}, default 'biaxial'
        Shape of the simulation box.
    nlags: int, default 7000
        Maximum lag in the auto correlation function (AFC).
    alpha: float, default 0.05
        If a number is given, the confidence intervals for the given level
        are returned. For instance if alpha=.05, 95 % confidence intervals
        are returned where the standard deviation is computed according to
        Bartlett”s formula.
    """
    invalid_keyword(geometry, ['biaxial', 'slit', 'box'])
    save_to_whole, save_to_ens, save_to_ens_avg = save_to
    if tseries_properties is not None:
        for property_, species, group in tseries_properties:
            segments = sort_filenames(
                observations,
                fmts=['-' + property_ + species + '.npy']
            )
            # 'whole' dataframes, each with a 'whole' as its column:
            wholes = whole(
                property_ + species,
                segments,
                parser,
                geometry=geometry,
                group=group,
                relation='tseries',
                save_to=save_to_whole
            )
            ensembles = ensemble(
                    property_ + species,
                    wholes,
                    parser,
                    geometry=geometry,
                    group=group,
                    save_to=save_to_ens
            )
            _ = ensemble_avg(
                    property_ + species,
                    ensembles,
                    parser,
                    geometry='biaxial',
                    group=group,
                    save_to=save_to_ens_avg
            )
        del wholes, ensembles
    if acf_tseries_properties is not None:
        for property_, species, group in acf_tseries_properties:
            segments = sort_filenames(
                observations,
                fmts=['-' + property_ + species + '.npy']
            )
            # 'whole' dataframes, each with a 'whole' as its column:
            wholes = whole(
                property_ + species,
                segments,
                parser,
                geometry=geometry,
                group=group,
                relation='tseries',
                save_to=save_to_whole
            )
            ensembles = ensemble(
                    property_ + species,
                    wholes,
                    parser,
                    geometry=geometry,
                    group=group,
                    save_to=save_to_ens
                )
            acfs, lower_cls, upper_cls = acf_generator(
                property_ + species,
                ensembles,
                nlags,
                alpha,
                parser,
                group=group,
                save_to=save_to_ens
            )
            _ = ensemble_avg(
                    property_ + species,
                    ensembles,
                    parser,
                    geometry='biaxial',
                    group=group,
                    save_to=save_to_ens_avg
                )
            _ = ensemble_avg(
                    property_ + species + '-acf',
                    acfs,
                    parser,
                    geometry='biaxial',
                    group=group,
                    save_to=save_to_ens_avg
                )
            _ = ensemble_avg(
                    property_ + species + '-acfLowerCi',
                    lower_cls,
                    parser,
                    geometry='biaxial',
                    group=group,
                    save_to=save_to_ens_avg
                )
            _ = ensemble_avg(
                    property_ + species + '-acfUpperCi',
                    upper_cls,
                    parser,
                    geometry='biaxial',
                    group=group,
                    save_to=save_to_ens_avg
                )


def histograms(
    observations: List[str],
    save_to: Tuple[str, str, str],
    geometry: str = 'biaxial',
    hist_properties: Optional[List[Tuple[str, str, str]]] = None,
    rho_phi_hist_properties: Optional[List[Tuple[str, str, str]]] = None
) -> None:
    """run overs all 'segment' `observations` resulted from 'probing' a
    `group` in a given `geometry`, adds histograms horizontally to
    create 'whole' files, do different analyses on histograms including
    local number density and volume fraction analysis, and finally
    writes the ensembles and ensembles averages of histograms and thier
    associated analyses to file.

    Parameters
    ----------
    observations: list of str
        List of path to different observations generated by 'probed'
        trajectory files.
    save_to : tuple of three str
        Absolute or relative path of the directories to which wholes,
        ensembles, and ensemble-aveages are saved.
    geometry : {'biaxial', 'slit', 'box'}, default biaxial
        Shape of the simulation box.
    rho_phi_hist_properties: list of tuple of str, default None
        A list of tumple where each tumple has four members: the direction,
        direction long name, species, and group of a 'histogram' property.
        These histogram properties are then used to calculate the local
        number density and volume fraction.
    hist_properties: list of tuple of str, default None
        A list of tumple where each tumple has three members: the direction,
        species, and group of a 'histogram' property.
    """
    invalid_keyword(geometry, ['biaxial', 'slit', 'box'])
    save_to_whole, save_to_ens, save_to_ens_avg = save_to
    # Histograms:
    # Two types of histograms with and without rhos and phis:
    # rho: local number density
    # phi: locla volume fraction
    if rho_phi_hist_properties is not None:
        for direction, species, group in rho_phi_hist_properties:
            segments = sort_filenames(
                observations,
                fmts=['-' + direction + 'Hist' + species + '.npy']
            )
            edge_segments = sort_filenames(
                observations,
                fmts=['-' + direction + 'Edge' + species + '.npy']
            )
            # 'whole' dataframes, each with 'segments' as columns:
            wholes = whole(
                direction + 'Hist' + species,
                segments,
                parser,
                geometry=geometry,
                group=group,
                relation='histogram',
                save_to=save_to_whole
            )
            edge_wholes = whole(
                direction + 'Edge' + species,
                edge_segments,
                parser,
                geometry=geometry,
                group=group,
                relation='bin_edge',
                save_to=save_to_whole
            )
            # 'whole' dataframes, each with a 'whole' columns.
            rho_wholes, phi_wholes = distributions_generator(
                wholes,
                edge_wholes,
                group,
                species,
                geometry,
                direction,
                parser,
                save_to=save_to_whole
            )
            ensembles = ensemble(
                direction + 'Hist' + species,
                wholes,
                parser,
                geometry=geometry,
                group=group,
                edge_wholes=edge_wholes,
                save_to=save_to_ens
            )
            _ = ensemble_avg(
                direction + 'Hist' + species,
                ensembles,
                parser,
                geometry='biaxial',
                group=group,
                save_to=save_to_ens_avg
            )
            ensembles = ensemble(
                direction + 'Rho' + species,
                rho_wholes,
                parser,
                geometry=geometry,
                group=group,
                edge_wholes=edge_wholes,
                save_to=None
            )
            _ = ensemble_avg(
                direction + 'Rho' + species,
                ensembles,
                parser,
                geometry='biaxial',
                group=group,
                save_to=save_to_ens_avg
            )
            ensembles = ensemble(
                direction + 'Phi' + species,
                phi_wholes,
                parser,
                geometry=geometry,
                group=group,
                edge_wholes=edge_wholes,
                save_to=save_to_ens
            )
            _ = ensemble_avg(
                direction + 'Phi' + species,
                ensembles,
                parser,
                geometry='biaxial',
                group=group,
                save_to=save_to_ens_avg
            )
        del rho_wholes, phi_wholes, ensembles
    if hist_properties is not None:
        for species, direction, group in hist_properties:
            segments = sort_filenames(
                observations,
                fmts=['-' + direction + 'Hist' + species + '.npy']
            )
            edge_segments = sort_filenames(
                observations,
                fmts=['-' + direction + 'Edge' + species + '.npy']
            )
            # 'whole' dataframes, each with 'segments' as columns:
            wholes = whole(
                direction + 'Hist' + species,
                segments,
                parser,
                geometry=geometry,
                group=group,
                relation='histogram',
                save_to=save_to_whole
            )
            edge_wholes = whole(
                direction + 'Edge' + species,
                segments,
                parser,
                geometry=geometry,
                group=group,
                relation='bin_edge',
                save_to=save_to_whole
            )
            ensembles = ensemble(
                direction + 'Hist' + species,
                wholes,
                parser,
                geometry=geometry,
                group=group,
                edge_wholes=edge_wholes,
                save_to=save_to_ens
            )
            _ = ensemble_avg(
                direction + 'Hist' + species,
                ensembles,
                parser,
                geometry='biaxial',
                group=group,
                save_to=save_to_ens_avg
            )


def non_scalar_segments(
    observations: List[str],
    non_scalar_properties: List[Tuple[str, str, str]],
    save_to: Tuple[str, str, str],
    geometry: str = 'biaxial'
) -> None:
    """run overs all 'segment' `observations` resulted from 'probing' a
    `group` in a given 'geometry', and sequencially merge
    `non_scalar_properties`  to create 'whole' files.

    Parameters
    ----------
    observations: list of str
        List of path to different observations generated by 'probed'
        trajectory files.
    non_scalar_properties: list of tuple
        A list of tuples in which each tuple has three string members. The
        first string is the name of a physical property, the second one is
        the particletype, and the last one is `group` type. These physical
        properties are all of non_scalar form.
    save_to : tuple of three str
        Absolute or relative path of the directories to which wholes,
        ensembles, and ensemble-aveages are saved.
    geometry : {'biaxial', 'slit', 'box'}, default 'biaxial'
        Shape of the simulation box.
    """
    invalid_keyword(geometry, ['biaxial', 'slit', 'box'])
    for property_, species, group in non_scalar_properties:
        segments = sort_filenames(
            observations,
            fmts=['-' + property_ + species + '.npy']
        )
        # 'whole' dataframes, each with a 'whole' as its column:
        _ = whole(
            property_ + species,
            parser,
            segments,
            geometry=geometry,
            group=group,
            relation='tseries',
            save_to=save_to
        )


def analyze_segments(
    input_database: str,
    geometry: str = 'biaxial',
    hierarchy: str = "/N*/N*"
) -> None:
    """read in the 'probe' observations of the 'group' particles based on the
    `hierarchy` of directories and files from the `input_database` path to the
    'probe' phase of a 'space' and creates the 'analysis' phase at that parent
    directory of the 'probe' of that 'space', infers 'space' names from
    `input_database` path and creates a 'space' directories at various stages
    in the 'analysis' directory for both 'bug' and 'all' groups.

    Parameters
    ----------
    input_database: str
        Path to the input_database; a 'space' directory at a given 'phase'.
    geometry : {'biaxial', 'slit', 'box'}, default 'biaxial'
        Shape of the simulation box.
    hierarchy: str
        Hierarchy of the directories and files within the `input_database`.
    """
    # if not pathlib.Path(input_database).exists():
    #    raise ValueError(
    #        f"'{input_database}'"
    #        "path does not exist."
    #        )
    invalid_keyword(geometry, ['biaxial', 'slit', 'box'])
    observations = glob(input_database + hierarchy)
    if observations == []:
        raise ValueError(
            "File not found in "
            f"'{input_database + hierarchy}'"
            )
    # 'bug' save_to paths:
    save_to_whole = database_path(
        input_database, 'analysis', stage='wholeSim', group='bug'
    )
    save_to_ens = database_path(
        input_database, 'analysis', stage='ens', group='bug'
    )
    save_to_ens_avg = database_path(
        input_database, 'analysis', stage='ensAvg', group='bug'
    )
    # stamps:
    stamp_files = sort_filenames(observations, fmts=['-stamps.csv'])
    segments_stamps = children_stamps(
        stamp_files,
        lineage='segment',
        save_to=save_to_whole
    )
    whole_stamps = parents_stamps(
        segments_stamps,
        geometry=geometry,
        lineage='segment',
        save_to=save_to_ens
    )
    _ = parents_stamps(
        whole_stamps,
        geometry=geometry,
        lineage='whole',
        save_to=save_to_ens_avg
    )
    # 'bug' time series and histograms:
    tseries_bug = [  # property_, species, group
                   ('fsdT', 'Mon', 'bug'),
                   ('gyrT', 'Mon', 'bug'),
                   ('rfloryT', 'Mon', 'bug')
                   ]
    time_series(
        observations,
        (save_to_whole, save_to_ens, save_to_ens_avg),
        tseries_properties=tseries_bug,
        geometry=geometry
    )
    hist_bug = [  # direction, species, group
                          ('rflory', 'Mon', 'bug')
                          ]
    histograms(
        observations,
        (save_to_whole, save_to_ens, save_to_ens_avg),
        geometry=geometry,
        hist_properties=hist_bug
    )
    # 'all' save_to paths:
    save_to_whole = database_path(
        input_database, 'analysis', stage='wholeSim', group='all'
    )
    save_to_ens = database_path(
        input_database, 'analysis', stage='ens', group='all'
    )
    save_to_ens_avg = database_path(
        input_database, 'analysis', stage='ensAvg', group='all'
    )
    # 'all' histograms:
    rho_phi_hist_all = [  # direction, direction long name, species, group
                   ('r', 'Crd', 'all'),
                   ('z', 'Crd', 'all'),
                   ('r', 'Mon', 'all'),
                   ('z', 'Mon', 'all'),
                   ]
    hist_all = [  # direction, species, group
                      ('theta', 'Crd', 'all'),
                      ('theta', 'Mon', 'all'),
                      ('rflory', 'Mon', 'bug')
                      ]
    histograms(
        observations,
        (save_to_whole, save_to_ens, save_to_ens_avg),
        geometry=geometry,
        hist_properties=hist_all,
        rho_phi_hist_properties=rho_phi_hist_all
    )


def analyze_segments_bug(
    input_database: str,
    parser: Callable,
    non_scalar_properties: List[Tuple[str, str, str]] = None,
    tseries_properties: List[Tuple[str, str, str]] = None,
    acf_tseries_properties: List[Tuple[str, str, str]] = None,
    hist_properties: List[Tuple[str, str, str]] = None,
    rho_phi_hist_properties: List[Tuple[str, str, str]] = None,
    geometry: str = 'biaxial',
    hierarchy: str = "/N*/N*",
    nlags: int = 7000,
    alpha: float = 0.05
) -> None:
    """read in the 'probe' observations of the 'group' particles based on the
    `hierarchy` of directories and files from the `input_database` path to the
    'probe' phase of a 'space' and creates the 'analysis' phase at that parent
    directory of the 'probe' of that 'space', infers 'space' names from
    `input_database` path and creates a 'space' directories at various stages
    in the 'analysis' directory for both 'bug' and 'all' groups.

    `tseries_properties`, `hists_properties`, `rho_phi_hists_properties` are
    list of tuples in which each tuple has three string members. The first
    string is the name of a physical property, the second one is the particle
    type, and the last one is `group` type.

    Parameters
    ----------
    input_database: str
        Path to the input_database; a 'space' directory at a given 'phase'.
    parser: Callable
        A class from 'PolyPhys.manage.parser' moduel that parses filenames
        or filepathes to infer information about a file.
    non_scalar_properties: list of tuple, default None
        A list of tuples in which each tuple has three string members. The
        first string is the name of a physical property, the second one is
        the particletype, and the last one is `group` type. These physical
        properties are all of non_scalar form.
    tseries_properties: list of tuple, default None
        A list of tuples in which each tuple has three string members. The
        first string is the name of a physical property, the second one is
        the particletype, and the last one is `group` type. These physical
        properties are all of the time-series form.
    acf_tseries_properties: list of tuple of str, default None
        A list of tumple where each tumple has three members: the property
        name, species, and group of a 'time-series' property. For
        `cls_tseries_properties`, the the auto correlation function (AFC) is
        also computed.
    hist_properties: list of tuple, default None
        A list of tuples in which each tuple has three string members. The
        first string is the name of a physical property, the second one is
        the particletype, and the last one is `group` type. These physical
        properties are all of the histogram form.
    rho_phi_hist_properties: list of tuple, default None
        A list of tuples in which each tuple has three string members. The
        first string is the name of a physical property, the second one is
        the particletype, and the last one is `group` type. These physical
        properties are all of the histogram form; however, in contrast to
        `hists_properties`, the local number denisty and volume fraction of
        `rho_phi_hists_properties` are also calculated.
    geometry : {'biaxial', 'slit', 'box'}, default 'biaxial'
        Shape of the simulation box.
    hierarchy: str
        Hierarchy of the directories and files within the `input_database`.
    nlags: int, default 7000
        Maximum lag in the auto correlation function (AFC).
    alpha: float, default 0.05
        If a number is given, the confidence intervals for the given level
        are returned. For instance if alpha=.05, 95 % confidence intervals
        are returned where the standard deviation is computed according to
        Bartlett”s formula.
    """
    invalid_keyword(geometry, ['biaxial', 'slit', 'box'])
    observations = glob(input_database + hierarchy)
    if observations == []:
        raise ValueError(
            "File not found in "
            f"'{input_database + hierarchy}'"
            )
    # 'bug' save_to paths:
    save_to_whole = database_path(
        input_database, 'analysis', stage='wholeSim', group='bug'
    )
    save_to_ens = database_path(
        input_database, 'analysis', stage='ens', group='bug'
    )
    save_to_ens_avg = database_path(
        input_database, 'analysis', stage='ensAvg', group='bug'
    )
    # stamps:
    stamp_files = sort_filenames(observations, fmts=['-stamps.csv'])
    print(stamp_files[:3])
    segments_stamps = children_stamps(
        stamp_files,
        lineage='segment',
        save_to=save_to_whole
    )
    whole_stamps = parents_stamps(
        segments_stamps,
        geometry=geometry,
        lineage='segment',
        save_to=save_to_ens
    )
    _ = parents_stamps(
        whole_stamps,
        parser,
        geometry=geometry,
        lineage='whole',
        save_to=save_to_ens_avg
    )
    # generating whole properties:
    if non_scalar_properties is not None:
        non_scalar_segments(
            observations,
            non_scalar_properties,
            save_to_whole,
            geometry=geometry)
    if tseries_properties is not None:
        time_series(
            observations,
            (save_to_whole, save_to_ens, save_to_ens_avg),
            tseries_properties=tseries_properties,
            geometry=geometry
        )
    if acf_tseries_properties is not None:
        time_series(
            observations,
            (save_to_whole, save_to_ens, save_to_ens_avg),
            acf_tseries_properties=acf_tseries_properties,
            geometry=geometry,
            nlags=nlags,
            alpha=alpha
        )
    if hist_properties is not None:
        histograms(
            observations,
            (save_to_whole, save_to_ens, save_to_ens_avg),
            geometry=geometry,
            hist_properties=hist_properties
        )
    if rho_phi_hist_properties is not None:
        histograms(
            observations,
            (save_to_whole, save_to_ens, save_to_ens_avg),
            geometry=geometry,
            rho_phi_hist_properties=rho_phi_hist_properties
        )


def analyze_wholes(
    input_database: str,
    geometry: str = 'biaxial',
    hierarchy: str = "/N*/N*"
) -> None:
    """Reads in the 'probe' observations based on the `hierarchy` of
    directories and files from the `input_database` path to the 'probe'
    phase of a 'space' and creates the 'analysis' phase at that parent
    directory of the 'probe' of that 'space', infers 'space' names from
    `input_database` path and creates a 'space' directories at various
    stages in the 'analysis' directory for both 'bug' and 'all' groups.

    Parameters
    ----------
    input_database: str
        Path to the input_database; a 'space' directory at a given 'phase'.
    geometry : {'biaxial', 'slit', 'box'}, default 'biaxial'
        Shape of the simulation box.
    hierarchy: str
        Hierarchy of the directories and files within the `input_database`.
    """
    # if not pathlib.Path(input_database).exists():
    #    raise ValueError(
    #        f"'{input_database}'"
    #        "path does not exist."
    #        )
    invalid_keyword(geometry, ['biaxial', 'slit', 'box'])
    observations = glob(input_database + hierarchy)
    if observations == []:
        raise ValueError(
            "File not found in "
            f"'{input_database + hierarchy}'"
            )
    # 'bug' save_to paths:
    save_to_whole = database_path(
        input_database, 'analysis', stage='wholeSim', group='bug'
    )
    save_to_ens = database_path(
        input_database, 'analysis', stage='ens', group='bug'
    )
    save_to_ens_avg = database_path(
        input_database, 'analysis', stage='ensAvg', group='bug'
    )
    # stamps:
    stamp_files = sort_filenames(observations, fmts=['-stamps.csv'])
    whole_stamps = children_stamps(
        stamp_files,
        lineage='whole',
        save_to=save_to_whole
    )
    _ = parents_stamps(
        whole_stamps,
        geometry=geometry,
        lineage='whole',
        save_to=save_to_ens_avg
    )
    # 'bug' time series and histograms:
    acf_tseries_bug = [  # property_, species, group
                   ('fsdT', 'Mon', 'bug'),
                   ('gyrT', 'Mon', 'bug'),
                   ('rfloryT', 'Mon', 'bug')
                   ]
    time_series(
        observations,
        (save_to_whole, save_to_ens, save_to_ens_avg),
        acf_tseries_properties=acf_tseries_bug,
        geometry=geometry
    )
    hist_bug = [  # direction, species, group
                          ('rflory', 'Mon', 'bug')
                          ]
    histograms(
        observations,
        (save_to_whole, save_to_ens, save_to_ens_avg),
        geometry=geometry,
        hist_properties=hist_bug
    )
    # 'all' save_to paths:
    save_to_whole = database_path(
        input_database, 'analysis', stage='wholeSim', group='all'
    )
    save_to_ens = database_path(
        input_database, 'analysis', stage='ens', group='all'
    )
    save_to_ens_avg = database_path(
        input_database, 'analysis', stage='ensAvg', group='all'
    )
    # 'all' histograms:
    rho_phi_hist_all = [  # direction, direction long name, species, group
                   ('r', 'Crd', 'all'),
                   ('z', 'Crd', 'all'),
                   ('r', 'Mon', 'all'),
                   ('z', 'Mon', 'all'),
                   ]
    hist_all = [  # direction, species, group
                      ('theta', 'Crd', 'all'),
                      ('theta', 'Mon', 'all'),
                      ('rflory', 'Mon', 'bug')
                      ]
    histograms(
        observations,
        (save_to_whole, save_to_ens, save_to_ens_avg),
        geometry=geometry,
        hist_properties=hist_all,
        rho_phi_hist_properties=rho_phi_hist_all
    )


def error_calc_block(
    data: np.ndarray,
    save_to: str = None
) -> pd.DataFrame:
    """
    computes the statistical inefficiency (si) and uncertainty associated with
     a physical quantity calculated in a simulation.

    Using Flybbjerg-Peterson block average method, the plateau should be
     evident after 6-8 transformations.

    Parameters
    ----------
    data: np.array
        Inpute data
    filename: str
        Name of output file
    to_file: bool
        Whether save results to file or not.

    Return:
    block_analysis: pd.dataframe
        A pandas dataframe in which there are sevweral columns of data about
         block-averaging error analysis.

    References
    ----------
    Original python code snippets are from "Computer simulation of liquids",
    Allen MP Tildesley DJ (2017):
    https://github.com/Allen-Tildesley/examples/blob/master/python_examples/error_calc.py

    https://github.com/MDAnalysis/MDAnalysisCookbook/blob/master/examples/blocks.py

    "Error estimates on averages of correlated data",HG Flyvbjerg and
    H Petersen. J Chem Phys, 91, 461 (1989): https://doi.org/10.1063/1.457480
    """
    nframes = len(data)  # size of the data
    var = np.var(data, ddof=1)  # Bias-corrected sample variance
    var_err = np.sqrt(2 / (nframes-1)) * var  # error in bias-corrected var
    sem = np.sqrt(var / nframes)  # correlations are neglected
    sem_err = np.sqrt(1 / (2*(nframes-1))) * sem  # error in SEM
    blocks = data.copy()
    ntransfroms = np.zeros(0, dtype=np.int8)  # number of block tranformartion
    ntransfroms = np.append(ntransfroms, 0)
    nblocks = np.zeros(0, dtype=np.int8)  # number of blocks
    nblocks = np.append(nblocks, nframes)
    bsize = np.zeros(0, dtype=np.int8)  # size of each block
    bsize = np.append(bsize, 1)
    bvar = np.zeros(0)  # block variances
    bvar = np.append(bvar, var)
    bvar_err = np.zeros(0)  # error in block variances
    bvar_err = np.append(bvar_err, var_err)
    bsem = np.zeros(0)  # block sems
    bsem = np.append(bsem, sem)
    bsem_err = np.zeros(0)  # error in sem
    bsem_err = np.append(bsem_err, sem_err)
    si = np.zeros(0)  # statistical inefficiency (si)
    si_initial = bsize[-1] * bvar[-1] / var  # inintial si
    si = np.append(si, si_initial)
    si_err = np.zeros(0)  # error in si
    si_initial_err = np.sqrt(2 / (nframes-1)) * si_initial  # initial si error
    si_err = np.append(si_err, si_initial_err)

    while True:  # Loop over number, and hence length, of blocks
        # halving nblocks and rounding if it is odd:
        if nblocks[-1] <= 3:  # loop counter
            break
        nblocks = np.append(nblocks, nblocks[-1] // 2)
        bsize = np.append(bsize, bsize[-1] * 2)
        blocks[0:nblocks[-1]] = (
            blocks[0:2*nblocks[-1]-1:2] + blocks[1:2*nblocks[-1]:2]
            ) / 2.0  # Blocking transformation, halving the data set
        bvar = np.append(bvar, np.var(blocks[0:nblocks[-1]], ddof=1))
        bvar_err = np.append(
            bvar_err, np.sqrt(2 / (nblocks[-1]-1)) * bvar[-1]
        )
        bsem = np.append(bsem, np.sqrt(bvar[-1] / nblocks[-1]))
        bsem_err = np.append(
            bsem_err, np.sqrt((1 / (2 * (nblocks[-1]-1)))) * bsem[-1]
            )
        si = np.append(si, bsize[-1] * bvar[-1] / var)
        si_err = np.append(
            si_err, np.sqrt((1 / (2 * (nblocks[-1]-1)))) * si[-1]
            )
        ntransfroms = np.append(ntransfroms, ntransfroms[-1]+1)

    cols = [
        "ntransfroms", "bsize", "nblocks", "var", "var_err", "sem", "sem_err",
        "si", "si_err"
        ]
    block_analysis = pd.DataFrame(
        data=np.stack(
            (ntransfroms, bsize, nblocks, bvar, bvar_err, bsem, bsem_err, si,
                si_err),
            axis=1
        ),
        columns=cols
    )
    if save_to is not None:
        block_analysis.to_csv(save_to + '-block_average.csv', index=False)
    return block_analysis
